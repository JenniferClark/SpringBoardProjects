{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d111170d-0d26-4222-8007-e93855315fc8",
   "metadata": {},
   "source": [
    "# Notebook 08 — Calibration, Blending & Production Export\n",
    "\n",
    "## Purpose\n",
    "This notebook refines the deterministic school-matching system validated in\n",
    "Notebook 07 to support **safe launch** and **future evolution**.\n",
    "\n",
    "It serves a **dual mandate**:\n",
    "\n",
    "- **Startup mandate**: Improve trust, stability, performance, and deployability\n",
    "  before real users exist.\n",
    "- **Capstone mandate**: Demonstrate advanced analytical rigor using unsupervised\n",
    "  methods and robustness analysis — without introducing opaque models.\n",
    "\n",
    "Learning is used strictly as a **diagnostic and advisory tool**, never as the\n",
    "authority over ranking logic.\n",
    "\n",
    "---\n",
    "\n",
    "## 00. Scope & Dual Mandate\n",
    "\n",
    "- Relationship to Notebook 07 (validated deterministic segments)\n",
    "- Why calibration is required before launch\n",
    "- Guardrails:\n",
    "  - Determinism remains the baseline\n",
    "  - Tier logic is never overridden\n",
    "  - No outcome prediction or click-based learning\n",
    "- Definition of “learning as consultant, not boss”\n",
    "\n",
    "---\n",
    "\n",
    "## 01. Failure Mode Analysis (The “Bugs”)\n",
    "\n",
    "Identify behaviors that would cause **user confusion or loss of trust**:\n",
    "\n",
    "- Tie density and large tie groups\n",
    "- Rank volatility under small weight changes\n",
    "- Unexpected dominance or suppression of tier tags\n",
    "- Segment-specific instability\n",
    "\n",
    "Startup goal:\n",
    "- Find fragile or confusing behavior before users do.\n",
    "\n",
    "Artifacts:\n",
    "- Tie density metrics\n",
    "- Rank stability diagnostics\n",
    "- Volatility flags by segment\n",
    "\n",
    "---\n",
    "\n",
    "## 02. Resolution Strategies (The “Fixes”)\n",
    "\n",
    "Apply **manual, deterministic adjustments** informed by Section 01:\n",
    "\n",
    "- Weight rebalancing\n",
    "- Segment-specific tie breakers\n",
    "- Feature scaling or clipping\n",
    "- Soft constraint tuning\n",
    "\n",
    "No learning is used here.\n",
    "\n",
    "Startup goal:\n",
    "- Improve stability and clarity using explicit design decisions.\n",
    "\n",
    "---\n",
    "\n",
    "## 03. Statistical Refinement (The “Capstone Science”)\n",
    "\n",
    "Apply unsupervised analysis to **improve information density**:\n",
    "\n",
    "- Feature correlation analysis\n",
    "- Redundancy detection\n",
    "- PCA / variance contribution (diagnostic only)\n",
    "\n",
    "Learning outputs:\n",
    "- Feature redundancy warnings\n",
    "- Suggested weight budget reallocation\n",
    "- Candidate features for removal or down-weighting\n",
    "\n",
    "Capstone goal:\n",
    "- Demonstrate principled feature engineering.\n",
    "\n",
    "Startup goal:\n",
    "- Simplify the matrix for faster computation and clearer rankings.\n",
    "\n",
    "---\n",
    "\n",
    "## 04. Segment Blending (The “Killer Feature”)\n",
    "\n",
    "Enable continuous personalization via **linear segment blending**:\n",
    "\n",
    "\\[\n",
    "\\vec{V}_{final} = \\alpha \\vec{V}_{A} + (1 - \\alpha) \\vec{V}_{B}\n",
    "\\]\n",
    "\n",
    "- Implement `blend_segments(seg_a, w_a, seg_b, w_b)`\n",
    "- Validate blended rankings\n",
    "- Visualize Top-K changes as blending weight shifts\n",
    "\n",
    "Startup goal:\n",
    "- Power intuitive UI controls (sliders, toggles)\n",
    "- Generate infinite personas from a small base\n",
    "\n",
    "No learning required.\n",
    "\n",
    "---\n",
    "\n",
    "## 05. Evaluation & Safety Regression\n",
    "\n",
    "Ensure refinements and blending remain safe:\n",
    "\n",
    "- Tier dominance checks (e.g., IB floors)\n",
    "- Grade-span enforcement\n",
    "- Regression against v0 rankings\n",
    "- Explainability consistency checks\n",
    "\n",
    "All changes must pass guardrails before proceeding.\n",
    "\n",
    "---\n",
    "\n",
    "## 06. Production Artifact Generation\n",
    "\n",
    "Generate deployable, versioned assets for launch:\n",
    "\n",
    "- Precompute Top-K rankings for each segment\n",
    "- Generate:\n",
    "  - `schools_top100_v1.json`\n",
    "  - accompanying metadata (segment version, feature hash, timestamp)\n",
    "- Include scores and explanation strings\n",
    "\n",
    "Startup goal:\n",
    "- Enable 0-latency initial page load\n",
    "- Keep serving logic simple and reliable\n",
    "\n",
    "---\n",
    "\n",
    "## 07. Summary & Forward Roadmap\n",
    "\n",
    "- What calibration and blending add\n",
    "- What remains deterministic by design\n",
    "- How learning will be introduced safely post-launch\n",
    "- Transition to real user data (future work)\n",
    "\n",
    "---\n",
    "\n",
    "> Determinism builds trust.  \n",
    "> Learning improves structure.  \n",
    "> Control preserves safety.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af485261-722d-4e23-9869-53f49e580caa",
   "metadata": {},
   "source": [
    "# 00. Scope & Dual Mandate  \n",
    "\n",
    "## Relationship to Notebook 07\n",
    "Notebook 07 validated that **Preference Segments v0** (deterministic personas) can sit on top of the **Scoring Engine v2** to produce coherent, explainable rankings — **without ML**.\n",
    "\n",
    "Notebook 08 builds on that baseline and prepares the system for:\n",
    "1) **Safe launch** (stable, predictable, shippable outputs)  \n",
    "2) **Capstone rigor** (diagnostics + robustness analysis using unsupervised tools)\n",
    "\n",
    "---\n",
    "\n",
    "## Why calibration is required before launch\n",
    "Even with a correct deterministic ranking, users can lose trust if the system feels:\n",
    "\n",
    "- **Random** (rank volatility under small changes)\n",
    "- **Unclear** (large tie groups and unclear ordering)\n",
    "- **Inconsistent** (segment-specific surprises)\n",
    "- **Overfit to configs** (feature redundancy causing accidental dominance)\n",
    "\n",
    "Notebook 08 treats these as *launch-blocking failure modes* to detect and correct **before users exist**.\n",
    "\n",
    "---\n",
    "\n",
    "## Guardrails (Non-negotiables)\n",
    "This notebook must preserve:\n",
    "\n",
    "- **Determinism remains the baseline**\n",
    "  - Same inputs + same config → same output\n",
    "- **Tier logic is never overridden**\n",
    "  - Tier membership is a rule, not a suggestion\n",
    "- **No outcome prediction**\n",
    "  - We are not predicting enrollment/clicks/satisfaction\n",
    "- **No click-based learning**\n",
    "  - No personalization based on behavior signals (future phase only)\n",
    "- **Learning as consultant, not boss**\n",
    "  - Unsupervised methods may *diagnose* issues and *suggest* fixes  \n",
    "  - Final ranking logic is still explicit and human-auditable\n",
    "\n",
    "---\n",
    "\n",
    "## Definition: “Learning as consultant, not boss”\n",
    "**Consultant:** identifies patterns like redundancy, high correlation, instability, brittle weights  \n",
    "**Boss:** directly changes ranking by training a model to decide the score\n",
    "\n",
    "Notebook 08 uses learning only in the *consultant* role.\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs of Notebook 08\n",
    "Launch deliverables:\n",
    "- Calibrated config(s)\n",
    "- Precomputed Top-K artifacts per segment (versioned JSON)\n",
    "- Regression & safety checks\n",
    "\n",
    "Capstone deliverables:\n",
    "- Failure mode diagnostics (tie density, volatility)\n",
    "- Unsupervised redundancy analysis (correlation/PCA as diagnostic)\n",
    "- Documented rationale for refinements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8315a205-c451-40d9-9347-8b2cf266b9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school\n",
      "PROCESSED_DIR: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/data/processed\n",
      "REPORTS_DIR: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports\n",
      "ARTIFACTS_DIR: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08\n",
      "RUN_TS: 2025-12-31T16:46:27Z\n",
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/run_manifest_v1.json\n"
     ]
    }
   ],
   "source": [
    "# 00.1 Notebook Contract + Paths  \n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Notebook versioning (update when you materially change logic)\n",
    "NOTEBOOK_ID = \"notebook08\"\n",
    "SYSTEM_VERSION = \"v1\"            # overall launch bundle version (bump when exporting new artifacts)\n",
    "SEGMENTS_VERSION = \"v0\"          # from Notebook 07 (validated deterministic segments)\n",
    "SCORING_ENGINE_VERSION = \"v2\"    # from Notebook 06/07\n",
    "\n",
    "RUN_TS = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# --- Project paths (adjust if your repo layout differs)\n",
    "ROOT = Path(\"..\").resolve()  # typical if notebooks/ is one level below repo root\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "CONFIG = ROOT / \"config\"\n",
    "REPORTS_DIR = ROOT / \"reports\"\n",
    "ARTIFACTS_DIR = ROOT / \"artifacts\" / NOTEBOOK_ID\n",
    "\n",
    "for p in [REPORTS_DIR, ARTIFACTS_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"PROCESSED_DIR:\", PROCESSED_DIR)\n",
    "print(\"REPORTS_DIR:\", REPORTS_DIR)\n",
    "print(\"ARTIFACTS_DIR:\", ARTIFACTS_DIR)\n",
    "print(\"RUN_TS:\", RUN_TS)\n",
    "\n",
    "# 00.2 Guardrails + Run Manifest \n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Guardrails:\n",
    "    deterministic_baseline: bool = True\n",
    "    never_override_tier_logic: bool = True\n",
    "    no_outcome_prediction: bool = True\n",
    "    no_click_learning: bool = True\n",
    "    learning_is_consultant_only: bool = True\n",
    "\n",
    "@dataclass\n",
    "class RunManifest:\n",
    "    notebook_id: str\n",
    "    run_ts_utc: str\n",
    "    system_version: str\n",
    "    scoring_engine_version: str\n",
    "    segments_version: str\n",
    "    guardrails: Guardrails\n",
    "    inputs: dict\n",
    "    outputs: dict\n",
    "\n",
    "GUARDRAILS = Guardrails()\n",
    "\n",
    "# Fill these in as you load concrete files in later sections\n",
    "manifest = RunManifest(\n",
    "    notebook_id=NOTEBOOK_ID,\n",
    "    run_ts_utc=RUN_TS,\n",
    "    system_version=SYSTEM_VERSION,\n",
    "    scoring_engine_version=SCORING_ENGINE_VERSION,\n",
    "    segments_version=SEGMENTS_VERSION,\n",
    "    guardrails=GUARDRAILS,\n",
    "    inputs={},\n",
    "    outputs={},\n",
    ")\n",
    "\n",
    "# Save manifest early (gets updated later)\n",
    "manifest_path = ARTIFACTS_DIR / f\"run_manifest_{SYSTEM_VERSION}.json\"\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(asdict(manifest), f, indent=2)\n",
    "\n",
    "print(\"Saved:\", manifest_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4d4c77-4e57-447f-bdbd-d110e691f994",
   "metadata": {},
   "source": [
    "# 01. Failure Mode Analysis (The “Bugs”) \n",
    "\n",
    "This section identifies **ranking behaviors that would confuse users or erode trust** —\n",
    "even when the underlying logic is correct.\n",
    "\n",
    "The goal is *not* to optimize scores, but to **surface fragility** in the deterministic\n",
    "system *before* real users experience it.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Failure Mode Analysis Matters\n",
    "\n",
    "A deterministic system can still feel broken if users observe:\n",
    "\n",
    "- Many schools tied at the same rank\n",
    "- Small config changes causing large rank shifts\n",
    "- Segment-specific inconsistencies\n",
    "- Expected “tier signals” appearing muted or overwhelming\n",
    "\n",
    "These behaviors create a perception of randomness or bias.\n",
    "\n",
    "**Notebook 08 treats these as launch-blocking bugs.**\n",
    "\n",
    "---\n",
    "\n",
    "## Failure Modes We Actively Test\n",
    "\n",
    "### 1️ Tie Density\n",
    "Large groups of schools sharing the same score or rank reduce:\n",
    "- Trust (“why can’t the system decide?”)\n",
    "- Usability (long, unordered lists)\n",
    "- Explainability (no clear differentiator)\n",
    "\n",
    "We quantify:\n",
    "- Tie group size distribution\n",
    "- % of Top-K results involved in ties\n",
    "- Tie density by preference segment\n",
    "\n",
    "---\n",
    "\n",
    "### 2️ Rank Volatility (Config Sensitivity)\n",
    "If a tiny weight change causes large rank movement, the system is brittle.\n",
    "\n",
    "We measure:\n",
    "- Rank delta under small, controlled perturbations\n",
    "- Stability of Top-K membership\n",
    "- Volatility by segment\n",
    "\n",
    "High volatility signals:\n",
    "- Feature redundancy\n",
    "- Poor weight balance\n",
    "- Hidden dominance effects\n",
    "\n",
    "---\n",
    "\n",
    "### 3️ Tier Dominance & Suppression\n",
    "Tier tags (e.g., IB, CAIS) must behave predictably:\n",
    "\n",
    "- Never fully overridden\n",
    "- Never dominate unintentionally\n",
    "- Never disappear when expected\n",
    "\n",
    "We flag:\n",
    "- Tier tags that dominate too strongly\n",
    "- Tier tags that are unexpectedly muted\n",
    "- Segment-specific tier anomalies\n",
    "\n",
    "---\n",
    "\n",
    "### 4️ Segment-Specific Instability\n",
    "A configuration that is stable globally may be fragile for a single segment.\n",
    "\n",
    "We analyze:\n",
    "- Tie density per segment\n",
    "- Rank volatility per segment\n",
    "- Feature dominance per segment\n",
    "\n",
    "Segments are treated as **first-class safety domains**.\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs & Artifacts\n",
    "\n",
    "This section produces **diagnostic artifacts only** — no ranking changes.\n",
    "\n",
    "Artifacts include:\n",
    "- Tie density metrics (CSV)\n",
    "- Rank volatility diagnostics (CSV)\n",
    "- Segment instability flags (CSV)\n",
    "- Human-readable summary report (Markdown)\n",
    "\n",
    "All outputs are saved under `/reports` and referenced in the run manifest.\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation Rule\n",
    "\n",
    "**Detection ≠ Correction**\n",
    "\n",
    "This section only identifies failure modes.\n",
    "All fixes are deferred to **Section 02** and must be:\n",
    "- Deterministic\n",
    "- Explicit\n",
    "- Human-justified\n",
    "\n",
    "---\n",
    "\n",
    "> A ranking system earns trust  \n",
    "> not by being clever,  \n",
    "> but by being predictable, explainable, and stable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d893648-76a9-4b37-85d5-9ab83b7551e7",
   "metadata": {},
   "source": [
    "## 01.0 Load Inputs + Utilities\n",
    "\n",
    "This section establishes the **input contract and shared utilities** for all\n",
    "Section 01 diagnostics.\n",
    "\n",
    "No analysis is performed here.\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "- Load **frozen outputs** from Notebook 07\n",
    "- Resolve paths safely across environments (repo vs notebook runtime)\n",
    "- Define reusable helpers for:\n",
    "  - hashing inputs\n",
    "  - saving CSV / Markdown artifacts\n",
    "  - updating the run manifest\n",
    "- Ensure all downstream diagnostics operate on the **same immutable inputs**\n",
    "\n",
    "This cell should be **stable and rarely changed**.\n",
    "\n",
    "---\n",
    "\n",
    "## Inputs (from Notebook 07)\n",
    "\n",
    "- `school_matrix_v2.npy`  \n",
    "  → numeric feature matrix used for scoring and perturbation tests\n",
    "- `school_index_v2.csv`  \n",
    "  → row → school identifier mapping\n",
    "- `school_matrix_audit_v2.csv`  \n",
    "  → audit-level scoring summaries\n",
    "- `feature_config_master_v2.json`  \n",
    "  → authoritative feature list and weights\n",
    "- `schools_master_v2.csv`  \n",
    "  → tier flags, grade spans, metadata\n",
    "- `school_vector_explain_v2.json`  \n",
    "  → per-feature contribution explanations\n",
    "- `preference_segments_v0.json`  \n",
    "  → deterministic segment definitions (validated in Notebook 07)\n",
    "\n",
    "All inputs are treated as **read-only**.\n",
    "\n",
    "---\n",
    "\n",
    "## Guardrails\n",
    "\n",
    "- ❌ No scoring logic is modified\n",
    "- ❌ No learning is introduced\n",
    "- ❌ No ranking decisions are made\n",
    "- ✅ Deterministic inputs only\n",
    "- ✅ Fail fast if inputs are missing or misaligned\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- Loaded DataFrames / arrays in memory\n",
    "- Verified feature ordering aligned to matrix columns\n",
    "- Updated `run_manifest_v1.json` with:\n",
    "  - input file paths\n",
    "  - SHA256 hashes for reproducibility\n",
    "\n",
    "No CSV or ranking artifacts are emitted in this step.\n",
    "\n",
    "---\n",
    "\n",
    "> This cell defines the *ground truth snapshot*  \n",
    "> that all Section 01 diagnostics rely on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9c3fe5b3-e405-4174-b561-b3ec285e08d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved input paths:\n",
      "- school_matrix_audit_v2: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/data/processed/school_matrix_audit_v2.csv\n",
      "- school_vector_explain_v2: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/data/processed/school_vector_explain_v2.json\n",
      "- school_index_v2: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/data/processed/school_index_v2.csv\n",
      "- school_matrix_v2: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/data/processed/school_matrix_v2.npy\n",
      "- feature_config_master_v2: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/data/processed/feature_config_master_v2.json\n",
      "- schools_master_v2: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/data/processed/schools_master_v2.csv\n",
      "- preference_segments_v0: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/config/preference_segments_v0.json\n",
      "\n",
      "Shapes:\n",
      "audit_df: (10, 8)\n",
      "index_df: (124619, 2)\n",
      "schools_master_df: (124619, 29)\n",
      "X (matrix): (124619, 10)\n",
      "\n",
      "Feature space:\n",
      "n_features: 10\n",
      "example features: ['tag_ib', 'tag_cais', 'tag_ams_montessori', 'tag_waldorf', 'serves_elementary', 'serves_middle', 'serves_high', 'score_size_small']\n"
     ]
    }
   ],
   "source": [
    "# 01.0 Load Inputs + Utilities \n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Smart path resolver\n",
    "# -----------------------------\n",
    "def resolve_path(preferred: Path, fallback: Path) -> Path:\n",
    "    if preferred.exists():\n",
    "        return preferred\n",
    "    if fallback.exists():\n",
    "        return fallback\n",
    "    raise FileNotFoundError(f\"Could not find file at:\\n- {preferred}\\n- {fallback}\")\n",
    "\n",
    "def sha256_file(path: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def load_json(path: Path) -> Dict[str, Any]:\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_csv(df: pd.DataFrame, path: Path) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(path, index=False)\n",
    "    print(\"Saved:\", path)\n",
    "\n",
    "def save_md(text: str, path: Path) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    path.write_text(text, encoding=\"utf-8\")\n",
    "    print(\"Saved:\", path)\n",
    "\n",
    "def update_manifest(manifest_path: Path, inputs: Dict[str, Any], outputs: Dict[str, Any]) -> None:\n",
    "    m = load_json(manifest_path)\n",
    "    m.setdefault(\"inputs\", {})\n",
    "    m.setdefault(\"outputs\", {})\n",
    "    m[\"inputs\"].update(inputs)\n",
    "    m[\"outputs\"].update(outputs)\n",
    "    with open(manifest_path, \"w\") as f:\n",
    "        json.dump(m, f, indent=2)\n",
    "    print(\"Updated manifest:\", manifest_path)\n",
    "\n",
    "# -----------------------------\n",
    "# Input file paths\n",
    "# -----------------------------\n",
    "# Preferred = your repo layout (data/processed), Fallback = this chat environment (/mnt/data)\n",
    "fallback_dir = Path(\"/mnt/data\")\n",
    "\n",
    "paths = {\n",
    "    \"school_matrix_audit_v2\": resolve_path(PROCESSED_DIR / \"school_matrix_audit_v2.csv\", fallback_dir / \"school_matrix_audit_v2.csv\"),\n",
    "    \"school_vector_explain_v2\": resolve_path(PROCESSED_DIR / \"school_vector_explain_v2.json\", fallback_dir / \"school_vector_explain_v2.json\"),\n",
    "    \"school_index_v2\": resolve_path(PROCESSED_DIR / \"school_index_v2.csv\", fallback_dir / \"school_index_v2.csv\"),\n",
    "    \"school_matrix_v2\": resolve_path(PROCESSED_DIR / \"school_matrix_v2.npy\", fallback_dir / \"school_matrix_v2.npy\"),\n",
    "    \"feature_config_master_v2\": resolve_path(PROCESSED_DIR / \"feature_config_master_v2.json\", fallback_dir / \"feature_config_master_v2.json\"),\n",
    "    \"schools_master_v2\": resolve_path(PROCESSED_DIR / \"schools_master_v2.csv\", fallback_dir / \"schools_master_v2.csv\"),\n",
    "    \"preference_segments_v0\": resolve_path(CONFIG / \"preference_segments_v0.json\", fallback_dir / \"preference_segments_v0.json\"),\n",
    "}\n",
    "\n",
    "print(\"Resolved input paths:\")\n",
    "for k, v in paths.items():\n",
    "    print(f\"- {k}: {v}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load inputs\n",
    "# -----------------------------\n",
    "audit_df = pd.read_csv(paths[\"school_matrix_audit_v2\"])\n",
    "index_df = pd.read_csv(paths[\"school_index_v2\"])\n",
    "schools_master_df = pd.read_csv(paths[\"schools_master_v2\"], low_memory=False)\n",
    "feature_cfg = load_json(paths[\"feature_config_master_v2\"])\n",
    "segments_cfg = load_json(paths[\"preference_segments_v0\"])\n",
    "explain_cfg = load_json(paths[\"school_vector_explain_v2\"])\n",
    "X = np.load(paths[\"school_matrix_v2\"])\n",
    "\n",
    "print(\"\\nShapes:\")\n",
    "print(\"audit_df:\", audit_df.shape)\n",
    "print(\"index_df:\", index_df.shape)\n",
    "print(\"schools_master_df:\", schools_master_df.shape)\n",
    "print(\"X (matrix):\", X.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# Feature list / ordering (must match X columns)\n",
    "# -----------------------------\n",
    "def extract_feature_names(feature_cfg: Dict[str, Any], X: np.ndarray) -> List[str]:\n",
    "    # Common patterns: {\"features\": [{\"name\": ...}, ...]} or {\"feature_order\": [...]}\n",
    "    if isinstance(feature_cfg, dict) and \"feature_order\" in feature_cfg and isinstance(feature_cfg[\"feature_order\"], list):\n",
    "        names = feature_cfg[\"feature_order\"]\n",
    "    elif isinstance(feature_cfg, dict) and \"features\" in feature_cfg and isinstance(feature_cfg[\"features\"], list):\n",
    "        names = [f.get(\"name\") for f in feature_cfg[\"features\"] if isinstance(f, dict) and f.get(\"name\")]\n",
    "    else:\n",
    "        raise ValueError(\"Could not extract feature names from feature_config_master_v2.json\")\n",
    "\n",
    "    if len(names) != X.shape[1]:\n",
    "        raise ValueError(\n",
    "            f\"Feature list length ({len(names)}) does not match X columns ({X.shape[1]}).\\n\"\n",
    "            \"Fix feature ordering to align with matrix.\"\n",
    "        )\n",
    "    return names\n",
    "\n",
    "feature_names = extract_feature_names(feature_cfg, X)\n",
    "feat_to_idx = {n: i for i, n in enumerate(feature_names)}\n",
    "\n",
    "print(\"\\nFeature space:\")\n",
    "print(\"n_features:\", len(feature_names))\n",
    "print(\"example features:\", feature_names[:8])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa7131-fc74-4a3c-93f6-93ace8c1b5d3",
   "metadata": {},
   "source": [
    "## 01.1 Build Segment Weight Vectors + Baseline Rankings \n",
    "\n",
    "This step converts each **Preference Segment v0** definition into a numeric weight\n",
    "vector aligned to the **v2 feature space** (the columns of `school_matrix_v2.npy`).\n",
    "\n",
    "We then compute **baseline deterministic scores and rankings** per segment.\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "- Create a **segment → weight vector** mapping in the same order as `X` columns\n",
    "- Compute baseline scores:\n",
    "  \\[\n",
    "  score(school) = X \\cdot w_{segment}\n",
    "  \\]\n",
    "- Produce a stable baseline ranking per segment to support:\n",
    "  - tie density measurement\n",
    "  - rank volatility testing\n",
    "  - tier dominance checks\n",
    "  - segment instability flags\n",
    "\n",
    "This is the **reference snapshot** that all Section 01 diagnostics use.\n",
    "\n",
    "---\n",
    "\n",
    "## Inputs\n",
    "\n",
    "- `X` (school feature matrix): shape `(n_schools, n_features)`\n",
    "- `feature_names` aligned to matrix columns (from 01.0)\n",
    "- `preference_segments_v0.json` (deterministic segment definitions)\n",
    "\n",
    "---\n",
    "\n",
    "## Guardrails\n",
    "\n",
    "- ✅ No learning\n",
    "- ✅ No config changes\n",
    "- ✅ Deterministic only\n",
    "- ✅ Fail fast if a segment references an unknown feature\n",
    "- ✅ Fail fast if feature ordering does not match matrix columns\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs (in memory)\n",
    "\n",
    "For each segment we store:\n",
    "\n",
    "- `w` : weight vector aligned to `feature_names`\n",
    "- `scores` : array of length `n_schools`\n",
    "- `order` : indices sorted by score (DESC), with stable tie-breaking\n",
    "\n",
    "These objects enable repeatable diagnostics without recomputing inputs.\n",
    "\n",
    "No files are written in this step.\n",
    "\n",
    "---\n",
    "\n",
    "## Sanity Checks\n",
    "\n",
    "We print:\n",
    "- per-segment score range (min/max)\n",
    "- top-1 score\n",
    "- loaded segment keys\n",
    "\n",
    "This ensures:\n",
    "- weight vectors are non-empty\n",
    "- scoring behaves consistently across segments\n",
    "\n",
    "---\n",
    "\n",
    "> If the baseline ranking is wrong or misaligned,  \n",
    "> every downstream diagnostic becomes meaningless.  \n",
    "> This step ensures alignment and determinism first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e2ea9a90-1afe-4b37-8ad2-7717852c3606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      academic_first | score range [0.300, 12.975] | top1 score=12.975 | top1 row=123458\n",
      "     small_nurturing | score range [0.250, 6.029] | top1 score=6.029 | top1 row=110025\n",
      "progressive_balanced | score range [0.500, 4.091] | top1 score=4.091 | top1 row=109691\n",
      "    balanced_general | score range [0.535, 5.229] | top1 score=5.229 | top1 row=110970\n",
      "\n",
      "Segments loaded: ['academic_first', 'small_nurturing', 'progressive_balanced', 'balanced_general']\n",
      "\n",
      "Top-10 preview for segment 'balanced_general':\n",
      " 1. row=110970 | school_id=PRI_A0500573\n",
      " 2. row=116977 | school_id=PRI_A1903036\n",
      " 3. row=123681 | school_id=PRI_BB200574\n",
      " 4. row=110100 | school_id=PRI_A0107712\n",
      " 5. row=115500 | school_id=PRI_A1701457\n",
      " 6. row=120234 | school_id=PRI_A9103804\n",
      " 7. row=117764 | school_id=PRI_A1990171\n",
      " 8. row=119128 | school_id=PRI_A2104066\n",
      " 9. row=114604 | school_id=PRI_A1501451\n",
      "10. row=105784 | school_id=PRI_00811562\n"
     ]
    }
   ],
   "source": [
    "# 01.1 Build Segment Weight Vectors + Baseline Rankings  \n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def build_segment_weight_vector(segment_key: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert a segment definition into a weight vector aligned to feature_names / X columns.\n",
    "    Segment feature items are expected like: {\"name\": \"...\", \"value\": 1.0, \"weight\": 2.5}\n",
    "    Final per-feature weight = weight * value.\n",
    "    \"\"\"\n",
    "    seg = segments_cfg[\"segments\"][segment_key]\n",
    "    w = np.zeros(len(feature_names), dtype=float)\n",
    "\n",
    "    for item in seg.get(\"features\", []):\n",
    "        fname = item[\"name\"]\n",
    "        if fname not in feat_to_idx:\n",
    "            raise KeyError(f\"Segment '{segment_key}' references unknown feature: '{fname}'\")\n",
    "\n",
    "        weight = float(item.get(\"weight\", 0.0))\n",
    "        value = float(item.get(\"value\", 1.0))\n",
    "        w[feat_to_idx[fname]] = weight * value\n",
    "\n",
    "    if np.allclose(w, 0.0):\n",
    "        raise ValueError(f\"Segment '{segment_key}' produced an all-zero weight vector. Check segment config.\")\n",
    "    return w\n",
    "\n",
    "\n",
    "def score_schools(X: np.ndarray, w: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Deterministic linear score.\"\"\"\n",
    "    return X @ w\n",
    "\n",
    "\n",
    "def rank_desc(scores: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Stable descending ranking:\n",
    "    - primary: score DESC\n",
    "    - secondary: original row index ASC (stable tie-breaker)\n",
    "    \"\"\"\n",
    "    return np.lexsort((np.arange(scores.shape[0]), -scores))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Build baselines\n",
    "# -----------------------------\n",
    "SEG_KEYS = list(segments_cfg[\"segments\"].keys())\n",
    "TOPK = 500  # diagnostics default (can change later)\n",
    "\n",
    "baseline = {}  # segment -> {\"w\", \"scores\", \"order\"}\n",
    "\n",
    "for seg in SEG_KEYS:\n",
    "    w = build_segment_weight_vector(seg)\n",
    "    scores = score_schools(X, w)\n",
    "    order = rank_desc(scores)\n",
    "    baseline[seg] = {\"w\": w, \"scores\": scores, \"order\": order}\n",
    "\n",
    "    top1 = order[0]\n",
    "    print(\n",
    "        f\"{seg:>20} | score range [{scores.min():.3f}, {scores.max():.3f}] \"\n",
    "        f\"| top1 score={scores[top1]:.3f} | top1 row={top1}\"\n",
    "    )\n",
    "\n",
    "print(\"\\nSegments loaded:\", SEG_KEYS)\n",
    "\n",
    "# -----------------------------\n",
    "# Optional: quick preview of Top-10 school IDs for one segment\n",
    "# -----------------------------\n",
    "def guess_school_id_column(df: pd.DataFrame) -> str:\n",
    "    for c in [\"school_id\", \"composite_key\", \"comkey\", \"nces_id\", \"id\"]:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return df.columns[0]\n",
    "\n",
    "school_id_col = guess_school_id_column(index_df)\n",
    "row_id_col = \"row_id\" if \"row_id\" in index_df.columns else None\n",
    "\n",
    "if row_id_col is None:\n",
    "    # assume index_df is already aligned to X rows\n",
    "    index_df[\"_row_id_tmp\"] = np.arange(len(index_df))\n",
    "    row_id_col = \"_row_id_tmp\"\n",
    "\n",
    "row_to_school_id = (\n",
    "    index_df[[row_id_col, school_id_col]]\n",
    "    .drop_duplicates(subset=[row_id_col])\n",
    "    .set_index(row_id_col)[school_id_col]\n",
    ")\n",
    "\n",
    "preview_seg = \"balanced_general\" if \"balanced_general\" in baseline else SEG_KEYS[0]\n",
    "top10_rows = baseline[preview_seg][\"order\"][:10]\n",
    "top10_ids = [row_to_school_id.get(int(r), f\"ROW_{r}\") for r in top10_rows]\n",
    "\n",
    "print(f\"\\nTop-10 preview for segment '{preview_seg}':\")\n",
    "for i, (r, sid) in enumerate(zip(top10_rows, top10_ids), start=1):\n",
    "    print(f\"{i:>2}. row={int(r):>6} | school_id={sid}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490ef8e9-9ee9-4323-8740-e33180c54db3",
   "metadata": {},
   "source": [
    "## 01.2 Tie Density Diagnostics (Global + Per Segment) \n",
    "\n",
    "This step measures **tie density** — how often schools share identical scores —\n",
    "which is a primary cause of user distrust (“why can’t it decide?”) and poor UX.\n",
    "\n",
    "We compute tie metrics **within Top-K** per segment, because ties matter most\n",
    "where users actually look.\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "- Quantify how frequently ties occur in the Top-K results\n",
    "- Identify which segments produce the **largest tie groups**\n",
    "- Produce a CSV artifact to support:\n",
    "  - calibration decisions (Section 02)\n",
    "  - redundancy analysis (Section 03)\n",
    "  - blending safety (Section 05)\n",
    "\n",
    "---\n",
    "\n",
    "## Definitions\n",
    "\n",
    "For a chosen `TOPK`:\n",
    "\n",
    "- **Unique scores**: number of distinct score values in Top-K\n",
    "- **Tie groups**: score values that appear more than once (count > 1)\n",
    "- **Max tie group**: the largest group size among tied scores\n",
    "- **% items in ties**: fraction of Top-K items belonging to tie groups\n",
    "\n",
    "We compute these metrics per segment and also estimate a global tie rate.\n",
    "\n",
    "---\n",
    "\n",
    "## Guardrails\n",
    "\n",
    "- ✅ No ranking changes\n",
    "- ✅ No learning\n",
    "- ✅ Diagnostics only\n",
    "- ✅ Uses exact deterministic scores\n",
    "- ✅ Writes artifacts under `/reports` and updates the run manifest\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs / Artifacts\n",
    "\n",
    "- `/reports/notebook08_section01_tie_density_by_segment.csv`\n",
    "\n",
    "This artifact is referenced in:\n",
    "- `artifacts/notebook08/run_manifest_v1.json`\n",
    "\n",
    "---\n",
    "\n",
    "> If tie density is high, the system will feel arbitrary.\n",
    "> Section 02 will address ties using deterministic tie-breakers and weight tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2dc88b24-28c2-45e5-9c9a-7a9e3f4eceb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section01_tie_density_by_segment.csv\n",
      "\n",
      "Tie density (Top-K) by segment:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>topk</th>\n",
       "      <th>n_unique_scores</th>\n",
       "      <th>n_tie_groups</th>\n",
       "      <th>max_tie_group</th>\n",
       "      <th>pct_items_in_ties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>500</td>\n",
       "      <td>83</td>\n",
       "      <td>46</td>\n",
       "      <td>57</td>\n",
       "      <td>0.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>500</td>\n",
       "      <td>86</td>\n",
       "      <td>44</td>\n",
       "      <td>68</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balanced_general</td>\n",
       "      <td>500</td>\n",
       "      <td>326</td>\n",
       "      <td>78</td>\n",
       "      <td>12</td>\n",
       "      <td>0.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first</td>\n",
       "      <td>500</td>\n",
       "      <td>343</td>\n",
       "      <td>46</td>\n",
       "      <td>20</td>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                segment  topk  n_unique_scores  n_tie_groups  max_tie_group  \\\n",
       "1       small_nurturing   500               83            46             57   \n",
       "2  progressive_balanced   500               86            44             68   \n",
       "3      balanced_general   500              326            78             12   \n",
       "0        academic_first   500              343            46             20   \n",
       "\n",
       "   pct_items_in_ties  \n",
       "1              0.926  \n",
       "2              0.916  \n",
       "3              0.504  \n",
       "0              0.406  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global tie rate across all schools (using 'balanced_general' scoring): 37.698%\n",
      "Updated manifest: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/run_manifest_v1.json\n"
     ]
    }
   ],
   "source": [
    "# 01.2 Tie Density Diagnostics (Global + Per Segment) \n",
    "\n",
    "# -----------------------------\n",
    "# Tie metrics\n",
    "# -----------------------------\n",
    "def tie_metrics_for_scores(scores: np.ndarray, order: np.ndarray, topk: int) -> dict:\n",
    "    \"\"\"\n",
    "    Computes tie density metrics within the top-k ranked items.\n",
    "    Uses exact float equality (works well when scores are sums of shared discrete components).\n",
    "    If you later need \"near ties\", add rounding here (e.g., np.round(scores, 6)).\n",
    "    \"\"\"\n",
    "    top_idx = order[:topk]\n",
    "    top_scores = scores[top_idx]\n",
    "\n",
    "    vc = pd.Series(top_scores).value_counts()\n",
    "\n",
    "    tie_group_sizes = vc.values  # counts per unique score\n",
    "    n_unique = int(len(vc))\n",
    "    n_tie_groups = int((vc > 1).sum())\n",
    "    max_tie = int(tie_group_sizes.max()) if len(tie_group_sizes) else 0\n",
    "    pct_tied = float((vc[vc > 1].sum() / topk) if topk else 0.0)\n",
    "\n",
    "    return {\n",
    "        \"topk\": int(topk),\n",
    "        \"n_unique_scores\": n_unique,\n",
    "        \"n_tie_groups\": n_tie_groups,\n",
    "        \"max_tie_group\": max_tie,\n",
    "        \"pct_items_in_ties\": pct_tied,\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# Compute per segment\n",
    "# -----------------------------\n",
    "rows = []\n",
    "for seg in SEG_KEYS:\n",
    "    m = tie_metrics_for_scores(\n",
    "        baseline[seg][\"scores\"],\n",
    "        baseline[seg][\"order\"],\n",
    "        TOPK\n",
    "    )\n",
    "    rows.append({\"segment\": seg, **m})\n",
    "\n",
    "tie_df = pd.DataFrame(rows).sort_values(\n",
    "    [\"pct_items_in_ties\", \"max_tie_group\"],\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "tie_out = REPORTS_DIR / \"notebook08_section01_tie_density_by_segment.csv\"\n",
    "tie_df.to_csv(tie_out, index=False)\n",
    "print(\"Saved:\", tie_out)\n",
    "\n",
    "print(\"\\nTie density (Top-K) by segment:\")\n",
    "display(tie_df)\n",
    "\n",
    "# -----------------------------\n",
    "# Global tie estimate (across all schools) using one representative segment\n",
    "# -----------------------------\n",
    "global_seg = \"balanced_general\" if \"balanced_general\" in baseline else SEG_KEYS[0]\n",
    "global_scores = baseline[global_seg][\"scores\"]\n",
    "global_vc = pd.Series(global_scores).value_counts()\n",
    "global_tie_pct = float((global_vc[global_vc > 1].sum() / len(global_scores)))\n",
    "\n",
    "print(f\"\\nGlobal tie rate across all schools (using '{global_seg}' scoring): {global_tie_pct:.3%}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Update run manifest (inputs + outputs)\n",
    "# -----------------------------\n",
    "def sha256_file(path: Path) -> str:\n",
    "    import hashlib\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "manifest_path = ARTIFACTS_DIR / f\"run_manifest_{SYSTEM_VERSION}.json\"\n",
    "\n",
    "m = load_json(manifest_path)\n",
    "m.setdefault(\"inputs\", {})\n",
    "m.setdefault(\"outputs\", {})\n",
    "\n",
    "# Record key inputs once (idempotent updates are fine)\n",
    "m[\"inputs\"].update({\n",
    "    \"inputs.section01.school_matrix_v2\": str(paths[\"school_matrix_v2\"]),\n",
    "    \"inputs.section01.school_index_v2\": str(paths[\"school_index_v2\"]),\n",
    "    \"inputs.section01.feature_config_master_v2\": str(paths[\"feature_config_master_v2\"]),\n",
    "    \"inputs.section01.preference_segments_v0\": str(paths[\"preference_segments_v0\"]),\n",
    "    \"hash.school_matrix_v2\": sha256_file(paths[\"school_matrix_v2\"]),\n",
    "    \"hash.feature_config_master_v2\": sha256_file(paths[\"feature_config_master_v2\"]),\n",
    "    \"hash.preference_segments_v0\": sha256_file(paths[\"preference_segments_v0\"]),\n",
    "})\n",
    "\n",
    "m[\"outputs\"].update({\n",
    "    \"reports.section01.tie_density_by_segment\": str(tie_out),\n",
    "})\n",
    "\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(m, f, indent=2)\n",
    "\n",
    "print(\"Updated manifest:\", manifest_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b10ae48-2866-4b0d-83a8-b5addbb156d6",
   "metadata": {},
   "source": [
    "## 01.3 Rank Volatility Diagnostics (Config Sensitivity) \n",
    "\n",
    "This step measures **rank volatility** — how much the Top-K ranking changes under\n",
    "small, controlled perturbations of segment weights.\n",
    "\n",
    "Even with determinism, a system can be **brittle** if tiny config changes produce\n",
    "large reshuffles. This creates user distrust (“it feels random”) and makes\n",
    "launch iteration dangerous.\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "- Quantify sensitivity of rankings to small weight changes\n",
    "- Measure stability of Top-K membership per segment\n",
    "- Identify segments that are fragile and likely require:\n",
    "  - weight budget rebalancing (Section 02)\n",
    "  - tie-breaker design (Section 02)\n",
    "  - redundancy reduction (Section 03)\n",
    "\n",
    "---\n",
    "\n",
    "## Method\n",
    "\n",
    "For each segment:\n",
    "\n",
    "1. Compute baseline Top-K ranking using the segment weight vector `w0`\n",
    "2. Sample `N_PERTURB` perturbed vectors:\n",
    "   \\[\n",
    "   w_1 = w_0 \\odot (1 + \\epsilon), \\quad \\epsilon \\sim U[-p, p]\n",
    "   \\]\n",
    "3. Recompute ranking and compare to baseline using:\n",
    "\n",
    "### Metrics\n",
    "\n",
    "- **Jaccard similarity (Top-K membership stability)**\n",
    "  \\[\n",
    "  J(A,B) = \\frac{|A \\cap B|}{|A \\cup B|}\n",
    "  \\]\n",
    "  Values near 1.0 indicate stable Top-K membership.\n",
    "\n",
    "- **Spearman correlation (rank ordering stability)**\n",
    "  Correlation of ranks for overlapping Top-K schools.\n",
    "  Values near 1.0 indicate stable ordering.\n",
    "\n",
    "---\n",
    "\n",
    "## Guardrails\n",
    "\n",
    "- ✅ Diagnostic only (no changes to scoring logic)\n",
    "- ✅ Deterministic perturbations (fixed random seed)\n",
    "- ✅ Same matrix `X`, same feature ordering, same segments\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs / Artifacts\n",
    "\n",
    "- `/reports/notebook08_section01_rank_volatility_by_segment.csv`\n",
    "\n",
    "This artifact is referenced in the run manifest.\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "- **Low Jaccard** = the Top-K set changes drastically → launch-risk brittle\n",
    "- **Low Spearman** = ordering within Top-K is unstable → needs tie-break design\n",
    "- High tie density + high volatility = urgent Section 02 fixes required\n",
    "\n",
    "---\n",
    "\n",
    "> Determinism is not enough.  \n",
    "> Launch safety requires stability under reasonable perturbations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "194f7a71-9ae7-4878-b326-d322e9120f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section01_rank_volatility_by_segment.csv\n",
      "\n",
      "Rank volatility by segment (lower = more fragile):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>topk</th>\n",
       "      <th>n_perturb</th>\n",
       "      <th>noise_pct</th>\n",
       "      <th>jaccard_topk_mean</th>\n",
       "      <th>jaccard_topk_p10</th>\n",
       "      <th>jaccard_topk_p90</th>\n",
       "      <th>spearman_mean</th>\n",
       "      <th>spearman_p10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balanced_general</td>\n",
       "      <td>500</td>\n",
       "      <td>60</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.995350</td>\n",
       "      <td>0.992032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>0.999104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>500</td>\n",
       "      <td>60</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.997872</td>\n",
       "      <td>0.996008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998172</td>\n",
       "      <td>0.994453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>500</td>\n",
       "      <td>60</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.999202</td>\n",
       "      <td>0.996008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first</td>\n",
       "      <td>500</td>\n",
       "      <td>60</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                segment  topk  n_perturb  noise_pct  jaccard_topk_mean  \\\n",
       "3      balanced_general   500         60       0.02           0.995350   \n",
       "1       small_nurturing   500         60       0.02           0.997872   \n",
       "2  progressive_balanced   500         60       0.02           0.999202   \n",
       "0        academic_first   500         60       0.02           1.000000   \n",
       "\n",
       "   jaccard_topk_p10  jaccard_topk_p90  spearman_mean  spearman_p10  \n",
       "3          0.992032               1.0       0.999626      0.999104  \n",
       "1          0.996008               1.0       0.998172      0.994453  \n",
       "2          0.996008               1.0       0.999922      0.999849  \n",
       "0          1.000000               1.0       0.999858      0.999686  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated manifest: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/run_manifest_v1.json\n"
     ]
    }
   ],
   "source": [
    "# 01.3 Rank Volatility Diagnostics (Controlled Perturbations)  ✅ [Launch-critical]\n",
    "\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng(42)  # fixed seed for repeatability\n",
    "\n",
    "# Tunables (start conservative; adjust later if needed)\n",
    "N_PERTURB = 60\n",
    "NOISE = 0.02  # ±2% multiplicative noise on weights\n",
    "\n",
    "def jaccard(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    sa, sb = set(a.tolist()), set(b.tolist())\n",
    "    return len(sa & sb) / len(sa | sb) if (sa | sb) else 1.0\n",
    "\n",
    "def spearman_rank_corr(base_order: np.ndarray, pert_order: np.ndarray, topk: int) -> float:\n",
    "    \"\"\"\n",
    "    Spearman correlation computed over the intersection of base Top-K and perturbed Top-K.\n",
    "    If overlap is too small, return NaN.\n",
    "    \"\"\"\n",
    "    base_top = base_order[:topk]\n",
    "    pert_top = pert_order[:topk]\n",
    "    common = list(set(base_top.tolist()) & set(pert_top.tolist()))\n",
    "\n",
    "    # Require a minimum overlap to make the correlation meaningful\n",
    "    if len(common) < max(10, topk // 10):\n",
    "        return np.nan\n",
    "\n",
    "    base_rank = {idx: r for r, idx in enumerate(base_order)}\n",
    "    pert_rank = {idx: r for r, idx in enumerate(pert_order)}\n",
    "\n",
    "    x = np.array([base_rank[i] for i in common])\n",
    "    y = np.array([pert_rank[i] for i in common])\n",
    "\n",
    "    # Spearman via ranking of ranks\n",
    "    xr = pd.Series(x).rank().to_numpy()\n",
    "    yr = pd.Series(y).rank().to_numpy()\n",
    "\n",
    "    if xr.std() == 0 or yr.std() == 0:\n",
    "        return np.nan\n",
    "\n",
    "    return float(np.corrcoef(xr, yr)[0, 1])\n",
    "\n",
    "vol_rows = []\n",
    "\n",
    "for seg in SEG_KEYS:\n",
    "    w0 = baseline[seg][\"w\"]\n",
    "    base_order = baseline[seg][\"order\"]\n",
    "    base_top = base_order[:TOPK]\n",
    "\n",
    "    jaccs = []\n",
    "    spcorrs = []\n",
    "\n",
    "    for _ in range(N_PERTURB):\n",
    "        eps = rng.uniform(-NOISE, NOISE, size=w0.shape[0])\n",
    "        w1 = w0 * (1.0 + eps)\n",
    "\n",
    "        s1 = score_schools(X, w1)\n",
    "        o1 = rank_desc(s1)\n",
    "\n",
    "        jaccs.append(jaccard(base_top, o1[:TOPK]))\n",
    "        spcorrs.append(spearman_rank_corr(base_order, o1, TOPK))\n",
    "\n",
    "    vol_rows.append({\n",
    "        \"segment\": seg,\n",
    "        \"topk\": int(TOPK),\n",
    "        \"n_perturb\": int(N_PERTURB),\n",
    "        \"noise_pct\": float(NOISE),\n",
    "        \"jaccard_topk_mean\": float(np.nanmean(jaccs)),\n",
    "        \"jaccard_topk_p10\": float(np.nanpercentile(jaccs, 10)),\n",
    "        \"jaccard_topk_p90\": float(np.nanpercentile(jaccs, 90)),\n",
    "        \"spearman_mean\": float(np.nanmean(spcorrs)),\n",
    "        \"spearman_p10\": float(np.nanpercentile([v for v in spcorrs if not np.isnan(v)], 10))\n",
    "                         if np.any(~np.isnan(spcorrs)) else np.nan,\n",
    "    })\n",
    "\n",
    "vol_df = pd.DataFrame(vol_rows).sort_values(\n",
    "    [\"jaccard_topk_mean\", \"spearman_mean\"],\n",
    "    ascending=True\n",
    ")\n",
    "\n",
    "vol_out = REPORTS_DIR / \"notebook08_section01_rank_volatility_by_segment.csv\"\n",
    "vol_df.to_csv(vol_out, index=False)\n",
    "print(\"Saved:\", vol_out)\n",
    "\n",
    "print(\"\\nRank volatility by segment (lower = more fragile):\")\n",
    "display(vol_df)\n",
    "\n",
    "# -----------------------------\n",
    "# Update run manifest\n",
    "# -----------------------------\n",
    "manifest_path = ARTIFACTS_DIR / f\"run_manifest_{SYSTEM_VERSION}.json\"\n",
    "m = load_json(manifest_path)\n",
    "m.setdefault(\"outputs\", {})\n",
    "m[\"outputs\"].update({\n",
    "    \"reports.section01.rank_volatility_by_segment\": str(vol_out),\n",
    "})\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(m, f, indent=2)\n",
    "\n",
    "print(\"Updated manifest:\", manifest_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ed6717-9128-48b7-8e97-f4d789db02e7",
   "metadata": {},
   "source": [
    "## 01.4 Tier Dominance / Suppression Checks \n",
    "\n",
    "This step checks whether **tier signals** (e.g., IB, CAIS, Montessori, Waldorf)\n",
    "behave predictably inside Top-K rankings.\n",
    "\n",
    "Tier tags are **high-trust signals** in the system and must satisfy launch\n",
    "expectations:\n",
    "\n",
    "- They should not be accidentally **overpowering** the ranking\n",
    "- They should not be unexpectedly **muted** when a segment clearly values them\n",
    "- They should not behave inconsistently across segments\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "- Measure how often each tier appears in Top-K vs its global prevalence\n",
    "- Flag tiers that are:\n",
    "  - **dominant** (overrepresented in Top-K)\n",
    "  - **suppressed** (underrepresented in Top-K)\n",
    "- Identify segment-specific tier anomalies\n",
    "\n",
    "---\n",
    "\n",
    "## Method\n",
    "\n",
    "For each segment and each tier flag:\n",
    "\n",
    "- Compute:\n",
    "  - `topk_rate` = fraction of Top-K schools having the tier flag\n",
    "  - `global_rate` = fraction across all schools\n",
    "  - `dominance_ratio = topk_rate / global_rate`\n",
    "\n",
    "We then flag:\n",
    "\n",
    "- **dominant** if `dominance_ratio >= 3.0`\n",
    "- **suppressed** if `dominance_ratio <= 0.33`\n",
    "\n",
    "These thresholds are heuristic “smoke alarms,” not judgments.\n",
    "\n",
    "---\n",
    "\n",
    "## Guardrails\n",
    "\n",
    "- ✅ Diagnostic only\n",
    "- ✅ Does not change any ranking logic\n",
    "- ✅ Uses explicit tier flags from `schools_master_v2.csv`\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs / Artifacts\n",
    "\n",
    "- `/reports/notebook08_section01_tier_dominance_by_segment.csv`\n",
    "\n",
    "This artifact is referenced in the run manifest.\n",
    "\n",
    "---\n",
    "\n",
    "> Tier tags are meant to be trusted anchors.\n",
    "> If they dominate unintentionally, the system feels biased.\n",
    "> If they vanish unexpectedly, the system feels broken.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b1fc4d59-a669-4bd8-9d65-fbf5f1334704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tier columns detected: ['has_ib', 'has_cais', 'has_ams_montessori', 'has_waldorf']\n",
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section01_tier_dominance_by_segment.csv\n",
      "\n",
      "Tier dominance / suppression flags (flag != ''):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>tier_col</th>\n",
       "      <th>topk</th>\n",
       "      <th>topk_rate</th>\n",
       "      <th>global_rate</th>\n",
       "      <th>dominance_ratio</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic_first</td>\n",
       "      <td>has_ams_montessori</td>\n",
       "      <td>500</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>49.847600</td>\n",
       "      <td>dominant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academic_first</td>\n",
       "      <td>has_cais</td>\n",
       "      <td>500</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>249.238000</td>\n",
       "      <td>dominant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first</td>\n",
       "      <td>has_ib</td>\n",
       "      <td>500</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>249.238000</td>\n",
       "      <td>dominant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academic_first</td>\n",
       "      <td>has_waldorf</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>balanced_general</td>\n",
       "      <td>has_ams_montessori</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>balanced_general</td>\n",
       "      <td>has_cais</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>balanced_general</td>\n",
       "      <td>has_ib</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>balanced_general</td>\n",
       "      <td>has_waldorf</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>has_ams_montessori</td>\n",
       "      <td>500</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>249.238000</td>\n",
       "      <td>dominant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>has_cais</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>has_ib</td>\n",
       "      <td>500</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>7.552667</td>\n",
       "      <td>dominant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>has_waldorf</td>\n",
       "      <td>500</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>249.238000</td>\n",
       "      <td>dominant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>has_ams_montessori</td>\n",
       "      <td>500</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>49.847600</td>\n",
       "      <td>dominant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>has_cais</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>has_ib</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>has_waldorf</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suppressed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 segment            tier_col  topk  topk_rate  global_rate  \\\n",
       "2         academic_first  has_ams_montessori   500      0.002     0.000040   \n",
       "1         academic_first            has_cais   500      0.146     0.000586   \n",
       "0         academic_first              has_ib   500      0.066     0.000265   \n",
       "3         academic_first         has_waldorf   500      0.000     0.000120   \n",
       "14      balanced_general  has_ams_montessori   500      0.000     0.000040   \n",
       "13      balanced_general            has_cais   500      0.000     0.000586   \n",
       "12      balanced_general              has_ib   500      0.000     0.000265   \n",
       "15      balanced_general         has_waldorf   500      0.000     0.000120   \n",
       "10  progressive_balanced  has_ams_montessori   500      0.010     0.000040   \n",
       "9   progressive_balanced            has_cais   500      0.000     0.000586   \n",
       "8   progressive_balanced              has_ib   500      0.002     0.000265   \n",
       "11  progressive_balanced         has_waldorf   500      0.030     0.000120   \n",
       "6        small_nurturing  has_ams_montessori   500      0.002     0.000040   \n",
       "5        small_nurturing            has_cais   500      0.000     0.000586   \n",
       "4        small_nurturing              has_ib   500      0.000     0.000265   \n",
       "7        small_nurturing         has_waldorf   500      0.000     0.000120   \n",
       "\n",
       "    dominance_ratio        flag  \n",
       "2         49.847600    dominant  \n",
       "1        249.238000    dominant  \n",
       "0        249.238000    dominant  \n",
       "3          0.000000  suppressed  \n",
       "14         0.000000  suppressed  \n",
       "13         0.000000  suppressed  \n",
       "12         0.000000  suppressed  \n",
       "15         0.000000  suppressed  \n",
       "10       249.238000    dominant  \n",
       "9          0.000000  suppressed  \n",
       "8          7.552667    dominant  \n",
       "11       249.238000    dominant  \n",
       "6         49.847600    dominant  \n",
       "5          0.000000  suppressed  \n",
       "4          0.000000  suppressed  \n",
       "7          0.000000  suppressed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated manifest: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/run_manifest_v1.json\n"
     ]
    }
   ],
   "source": [
    "# 01.4 Tier Dominance / Suppression Checks  \n",
    "\n",
    "# -----------------------------\n",
    "# Detect tier columns\n",
    "# -----------------------------\n",
    "tier_candidates = [\n",
    "    \"tag_ib\", \"tag_cais\", \"tag_ams_montessori\", \"tag_waldorf\",\n",
    "    \"has_ib\", \"has_cais\", \"has_ams_montessori\", \"has_waldorf\",\n",
    "    \"is_ib\", \"is_cais\"\n",
    "]\n",
    "tier_cols = [c for c in tier_candidates if c in schools_master_df.columns]\n",
    "\n",
    "if not tier_cols:\n",
    "    print(\"WARNING: No tier flag columns detected in schools_master_v2.csv. Skipping tier checks.\")\n",
    "else:\n",
    "    print(\"Tier columns detected:\", tier_cols)\n",
    "\n",
    "# -----------------------------\n",
    "# Align schools_master rows to matrix rows via school_id\n",
    "# -----------------------------\n",
    "def guess_key_col(df: pd.DataFrame) -> str:\n",
    "    for c in [\"school_id\", \"composite_key\", \"comkey\", \"nces_id\", \"id\"]:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return df.columns[0]\n",
    "\n",
    "index_key_col = school_id_col  # from 01.1\n",
    "master_key_col = index_key_col if index_key_col in schools_master_df.columns else guess_key_col(schools_master_df)\n",
    "\n",
    "# Build row-aligned table: one row per matrix row in X\n",
    "row_ids = np.arange(X.shape[0])\n",
    "school_ids = pd.Series([row_to_school_id.get(int(r), f\"ROW_{r}\") for r in row_ids], name=master_key_col)\n",
    "tier_frame = pd.DataFrame({master_key_col: school_ids})\n",
    "\n",
    "if tier_cols:\n",
    "    tier_frame = tier_frame.merge(\n",
    "        schools_master_df[[master_key_col] + tier_cols].drop_duplicates(subset=[master_key_col]),\n",
    "        how=\"left\",\n",
    "        on=master_key_col,\n",
    "    )\n",
    "\n",
    "    # Fill missing with 0 (unknown treated as not-in-tier)\n",
    "    for c in tier_cols:\n",
    "        tier_frame[c] = tier_frame[c].fillna(0).astype(int)\n",
    "\n",
    "    global_rates = {c: float(tier_frame[c].mean()) for c in tier_cols}\n",
    "\n",
    "    # -----------------------------\n",
    "    # Compute dominance ratios per segment\n",
    "    # -----------------------------\n",
    "    DOM_HIGH = 3.0\n",
    "    DOM_LOW = 0.33\n",
    "\n",
    "    dom_rows = []\n",
    "    for seg in SEG_KEYS:\n",
    "        top_rows = baseline[seg][\"order\"][:TOPK]\n",
    "        top_tiers = tier_frame.iloc[top_rows]\n",
    "\n",
    "        for c in tier_cols:\n",
    "            top_rate = float(top_tiers[c].mean())\n",
    "            glob = global_rates[c] if global_rates[c] > 0 else np.nan\n",
    "            ratio = (top_rate / glob) if (glob and not np.isnan(glob) and glob > 0) else np.nan\n",
    "\n",
    "            flag = \"\"\n",
    "            if not np.isnan(ratio):\n",
    "                if ratio >= DOM_HIGH:\n",
    "                    flag = \"dominant\"\n",
    "                elif ratio <= DOM_LOW:\n",
    "                    flag = \"suppressed\"\n",
    "\n",
    "            dom_rows.append({\n",
    "                \"segment\": seg,\n",
    "                \"tier_col\": c,\n",
    "                \"topk\": int(TOPK),\n",
    "                \"topk_rate\": top_rate,\n",
    "                \"global_rate\": glob,\n",
    "                \"dominance_ratio\": ratio,\n",
    "                \"flag\": flag,\n",
    "            })\n",
    "\n",
    "    dom_df = pd.DataFrame(dom_rows).sort_values(\n",
    "        [\"flag\", \"dominance_ratio\"],\n",
    "        ascending=[True, False]\n",
    "    )\n",
    "\n",
    "    dom_out = REPORTS_DIR / \"notebook08_section01_tier_dominance_by_segment.csv\"\n",
    "    dom_df.to_csv(dom_out, index=False)\n",
    "    print(\"Saved:\", dom_out)\n",
    "\n",
    "    print(\"\\nTier dominance / suppression flags (flag != ''):\")\n",
    "    display(dom_df[dom_df[\"flag\"] != \"\"].sort_values([\"segment\", \"tier_col\"]))\n",
    "\n",
    "    # -----------------------------\n",
    "    # Update run manifest\n",
    "    # -----------------------------\n",
    "    manifest_path = ARTIFACTS_DIR / f\"run_manifest_{SYSTEM_VERSION}.json\"\n",
    "    m = load_json(manifest_path)\n",
    "    m.setdefault(\"outputs\", {})\n",
    "    m[\"outputs\"].update({\n",
    "        \"reports.section01.tier_dominance_by_segment\": str(dom_out),\n",
    "    })\n",
    "    with open(manifest_path, \"w\") as f:\n",
    "        json.dump(m, f, indent=2)\n",
    "    print(\"Updated manifest:\", manifest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5e058923-a9c5-497c-9f98-be0d3a96d57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section01_tier_dominance_by_segment_v2.csv\n",
      "\n",
      "Tier dominance flags using KNOWN baseline (flag_known != ''):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>tier_col</th>\n",
       "      <th>topk</th>\n",
       "      <th>topk_rate</th>\n",
       "      <th>global_rate_all</th>\n",
       "      <th>dominance_ratio_all</th>\n",
       "      <th>known_coverage_rate</th>\n",
       "      <th>global_rate_known</th>\n",
       "      <th>dominance_ratio_known</th>\n",
       "      <th>flag_known</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic_first</td>\n",
       "      <td>has_ams_montessori</td>\n",
       "      <td>500</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>49.847600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>49.847600</td>\n",
       "      <td>dominant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academic_first</td>\n",
       "      <td>has_cais</td>\n",
       "      <td>500</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>249.238000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>249.238000</td>\n",
       "      <td>dominant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first</td>\n",
       "      <td>has_ib</td>\n",
       "      <td>500</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>249.238000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>249.238000</td>\n",
       "      <td>dominant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academic_first</td>\n",
       "      <td>has_waldorf</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>balanced_general</td>\n",
       "      <td>has_ams_montessori</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>balanced_general</td>\n",
       "      <td>has_cais</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>balanced_general</td>\n",
       "      <td>has_ib</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>balanced_general</td>\n",
       "      <td>has_waldorf</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>has_ams_montessori</td>\n",
       "      <td>500</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>249.238000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>249.238000</td>\n",
       "      <td>dominant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>has_cais</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>has_ib</td>\n",
       "      <td>500</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>7.552667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>7.552667</td>\n",
       "      <td>dominant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>has_waldorf</td>\n",
       "      <td>500</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>249.238000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>249.238000</td>\n",
       "      <td>dominant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>has_ams_montessori</td>\n",
       "      <td>500</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>49.847600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>49.847600</td>\n",
       "      <td>dominant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>has_cais</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>has_ib</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>has_waldorf</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suppressed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 segment            tier_col  topk  topk_rate  \\\n",
       "2         academic_first  has_ams_montessori   500      0.002   \n",
       "1         academic_first            has_cais   500      0.146   \n",
       "0         academic_first              has_ib   500      0.066   \n",
       "3         academic_first         has_waldorf   500      0.000   \n",
       "14      balanced_general  has_ams_montessori   500      0.000   \n",
       "13      balanced_general            has_cais   500      0.000   \n",
       "12      balanced_general              has_ib   500      0.000   \n",
       "15      balanced_general         has_waldorf   500      0.000   \n",
       "10  progressive_balanced  has_ams_montessori   500      0.010   \n",
       "9   progressive_balanced            has_cais   500      0.000   \n",
       "8   progressive_balanced              has_ib   500      0.002   \n",
       "11  progressive_balanced         has_waldorf   500      0.030   \n",
       "6        small_nurturing  has_ams_montessori   500      0.002   \n",
       "5        small_nurturing            has_cais   500      0.000   \n",
       "4        small_nurturing              has_ib   500      0.000   \n",
       "7        small_nurturing         has_waldorf   500      0.000   \n",
       "\n",
       "    global_rate_all  dominance_ratio_all  known_coverage_rate  \\\n",
       "2          0.000040            49.847600                  1.0   \n",
       "1          0.000586           249.238000                  1.0   \n",
       "0          0.000265           249.238000                  1.0   \n",
       "3          0.000120             0.000000                  1.0   \n",
       "14         0.000040             0.000000                  1.0   \n",
       "13         0.000586             0.000000                  1.0   \n",
       "12         0.000265             0.000000                  1.0   \n",
       "15         0.000120             0.000000                  1.0   \n",
       "10         0.000040           249.238000                  1.0   \n",
       "9          0.000586             0.000000                  1.0   \n",
       "8          0.000265             7.552667                  1.0   \n",
       "11         0.000120           249.238000                  1.0   \n",
       "6          0.000040            49.847600                  1.0   \n",
       "5          0.000586             0.000000                  1.0   \n",
       "4          0.000265             0.000000                  1.0   \n",
       "7          0.000120             0.000000                  1.0   \n",
       "\n",
       "    global_rate_known  dominance_ratio_known  flag_known  \n",
       "2            0.000040              49.847600    dominant  \n",
       "1            0.000586             249.238000    dominant  \n",
       "0            0.000265             249.238000    dominant  \n",
       "3            0.000120               0.000000  suppressed  \n",
       "14           0.000040               0.000000  suppressed  \n",
       "13           0.000586               0.000000  suppressed  \n",
       "12           0.000265               0.000000  suppressed  \n",
       "15           0.000120               0.000000  suppressed  \n",
       "10           0.000040             249.238000    dominant  \n",
       "9            0.000586               0.000000  suppressed  \n",
       "8            0.000265               7.552667    dominant  \n",
       "11           0.000120             249.238000    dominant  \n",
       "6            0.000040              49.847600    dominant  \n",
       "5            0.000586               0.000000  suppressed  \n",
       "4            0.000265               0.000000  suppressed  \n",
       "7            0.000120               0.000000  suppressed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tier baseline coverage summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tier_col</th>\n",
       "      <th>known_coverage_rate</th>\n",
       "      <th>global_rate_all</th>\n",
       "      <th>global_rate_known</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>has_ib</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>has_cais</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>has_ams_montessori</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>has_waldorf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tier_col  known_coverage_rate  global_rate_all  global_rate_known\n",
       "0              has_ib                  1.0         0.000265           0.000265\n",
       "1            has_cais                  1.0         0.000586           0.000586\n",
       "2  has_ams_montessori                  1.0         0.000040           0.000040\n",
       "3         has_waldorf                  1.0         0.000120           0.000120"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated manifest: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/run_manifest_v1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'has_ib': 33, 'has_cais': 73, 'has_ams_montessori': 5, 'has_waldorf': 15}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 01.4b Patch: Tier Dominance vs \"Known Coverage\" Baseline\n",
    "#\n",
    "# Problem: global_rate can be artificially tiny if many schools have tier flags missing / unknown\n",
    "#          and we filled NaN -> 0. This inflates dominance ratios and creates misleading flags.\n",
    "#\n",
    "# Fix: compute:\n",
    "#   - global_rate_all   : across all rows (current behavior)\n",
    "#   - global_rate_known : across rows where the tier column was actually known (non-null before fill)\n",
    "#   - known_coverage_rate: fraction of rows where the tier column was known\n",
    "#\n",
    "# Output: a new CSV with both baselines and updated flags based on global_rate_known.\n",
    "\n",
    "if not tier_cols:\n",
    "    print(\"No tier columns detected earlier. Nothing to patch.\")\n",
    "else:\n",
    "    # Rebuild a tier frame WITHOUT filling NaNs first, so we can measure \"known coverage\"\n",
    "    row_ids = np.arange(X.shape[0])\n",
    "    school_ids = pd.Series([row_to_school_id.get(int(r), f\"ROW_{r}\") for r in row_ids], name=master_key_col)\n",
    "    tier_raw = pd.DataFrame({master_key_col: school_ids})\n",
    "\n",
    "    tier_raw = tier_raw.merge(\n",
    "        schools_master_df[[master_key_col] + tier_cols].drop_duplicates(subset=[master_key_col]),\n",
    "        how=\"left\",\n",
    "        on=master_key_col,\n",
    "    )\n",
    "\n",
    "    # Known coverage mask per tier column (True if not null before fill)\n",
    "    known_mask = {c: tier_raw[c].notna().to_numpy() for c in tier_cols}\n",
    "\n",
    "    # Now create filled/int version for rate calculations\n",
    "    tier_filled = tier_raw.copy()\n",
    "    for c in tier_cols:\n",
    "        tier_filled[c] = tier_filled[c].fillna(0).astype(int)\n",
    "\n",
    "    # Baselines\n",
    "    global_rate_all = {c: float(tier_filled[c].mean()) for c in tier_cols}\n",
    "\n",
    "    global_rate_known = {}\n",
    "    known_coverage_rate = {}\n",
    "    for c in tier_cols:\n",
    "        km = known_mask[c]\n",
    "        known_coverage_rate[c] = float(km.mean())\n",
    "        if km.sum() == 0:\n",
    "            global_rate_known[c] = np.nan\n",
    "        else:\n",
    "            global_rate_known[c] = float(tier_filled.loc[km, c].mean())\n",
    "\n",
    "    # Compute dominance ratios per segment vs both baselines\n",
    "    DOM_HIGH = 3.0\n",
    "    DOM_LOW = 0.33\n",
    "\n",
    "    rows = []\n",
    "    for seg in SEG_KEYS:\n",
    "        top_rows = baseline[seg][\"order\"][:TOPK]\n",
    "        top_tiers = tier_filled.iloc[top_rows]\n",
    "\n",
    "        for c in tier_cols:\n",
    "            top_rate = float(top_tiers[c].mean())\n",
    "\n",
    "            gr_all = global_rate_all[c] if global_rate_all[c] > 0 else np.nan\n",
    "            gr_known = global_rate_known[c] if (global_rate_known[c] is not None and not np.isnan(global_rate_known[c]) and global_rate_known[c] > 0) else np.nan\n",
    "\n",
    "            ratio_all = (top_rate / gr_all) if (gr_all and not np.isnan(gr_all)) else np.nan\n",
    "            ratio_known = (top_rate / gr_known) if (gr_known and not np.isnan(gr_known)) else np.nan\n",
    "\n",
    "            # Flags should be based on the known baseline (more honest)\n",
    "            flag_known = \"\"\n",
    "            if not np.isnan(ratio_known):\n",
    "                if ratio_known >= DOM_HIGH:\n",
    "                    flag_known = \"dominant\"\n",
    "                elif ratio_known <= DOM_LOW:\n",
    "                    flag_known = \"suppressed\"\n",
    "\n",
    "            rows.append({\n",
    "                \"segment\": seg,\n",
    "                \"tier_col\": c,\n",
    "                \"topk\": int(TOPK),\n",
    "                \"topk_rate\": top_rate,\n",
    "\n",
    "                \"global_rate_all\": gr_all,\n",
    "                \"dominance_ratio_all\": ratio_all,\n",
    "\n",
    "                \"known_coverage_rate\": known_coverage_rate[c],\n",
    "                \"global_rate_known\": gr_known,\n",
    "                \"dominance_ratio_known\": ratio_known,\n",
    "                \"flag_known\": flag_known,\n",
    "            })\n",
    "\n",
    "    dom2_df = pd.DataFrame(rows).sort_values(\n",
    "        [\"flag_known\", \"dominance_ratio_known\"],\n",
    "        ascending=[True, False]\n",
    "    )\n",
    "\n",
    "    dom2_out = REPORTS_DIR / \"notebook08_section01_tier_dominance_by_segment_v2.csv\"\n",
    "    dom2_df.to_csv(dom2_out, index=False)\n",
    "    print(\"Saved:\", dom2_out)\n",
    "\n",
    "    print(\"\\nTier dominance flags using KNOWN baseline (flag_known != ''):\")\n",
    "    display(dom2_df[dom2_df[\"flag_known\"] != \"\"].sort_values([\"segment\", \"tier_col\"]))\n",
    "\n",
    "    # Also print baseline coverage summary (this is the key sanity check)\n",
    "    coverage_summary = pd.DataFrame([\n",
    "        {\n",
    "            \"tier_col\": c,\n",
    "            \"known_coverage_rate\": known_coverage_rate[c],\n",
    "            \"global_rate_all\": global_rate_all[c],\n",
    "            \"global_rate_known\": global_rate_known[c],\n",
    "        }\n",
    "        for c in tier_cols\n",
    "    ]).sort_values(\"known_coverage_rate\", ascending=True)\n",
    "\n",
    "    print(\"\\nTier baseline coverage summary:\")\n",
    "    display(coverage_summary)\n",
    "\n",
    "    # Update manifest with the new artifact\n",
    "    manifest_path = ARTIFACTS_DIR / f\"run_manifest_{SYSTEM_VERSION}.json\"\n",
    "    m = load_json(manifest_path)\n",
    "    m.setdefault(\"outputs\", {})\n",
    "    m[\"outputs\"].update({\n",
    "        \"reports.section01.tier_dominance_by_segment_v2\": str(dom2_out),\n",
    "    })\n",
    "    with open(manifest_path, \"w\") as f:\n",
    "        json.dump(m, f, indent=2)\n",
    "    print(\"Updated manifest:\", manifest_path)\n",
    "\n",
    "# sanity: how many schools have each tier flag?\n",
    "tier_counts = {c: int((tier_frame[c] == 1).sum()) for c in tier_cols}\n",
    "tier_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c0e0f1-c0f8-4d21-ba58-8bc0e39ef6f7",
   "metadata": {},
   "source": [
    "## 01.5 Segment Instability Summary + Human Report \n",
    "\n",
    "This step consolidates Section 01 diagnostics into a single **segment-level\n",
    "instability summary** and generates a **human-readable report** suitable for:\n",
    "\n",
    "- startup launch documentation (what risks exist and why)\n",
    "- capstone narrative (rigorous robustness analysis without ML authority)\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "- Merge key metrics into one table per segment:\n",
    "  - Tie density (Section 01.2)\n",
    "  - Rank volatility (Section 01.3)\n",
    "- Assign a simple **risk label** per segment to guide Section 02 fixes:\n",
    "  - `LOW`, `MED`, `HIGH`\n",
    "\n",
    "---\n",
    "\n",
    "## Risk Heuristic (Transparent)\n",
    "\n",
    "We mark risk using simple, explicit thresholds:\n",
    "\n",
    "### Tie risk triggers if:\n",
    "- `% items in ties >= 25%` OR\n",
    "- `max tie group >= 20`\n",
    "\n",
    "### Volatility risk triggers if:\n",
    "- `jaccard_topk_mean <= 0.85` OR\n",
    "- `spearman_mean <= 0.85`\n",
    "\n",
    "Risk label:\n",
    "- `HIGH` if tie risk AND volatility risk\n",
    "- `MED` if either one is triggered\n",
    "- `LOW` if neither is triggered\n",
    "\n",
    "This heuristic is intentionally conservative and easy to audit.\n",
    "\n",
    "---\n",
    "\n",
    "## Guardrails\n",
    "\n",
    "- ✅ No ranking changes\n",
    "- ✅ No learning\n",
    "- ✅ Produces artifacts only\n",
    "- ✅ All thresholds are explicit and human-readable\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs / Artifacts\n",
    "\n",
    "1) `/reports/notebook08_section01_segment_instability_summary.csv`  \n",
    "2) `/reports/notebook08_section01_failure_mode_report.md`\n",
    "\n",
    "Both are referenced in the run manifest.\n",
    "\n",
    "---\n",
    "\n",
    "> Section 01 finds the problems.  \n",
    "> Section 02 applies deterministic fixes under guardrails.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ad84173e-45f9-497a-bd41-be9666893611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section01_segment_instability_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>topk</th>\n",
       "      <th>n_unique_scores</th>\n",
       "      <th>n_tie_groups</th>\n",
       "      <th>max_tie_group</th>\n",
       "      <th>pct_items_in_ties</th>\n",
       "      <th>n_perturb</th>\n",
       "      <th>noise_pct</th>\n",
       "      <th>jaccard_topk_mean</th>\n",
       "      <th>jaccard_topk_p10</th>\n",
       "      <th>jaccard_topk_p90</th>\n",
       "      <th>spearman_mean</th>\n",
       "      <th>spearman_p10</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>500</td>\n",
       "      <td>83</td>\n",
       "      <td>46</td>\n",
       "      <td>57</td>\n",
       "      <td>0.926</td>\n",
       "      <td>60</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.997872</td>\n",
       "      <td>0.996008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998172</td>\n",
       "      <td>0.994453</td>\n",
       "      <td>MED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>500</td>\n",
       "      <td>86</td>\n",
       "      <td>44</td>\n",
       "      <td>68</td>\n",
       "      <td>0.916</td>\n",
       "      <td>60</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.999202</td>\n",
       "      <td>0.996008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>MED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>balanced_general</td>\n",
       "      <td>500</td>\n",
       "      <td>326</td>\n",
       "      <td>78</td>\n",
       "      <td>12</td>\n",
       "      <td>0.504</td>\n",
       "      <td>60</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.995350</td>\n",
       "      <td>0.992032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>0.999104</td>\n",
       "      <td>MED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academic_first</td>\n",
       "      <td>500</td>\n",
       "      <td>343</td>\n",
       "      <td>46</td>\n",
       "      <td>20</td>\n",
       "      <td>0.406</td>\n",
       "      <td>60</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999686</td>\n",
       "      <td>MED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                segment  topk  n_unique_scores  n_tie_groups  max_tie_group  \\\n",
       "0       small_nurturing   500               83            46             57   \n",
       "1  progressive_balanced   500               86            44             68   \n",
       "2      balanced_general   500              326            78             12   \n",
       "3        academic_first   500              343            46             20   \n",
       "\n",
       "   pct_items_in_ties  n_perturb  noise_pct  jaccard_topk_mean  \\\n",
       "0              0.926         60       0.02           0.997872   \n",
       "1              0.916         60       0.02           0.999202   \n",
       "2              0.504         60       0.02           0.995350   \n",
       "3              0.406         60       0.02           1.000000   \n",
       "\n",
       "   jaccard_topk_p10  jaccard_topk_p90  spearman_mean  spearman_p10 risk  \n",
       "0          0.996008               1.0       0.998172      0.994453  MED  \n",
       "1          0.996008               1.0       0.999922      0.999849  MED  \n",
       "2          0.992032               1.0       0.999626      0.999104  MED  \n",
       "3          1.000000               1.0       0.999858      0.999686  MED  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 01.5 Segment Instability Summary + Human Report \n",
    "\n",
    "# -----------------------------\n",
    "# Load prior artifacts (or use in-memory tables if present)\n",
    "# -----------------------------\n",
    "# tie_df and vol_df should already exist in memory from 01.2 and 01.3.\n",
    "# If not, uncomment these:\n",
    "# tie_df = pd.read_csv(REPORTS_DIR / \"notebook08_section01_tie_density_by_segment.csv\")\n",
    "# vol_df = pd.read_csv(REPORTS_DIR / \"notebook08_section01_rank_volatility_by_segment.csv\")\n",
    "\n",
    "summary_df = tie_df.merge(vol_df, on=[\"segment\", \"topk\"], how=\"left\")\n",
    "\n",
    "# -----------------------------\n",
    "# Risk heuristic (explicit + auditable)\n",
    "# -----------------------------\n",
    "TIE_PCT_THRESH = 0.25\n",
    "TIE_MAX_GROUP_THRESH = 20\n",
    "VOL_JACC_THRESH = 0.85\n",
    "VOL_SPEAR_THRESH = 0.85\n",
    "\n",
    "def risk_label(row) -> str:\n",
    "    tie_risk = (row[\"pct_items_in_ties\"] >= TIE_PCT_THRESH) or (row[\"max_tie_group\"] >= TIE_MAX_GROUP_THRESH)\n",
    "    vol_risk = (row[\"jaccard_topk_mean\"] <= VOL_JACC_THRESH) or (\n",
    "        (not pd.isna(row[\"spearman_mean\"])) and (row[\"spearman_mean\"] <= VOL_SPEAR_THRESH)\n",
    "    )\n",
    "    if tie_risk and vol_risk:\n",
    "        return \"HIGH\"\n",
    "    if tie_risk or vol_risk:\n",
    "        return \"MED\"\n",
    "    return \"LOW\"\n",
    "\n",
    "summary_df[\"risk\"] = summary_df.apply(risk_label, axis=1)\n",
    "\n",
    "# Stable sort for readability\n",
    "summary_df = summary_df.sort_values(\n",
    "    [\"risk\", \"pct_items_in_ties\", \"jaccard_topk_mean\"],\n",
    "    ascending=[True, False, True]\n",
    ")\n",
    "\n",
    "summary_out = REPORTS_DIR / \"notebook08_section01_segment_instability_summary.csv\"\n",
    "summary_df.to_csv(summary_out, index=False)\n",
    "print(\"Saved:\", summary_out)\n",
    "\n",
    "display(summary_df)\n",
    "\n",
    "# -----------------------------\n",
    "# Build human-readable markdown report\n",
    "# -----------------------------\n",
    "def pct(x: float) -> str:\n",
    "    return f\"{100*x:.1f}%\"\n",
    "\n",
    "lines = []\n",
    "lines.append(\"# Notebook 08 — Section 01 Failure Mode Report\\n\")\n",
    "lines.append(f\"- Run timestamp (UTC): `{RUN_TS}`\")\n",
    "lines.append(f\"- Top-K analyzed: `{TOPK}`\")\n",
    "lines.append(f\"- Segments analyzed: `{', '.join(SEG_KEYS)}`\\n\")\n",
    "\n",
    "lines.append(\"## Headline Findings\\n\")\n",
    "\n",
    "# Identify highest tie density segments\n",
    "tie_rank = summary_df.sort_values([\"pct_items_in_ties\", \"max_tie_group\"], ascending=False)\n",
    "top_tie = tie_rank.head(2)\n",
    "\n",
    "lines.append(\"### Tie Density (Top-K)\\n\")\n",
    "for _, r in top_tie.iterrows():\n",
    "    lines.append(\n",
    "        f\"- **{r['segment']}**: items-in-ties={pct(r['pct_items_in_ties'])}, \"\n",
    "        f\"max_tie_group={int(r['max_tie_group'])}, unique_scores={int(r['n_unique_scores'])}/{int(r['topk'])}\"\n",
    "    )\n",
    "\n",
    "# Volatility\n",
    "vol_rank = summary_df.sort_values([\"jaccard_topk_mean\", \"spearman_mean\"], ascending=True)\n",
    "most_fragile = vol_rank.head(2)\n",
    "\n",
    "lines.append(\"\\n### Rank Volatility (±2% weight noise)\\n\")\n",
    "for _, r in most_fragile.iterrows():\n",
    "    lines.append(\n",
    "        f\"- **{r['segment']}**: jaccard_mean={r['jaccard_topk_mean']:.3f}, spearman_mean={r['spearman_mean']:.3f}\"\n",
    "    )\n",
    "\n",
    "lines.append(\"\\n## Interpretation\\n\")\n",
    "lines.append(\n",
    "    \"- Rankings are **highly stable** under small weight perturbations (low brittleness risk).\\n\"\n",
    "    \"- The launch-critical issue is **tie density**, especially in certain segments.\\n\"\n",
    "    \"- Section 02 will introduce deterministic tie-breakers and calibration tweaks without ML authority.\"\n",
    ")\n",
    "\n",
    "lines.append(\"\\n## Artifacts (Saved to /reports)\\n\")\n",
    "lines.append(f\"- Tie density: `{tie_out.name}`\")\n",
    "lines.append(f\"- Rank volatility: `{vol_out.name}`\")\n",
    "lines.append(f\"- Tier dominance (original): `notebook08_section01_tier_dominance_by_segment.csv`\")\n",
    "lines.append(f\"- Tier dominance (baseline patch): `notebook08_section01_tier_dominance_by_segment_v2.csv`\")\n",
    "lines.append(f\"- Segment instability summary: `{summary_out.name}`\\n\")\n",
    "\n",
    "lines.append(\"## Risk Table (Summary)\\n\")\n",
    "lines.append(summary_df[[\"segment\", \"risk\", \"pct_items_in_ties\", \"max_tie_group\", \"jaccard_topk_mean\", \"spearman_mean\"]]\n",
    "             .to_markdown(index=False))\n",
    "\n",
    "report_out = REPORTS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ada373e-bc9c-4739-a857-98c3352cb80c",
   "metadata": {},
   "source": [
    "## 02.0 Tie-Breaker Policy (Deterministic Completion) \n",
    "\n",
    "This section defines the **explicit, deterministic tie-breaker policy** used to\n",
    "complete rankings when multiple schools receive the same primary segment score.\n",
    "\n",
    "The goal is **not to change what matters**, but to **finish the ordering**\n",
    "in a way that is stable, explainable, and safe for launch.\n",
    "\n",
    "---\n",
    "\n",
    "## Why a Tie-Breaker Policy Is Required\n",
    "\n",
    "Section 01 showed that:\n",
    "\n",
    "- Rankings are **stable** (low volatility)\n",
    "- But many segments produce **large tie groups**\n",
    "- Users would see dozens of schools listed as “equal”\n",
    "\n",
    "This creates confusion and undermines trust, even when the scoring logic is correct.\n",
    "\n",
    "A tie-breaker policy **completes** the ranking without changing its intent.\n",
    "\n",
    "---\n",
    "\n",
    "## Design Principles (Non-Negotiable)\n",
    "\n",
    "The tie-breaker must be:\n",
    "\n",
    "- ✅ **Deterministic**  \n",
    "  Same inputs always produce the same order\n",
    "- ✅ **Explainable in plain language**\n",
    "- ✅ **Numerically tiny**  \n",
    "  Cannot override the primary score\n",
    "- ✅ **Segment-agnostic**  \n",
    "  Does not favor any pedagogy or tier\n",
    "- ✅ **Safe under version changes**\n",
    "- ❌ **Not random**\n",
    "- ❌ **Not learned**\n",
    "- ❌ **Not outcome-driven**\n",
    "\n",
    "---\n",
    "\n",
    "## Tie-Breaker Chain (Authoritative)\n",
    "\n",
    "When two schools have the same **primary segment score**, ordering is resolved\n",
    "using the following steps, in order:\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1 — Primary Segment Score (Baseline)\n",
    "\n",
    "The existing deterministic score from Notebook 07:\n",
    "\n",
    "\\[\n",
    "score_{primary} = X \\cdot w_{segment}\n",
    "\\]\n",
    "\n",
    "This remains the **dominant signal** and is never overridden.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2 — Data Completeness Bonus (Tiny, Deterministic)\n",
    "\n",
    "If primary scores are equal, apply a **small deterministic bonus**\n",
    "based on how much information is available for the school.\n",
    "\n",
    "**Conceptual rule (human explanation):**\n",
    "\n",
    "> “If two schools score the same, we slightly prefer the one where we have\n",
    "> more contributing information.”\n",
    "\n",
    "**Implementation rule (numeric):**\n",
    "\n",
    "\\[\n",
    "bonus_{data} = \\epsilon \\times (\\text{count of contributing features})\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- `count of contributing features` = number of non-zero feature values\n",
    "- \\(\\epsilon\\) is very small (e.g., `0.0001`)\n",
    "\n",
    "**Important properties:**\n",
    "- Too small to change Top-K membership\n",
    "- Too small to override tier logic\n",
    "- Large enough to break perfect ties\n",
    "- Fully deterministic\n",
    "\n",
    "This bonus exists **only to complete ordering**, not to improve quality.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3 — Stable ID Fallback (Final Determinism)\n",
    "\n",
    "If schools are still tied after Steps 1 and 2:\n",
    "\n",
    "- Order by a stable identifier (e.g., `school_id`, `comkey`) in ascending order\n",
    "\n",
    "**Rationale:**\n",
    "- Honest acknowledgment of true equivalence\n",
    "- Guarantees a total ordering\n",
    "- Prevents silent randomness\n",
    "\n",
    "---\n",
    "\n",
    "## Explicitly Excluded from Tie-Breaking\n",
    "\n",
    "The following are **not allowed** as tie-breakers:\n",
    "\n",
    "- Tier tags (`IB`, `CAIS`, `Waldorf`, `Montessori`)\n",
    "- Rare binary indicators\n",
    "- Random or seeded randomness\n",
    "- Learned re-ranking models\n",
    "- User behavior signals\n",
    "\n",
    "These remain part of **primary scoring only** (where applicable).\n",
    "\n",
    "---\n",
    "\n",
    "## User-Facing Explanation (Approved)\n",
    "\n",
    "If asked why one school appears above another:\n",
    "\n",
    "> “They scored the same on what you care about.  \n",
    "> When that happens, we slightly prefer schools where we have more complete\n",
    "> information, and if they’re still equal, we use a stable ordering so the\n",
    "> results don’t jump around.”\n",
    "\n",
    "This explanation is:\n",
    "- truthful\n",
    "- simple\n",
    "- consistent across segments\n",
    "\n",
    "---\n",
    "\n",
    "## Outcome of This Policy\n",
    "\n",
    "After applying this policy:\n",
    "\n",
    "- Rankings remain **deterministic**\n",
    "- Large tie blocks collapse into stable orderings\n",
    "- User trust improves\n",
    "- No ML authority is introduced\n",
    "\n",
    "This policy enables safe launch without compromising system integrity.\n",
    "\n",
    "---\n",
    "\n",
    "> Section 01 diagnosed the problem.  \n",
    "> Section 02 completes the decision — explicitly and safely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "18e5969f-ffbf-4897-b55e-c4368b539b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tie-breaker policy:\n",
      "TieBreakerPolicy(policy_version='tb_v1', epsilon=0.0001, count_mode='nonzero_features', stable_id_col='school_id', use_dense_secondary=False, dense_secondary_cols=[])\n",
      "\n",
      "Contributing-feature count stats:\n",
      "count    124619.000000\n",
      "mean          4.341328\n",
      "std           0.879029\n",
      "min           2.000000\n",
      "25%           4.000000\n",
      "50%           4.000000\n",
      "75%           5.000000\n",
      "max           8.000000\n",
      "dtype: float64\n",
      "\n",
      "Bonus range:\n",
      "min_bonus=0.000200  max_bonus=0.000800\n",
      "\n",
      "Reference primary score scale:\n",
      "segment='balanced_general' score_range=[0.535, 5.229]\n",
      "max_bonus / score_range ≈ 0.000170\n",
      "\n",
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/tie_breaker_policy_tb_v1.json\n",
      "Updated manifest: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/run_manifest_v1.json\n"
     ]
    }
   ],
   "source": [
    "# 02.0 Tie-Breaker Policy (Deterministic Completion) \n",
    "#\n",
    "# This cell:\n",
    "# - Encodes the tie-breaker policy as config + small helper functions\n",
    "# - Does NOT modify primary scoring logic\n",
    "# - Produces no rankings yet (that happens in 02.1)\n",
    "# - Persists the policy to a versioned JSON artifact and updates the run manifest\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Policy definition\n",
    "# -----------------------------\n",
    "@dataclass(frozen=True)\n",
    "class TieBreakerPolicy:\n",
    "    policy_version: str\n",
    "    epsilon: float                  # tiny bonus multiplier\n",
    "    count_mode: str                 # \"nonzero_features\" (for now)\n",
    "    stable_id_col: str              # e.g., \"school_id\" or \"comkey\"\n",
    "    use_dense_secondary: bool       # reserved (false for now; may enable later)\n",
    "    dense_secondary_cols: List[str] # reserved (empty for now)\n",
    "\n",
    "POLICY = TieBreakerPolicy(\n",
    "    policy_version=\"tb_v1\",\n",
    "    epsilon=1e-4,  # 0.0001\n",
    "    count_mode=\"nonzero_features\",\n",
    "    stable_id_col=school_id_col,    # inferred in 01.1 from index_df\n",
    "    use_dense_secondary=False,\n",
    "    dense_secondary_cols=[],\n",
    ")\n",
    "\n",
    "print(\"Tie-breaker policy:\")\n",
    "print(POLICY)\n",
    "\n",
    "# -----------------------------\n",
    "# Helper: data completeness / contributing feature count\n",
    "# -----------------------------\n",
    "def contributing_feature_count(X: np.ndarray, mode: str = \"nonzero_features\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns an integer array of length n_schools.\n",
    "    For v2, X is mostly binary/dense scores, so \"nonzero_features\" is a reasonable proxy\n",
    "    for 'how many signals contributed' to the school representation.\n",
    "\n",
    "    NOTE: This is used ONLY as a tiny tie-breaker bonus, never as a primary ranking driver.\n",
    "    \"\"\"\n",
    "    if mode == \"nonzero_features\":\n",
    "        # Treat any non-zero value as \"contributes\"\n",
    "        return (X != 0).sum(axis=1).astype(int)\n",
    "    raise ValueError(f\"Unknown count_mode: {mode}\")\n",
    "\n",
    "# Precompute once for efficiency (used later in 02.1)\n",
    "contrib_count = contributing_feature_count(X, POLICY.count_mode)\n",
    "contrib_bonus = POLICY.epsilon * contrib_count\n",
    "\n",
    "print(\"\\nContributing-feature count stats:\")\n",
    "print(pd.Series(contrib_count).describe())\n",
    "\n",
    "print(\"\\nBonus range:\")\n",
    "print(f\"min_bonus={contrib_bonus.min():.6f}  max_bonus={contrib_bonus.max():.6f}\")\n",
    "\n",
    "# Sanity: ensure bonus is tiny relative to primary score magnitudes\n",
    "# (We use one segment as reference.)\n",
    "ref_seg = \"balanced_general\" if \"balanced_general\" in baseline else SEG_KEYS[0]\n",
    "ref_scores = baseline[ref_seg][\"scores\"]\n",
    "print(\"\\nReference primary score scale:\")\n",
    "print(f\"segment='{ref_seg}' score_range=[{ref_scores.min():.3f}, {ref_scores.max():.3f}]\")\n",
    "print(f\"max_bonus / score_range ≈ {contrib_bonus.max() / max(1e-9, (ref_scores.max()-ref_scores.min())):.6f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Persist policy artifact\n",
    "# -----------------------------\n",
    "policy_out = ARTIFACTS_DIR / \"tie_breaker_policy_tb_v1.json\"\n",
    "policy_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(policy_out, \"w\") as f:\n",
    "    json.dump(asdict(POLICY), f, indent=2)\n",
    "\n",
    "print(\"\\nSaved:\", policy_out)\n",
    "\n",
    "# -----------------------------\n",
    "# Update run manifest\n",
    "# -----------------------------\n",
    "manifest_path = ARTIFACTS_DIR / f\"run_manifest_{SYSTEM_VERSION}.json\"\n",
    "m = load_json(manifest_path)\n",
    "m.setdefault(\"inputs\", {})\n",
    "m.setdefault(\"outputs\", {})\n",
    "\n",
    "m[\"inputs\"].update({\n",
    "    \"inputs.section02.tie_breaker_policy_version\": POLICY.policy_version,\n",
    "    \"inputs.section02.tie_breaker_epsilon\": POLICY.epsilon,\n",
    "    \"inputs.section02.tie_breaker_count_mode\": POLICY.count_mode,\n",
    "    \"inputs.section02.tie_breaker_stable_id_col\": POLICY.stable_id_col,\n",
    "})\n",
    "\n",
    "m[\"outputs\"].update({\n",
    "    \"artifacts.section02.tie_breaker_policy_json\": str(policy_out),\n",
    "})\n",
    "\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(m, f, indent=2)\n",
    "\n",
    "print(\"Updated manifest:\", manifest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8806a5d-f620-4430-8ef8-653dd40afdf9",
   "metadata": {},
   "source": [
    "## 02.1 Implement `stable_rank()` + Verify Tie Reduction \n",
    "\n",
    "This step implements the **deterministic tie-breaker chain** defined in 02.0 and\n",
    "applies it to produce a **total ordering** (no ambiguous tie blocks) per segment.\n",
    "\n",
    "We then verify that:\n",
    "\n",
    "- The **Top-K membership** remains essentially unchanged (guardrail)\n",
    "- The **tie density** within Top-K is dramatically reduced (goal)\n",
    "- Ordering is fully deterministic using a stable ID fallback\n",
    "\n",
    "---\n",
    "\n",
    "## Tie-Breaker Chain (Applied)\n",
    "\n",
    "For each segment, schools are ranked by:\n",
    "\n",
    "1. **Primary segment score** (DESC)\n",
    "2. **Data completeness bonus** (DESC)  \n",
    "   - `bonus = epsilon × contributing_feature_count`\n",
    "3. **Stable ID** (ASC)  \n",
    "   - e.g., `school_id` (final deterministic fallback)\n",
    "\n",
    "This preserves the system’s intent while completing the ordering.\n",
    "\n",
    "---\n",
    "\n",
    "## Guardrails\n",
    "\n",
    "- ✅ Primary score remains dominant\n",
    "- ✅ Bonus is numerically tiny (tie-breaking only)\n",
    "- ✅ Tier logic is not overridden\n",
    "- ✅ Ranking is stable and repeatable\n",
    "- ✅ Outputs are saved and versioned\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs / Artifacts\n",
    "\n",
    "- `/reports/notebook08_section02_tie_density_after_tiebreak.csv`\n",
    "- `/reports/notebook08_section02_topk_overlap_guardrail.csv`\n",
    "\n",
    "These artifacts are referenced in the run manifest.\n",
    "\n",
    "---\n",
    "\n",
    "> Section 02 does not “learn” a better ranking.  \n",
    "> It deterministically finishes the ranking where the primary score is equal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "95031445-2e35-4283-a359-0771eeb7653f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section02_tie_density_after_tiebreak.csv\n",
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section02_topk_overlap_guardrail.csv\n",
      "\n",
      "Tie density BEFORE vs AFTER (Top-K):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>topk</th>\n",
       "      <th>before_pct_items_in_ties</th>\n",
       "      <th>after_pct_items_in_ties</th>\n",
       "      <th>before_max_tie_group</th>\n",
       "      <th>after_max_tie_group</th>\n",
       "      <th>before_unique_scores</th>\n",
       "      <th>after_unique_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>500</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.926</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>500</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.916</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balanced_general</td>\n",
       "      <td>500</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.504</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first</td>\n",
       "      <td>500</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.406</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                segment  topk  before_pct_items_in_ties  \\\n",
       "1       small_nurturing   500                     0.926   \n",
       "2  progressive_balanced   500                     0.916   \n",
       "3      balanced_general   500                     0.504   \n",
       "0        academic_first   500                     0.406   \n",
       "\n",
       "   after_pct_items_in_ties  before_max_tie_group  after_max_tie_group  \\\n",
       "1                    0.926                    57                   57   \n",
       "2                    0.916                    68                   68   \n",
       "3                    0.504                    12                   12   \n",
       "0                    0.406                    20                   20   \n",
       "\n",
       "   before_unique_scores  after_unique_scores  \n",
       "1                    83                   83  \n",
       "2                    86                   86  \n",
       "3                   326                  326  \n",
       "0                   343                  343  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-K membership overlap guardrail (Jaccard):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>topk</th>\n",
       "      <th>topk_jaccard_membership</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balanced_general</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                segment  topk  topk_jaccard_membership\n",
       "0        academic_first   500                      1.0\n",
       "1       small_nurturing   500                      1.0\n",
       "2  progressive_balanced   500                      1.0\n",
       "3      balanced_general   500                      1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated manifest: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/run_manifest_v1.json\n"
     ]
    }
   ],
   "source": [
    "# 02.1 Implement stable_rank() + Verify Tie Reduction \n",
    "\n",
    "# -----------------------------\n",
    "# Stable rank implementation\n",
    "# -----------------------------\n",
    "stable_id_series = pd.Series(\n",
    "    [row_to_school_id.get(int(r), f\"ROW_{r}\") for r in range(X.shape[0])],\n",
    "    name=POLICY.stable_id_col\n",
    ")\n",
    "\n",
    "def stable_rank(scores: np.ndarray, bonus: np.ndarray, stable_ids: pd.Series) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns row indices sorted by:\n",
    "      1) scores DESC\n",
    "      2) bonus DESC\n",
    "      3) stable_id ASC\n",
    "    \"\"\"\n",
    "    # Convert stable_ids to numpy array of strings for lexsort\n",
    "    sid = stable_ids.astype(str).to_numpy()\n",
    "\n",
    "    # np.lexsort uses last key as primary; we want:\n",
    "    # primary: -scores, secondary: -bonus, tertiary: sid\n",
    "    return np.lexsort((sid, -bonus, -scores))\n",
    "\n",
    "# -----------------------------\n",
    "# Apply to each segment\n",
    "# -----------------------------\n",
    "TOPK_CHECK = TOPK  # reuse TopK (500)\n",
    "\n",
    "def tie_metrics_for_scores(scores: np.ndarray, order: np.ndarray, topk: int) -> dict:\n",
    "    top_idx = order[:topk]\n",
    "    top_scores = scores[top_idx]\n",
    "    vc = pd.Series(top_scores).value_counts()\n",
    "    return {\n",
    "        \"topk\": int(topk),\n",
    "        \"n_unique_scores\": int(len(vc)),\n",
    "        \"n_tie_groups\": int((vc > 1).sum()),\n",
    "        \"max_tie_group\": int(vc.max()) if len(vc) else 0,\n",
    "        \"pct_items_in_ties\": float((vc[vc > 1].sum() / topk) if topk else 0.0),\n",
    "    }\n",
    "\n",
    "def overlap_jaccard(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    sa, sb = set(a.tolist()), set(b.tolist())\n",
    "    return len(sa & sb) / len(sa | sb) if (sa | sb) else 1.0\n",
    "\n",
    "after_rows = []\n",
    "overlap_rows = []\n",
    "\n",
    "for seg in SEG_KEYS:\n",
    "    scores = baseline[seg][\"scores\"]\n",
    "    base_order = baseline[seg][\"order\"]\n",
    "\n",
    "    # apply tie-breaker ordering\n",
    "    order_tb = stable_rank(scores, contrib_bonus, stable_id_series)\n",
    "\n",
    "    # tie metrics are computed on PRIMARY score only (ties refer to equal primary score)\n",
    "    base_tie = tie_metrics_for_scores(scores, base_order, TOPK_CHECK)\n",
    "    after_tie = tie_metrics_for_scores(scores, order_tb, TOPK_CHECK)\n",
    "\n",
    "    after_rows.append({\n",
    "        \"segment\": seg,\n",
    "        \"topk\": TOPK_CHECK,\n",
    "        \"before_pct_items_in_ties\": base_tie[\"pct_items_in_ties\"],\n",
    "        \"after_pct_items_in_ties\": after_tie[\"pct_items_in_ties\"],\n",
    "        \"before_max_tie_group\": base_tie[\"max_tie_group\"],\n",
    "        \"after_max_tie_group\": after_tie[\"max_tie_group\"],\n",
    "        \"before_unique_scores\": base_tie[\"n_unique_scores\"],\n",
    "        \"after_unique_scores\": after_tie[\"n_unique_scores\"],\n",
    "    })\n",
    "\n",
    "    # Guardrail: Top-K membership should be nearly unchanged\n",
    "    j = overlap_jaccard(base_order[:TOPK_CHECK], order_tb[:TOPK_CHECK])\n",
    "    overlap_rows.append({\n",
    "        \"segment\": seg,\n",
    "        \"topk\": TOPK_CHECK,\n",
    "        \"topk_jaccard_membership\": j,\n",
    "    })\n",
    "\n",
    "    # store for later sections\n",
    "    baseline[seg][\"order_tb_v1\"] = order_tb\n",
    "\n",
    "after_df = pd.DataFrame(after_rows)\n",
    "overlap_df = pd.DataFrame(overlap_rows)\n",
    "\n",
    "# -----------------------------\n",
    "# Save artifacts\n",
    "# -----------------------------\n",
    "tie_after_out = REPORTS_DIR / \"notebook08_section02_tie_density_after_tiebreak.csv\"\n",
    "overlap_out = REPORTS_DIR / \"notebook08_section02_topk_overlap_guardrail.csv\"\n",
    "\n",
    "after_df.to_csv(tie_after_out, index=False)\n",
    "overlap_df.to_csv(overlap_out, index=False)\n",
    "\n",
    "print(\"Saved:\", tie_after_out)\n",
    "print(\"Saved:\", overlap_out)\n",
    "\n",
    "print(\"\\nTie density BEFORE vs AFTER (Top-K):\")\n",
    "display(after_df.sort_values(\"after_pct_items_in_ties\", ascending=False))\n",
    "\n",
    "print(\"\\nTop-K membership overlap guardrail (Jaccard):\")\n",
    "display(overlap_df.sort_values(\"topk_jaccard_membership\"))\n",
    "\n",
    "# -----------------------------\n",
    "# Update run manifest\n",
    "# -----------------------------\n",
    "manifest_path = ARTIFACTS_DIR / f\"run_manifest_{SYSTEM_VERSION}.json\"\n",
    "m = load_json(manifest_path)\n",
    "m.setdefault(\"outputs\", {})\n",
    "m[\"outputs\"].update({\n",
    "    \"reports.section02.tie_density_after_tiebreak\": str(tie_after_out),\n",
    "    \"reports.section02.topk_overlap_guardrail\": str(overlap_out),\n",
    "})\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(m, f, indent=2)\n",
    "\n",
    "print(\"Updated manifest:\", manifest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "17e037ab-008a-41e6-9d06-d9e8d2465adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>topk</th>\n",
       "      <th>primary_pct_tied</th>\n",
       "      <th>primary_max_tie</th>\n",
       "      <th>composite_pct_tied</th>\n",
       "      <th>composite_max_tie</th>\n",
       "      <th>composite_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>500</td>\n",
       "      <td>0.926</td>\n",
       "      <td>57</td>\n",
       "      <td>0.866</td>\n",
       "      <td>55</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>500</td>\n",
       "      <td>0.916</td>\n",
       "      <td>68</td>\n",
       "      <td>0.842</td>\n",
       "      <td>60</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balanced_general</td>\n",
       "      <td>500</td>\n",
       "      <td>0.504</td>\n",
       "      <td>12</td>\n",
       "      <td>0.504</td>\n",
       "      <td>12</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first</td>\n",
       "      <td>500</td>\n",
       "      <td>0.406</td>\n",
       "      <td>20</td>\n",
       "      <td>0.346</td>\n",
       "      <td>16</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                segment  topk  primary_pct_tied  primary_max_tie  \\\n",
       "1       small_nurturing   500             0.926               57   \n",
       "2  progressive_balanced   500             0.916               68   \n",
       "3      balanced_general   500             0.504               12   \n",
       "0        academic_first   500             0.406               20   \n",
       "\n",
       "   composite_pct_tied  composite_max_tie  composite_unique  \n",
       "1               0.866                 55               116  \n",
       "2               0.842                 60               130  \n",
       "3               0.504                 12               326  \n",
       "0               0.346                 16               374  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 02.1b Verify tie-breaking using COMPOSITE score \n",
    "# composite_score = primary_score + tiny data bonus\n",
    "# This should show ties collapsing even though primary-score tie density stays the same.\n",
    "\n",
    "def tie_metrics(values: np.ndarray, order: np.ndarray, topk: int) -> dict:\n",
    "    top_idx = order[:topk]\n",
    "    top_vals = values[top_idx]\n",
    "    vc = pd.Series(top_vals).value_counts()\n",
    "    return {\n",
    "        \"topk\": int(topk),\n",
    "        \"n_unique\": int(len(vc)),\n",
    "        \"n_tie_groups\": int((vc > 1).sum()),\n",
    "        \"max_tie_group\": int(vc.max()) if len(vc) else 0,\n",
    "        \"pct_items_in_ties\": float((vc[vc > 1].sum() / topk) if topk else 0.0),\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "for seg in SEG_KEYS:\n",
    "    primary = baseline[seg][\"scores\"]\n",
    "    order_tb = baseline[seg][\"order_tb_v1\"]\n",
    "\n",
    "    composite = primary + contrib_bonus  # tiny tie-break bonus\n",
    "\n",
    "    primary_m = tie_metrics(primary, order_tb, TOPK)\n",
    "    composite_m = tie_metrics(composite, order_tb, TOPK)\n",
    "\n",
    "    rows.append({\n",
    "        \"segment\": seg,\n",
    "        \"topk\": TOPK,\n",
    "        \"primary_pct_tied\": primary_m[\"pct_items_in_ties\"],\n",
    "        \"primary_max_tie\": primary_m[\"max_tie_group\"],\n",
    "        \"composite_pct_tied\": composite_m[\"pct_items_in_ties\"],\n",
    "        \"composite_max_tie\": composite_m[\"max_tie_group\"],\n",
    "        \"composite_unique\": composite_m[\"n_unique\"],\n",
    "    })\n",
    "\n",
    "verify_df = pd.DataFrame(rows).sort_values(\"composite_pct_tied\", ascending=False)\n",
    "display(verify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7824f93-27fa-4712-893b-5e3ff264bd16",
   "metadata": {},
   "source": [
    "## 02.2 Lexicographic Tie-Break Ranking (Per-Segment Secondary Keys) \n",
    "\n",
    "Section 02.1 proved that a tiny “data completeness bonus” alone is too coarse to\n",
    "break ties at the scale observed in Section 01.\n",
    "\n",
    "This step upgrades the launch ranking to use a **lexicographic tie-break chain**:\n",
    "we keep the **primary segment score** unchanged, but complete the ordering using\n",
    "additional deterministic keys.\n",
    "\n",
    "---\n",
    "\n",
    "## Core Idea (Plain Language)\n",
    "\n",
    "> “Rank by the main segment score first.  \n",
    "> If schools are tied, look at a secondary dense signal.  \n",
    "> If still tied, prefer richer data.  \n",
    "> If still tied, fall back to a stable ID so results never shuffle.”\n",
    "\n",
    "This produces a fully deterministic and explainable total ordering.\n",
    "\n",
    "---\n",
    "\n",
    "## Lexicographic Tie-Break Chain (Authoritative)\n",
    "\n",
    "For each segment we rank schools by:\n",
    "\n",
    "1. **Primary score** (DESC)  \n",
    "   - segment’s deterministic score from Notebook 07\n",
    "2. **Secondary dense signal** (DESC), segment-specific  \n",
    "   - chosen to introduce variance without changing meaning\n",
    "3. **Contributing feature count** (DESC)  \n",
    "   - prefers richer coverage; tiny but deterministic\n",
    "4. **Stable ID** (ASC)  \n",
    "   - final deterministic fallback\n",
    "\n",
    "---\n",
    "\n",
    "## Segment-Specific Secondary Keys (v1)\n",
    "\n",
    "We only add secondary keys where they are aligned to segment intent:\n",
    "\n",
    "- `small_nurturing` → `score_size_small` (and/or `score_attention` if available)\n",
    "- `progressive_balanced` → `score_diversity` (or `score_progressive` if available)\n",
    "- `balanced_general` → no segment-specific secondary key (keeps neutrality)\n",
    "- `academic_first` → no secondary key that could override tier intent (keeps purity)\n",
    "\n",
    "If a requested secondary feature is not present in `feature_names`, we skip it\n",
    "and log a warning (no silent failure in production).\n",
    "\n",
    "---\n",
    "\n",
    "## Guardrails\n",
    "\n",
    "- ✅ Primary score remains the dominant signal (no numeric modification)\n",
    "- ✅ No learning\n",
    "- ✅ Deterministic across runs\n",
    "- ✅ Top-K membership must remain ≥ 0.98 Jaccard vs baseline (safety)\n",
    "- ✅ Rankings must be fully ordered (no unresolved ties after stable ID)\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs / Artifacts\n",
    "\n",
    "- `/reports/notebook08_section02_lex_tiebreak_effect.csv`\n",
    "- `/reports/notebook08_section02_topk_overlap_guardrail_v2.csv`\n",
    "\n",
    "These are referenced in the run manifest.\n",
    "\n",
    "---\n",
    "\n",
    "> This is “learning as consultant” philosophy applied to ranking:\n",
    "> we add structure and stability, not opaque authority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2a96e60f-508d-487c-aa31-3a3a7fb08d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secondary keys by segment (present in matrix):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>secondary_keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>[score_size_small, score_attention]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>[score_diversity, score_size_small]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balanced_general</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                segment                       secondary_keys\n",
       "0        academic_first                                   []\n",
       "1       small_nurturing  [score_size_small, score_attention]\n",
       "2  progressive_balanced  [score_diversity, score_size_small]\n",
       "3      balanced_general                                   []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section02_lex_tiebreak_effect.csv\n",
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section02_topk_overlap_guardrail_v2.csv\n",
      "\n",
      "Lex tie-break effect summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>topk</th>\n",
       "      <th>secondary_keys_used</th>\n",
       "      <th>topk_jaccard_membership</th>\n",
       "      <th>adjacent_primary_ties_before</th>\n",
       "      <th>adjacent_primary_ties_after</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first</td>\n",
       "      <td>500</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>Primary-score tie counts may remain; ordering ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>500</td>\n",
       "      <td>score_size_small,score_attention</td>\n",
       "      <td>1.0</td>\n",
       "      <td>417</td>\n",
       "      <td>417</td>\n",
       "      <td>Primary-score tie counts may remain; ordering ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>500</td>\n",
       "      <td>score_diversity,score_size_small</td>\n",
       "      <td>1.0</td>\n",
       "      <td>414</td>\n",
       "      <td>414</td>\n",
       "      <td>Primary-score tie counts may remain; ordering ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balanced_general</td>\n",
       "      <td>500</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>Primary-score tie counts may remain; ordering ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                segment  topk               secondary_keys_used  \\\n",
       "0        academic_first   500                                     \n",
       "1       small_nurturing   500  score_size_small,score_attention   \n",
       "2  progressive_balanced   500  score_diversity,score_size_small   \n",
       "3      balanced_general   500                                     \n",
       "\n",
       "   topk_jaccard_membership  adjacent_primary_ties_before  \\\n",
       "0                      1.0                           157   \n",
       "1                      1.0                           417   \n",
       "2                      1.0                           414   \n",
       "3                      1.0                           174   \n",
       "\n",
       "   adjacent_primary_ties_after  \\\n",
       "0                          157   \n",
       "1                          417   \n",
       "2                          414   \n",
       "3                          174   \n",
       "\n",
       "                                                note  \n",
       "0  Primary-score tie counts may remain; ordering ...  \n",
       "1  Primary-score tie counts may remain; ordering ...  \n",
       "2  Primary-score tie counts may remain; ordering ...  \n",
       "3  Primary-score tie counts may remain; ordering ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-K membership overlap guardrail (Jaccard):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>topk</th>\n",
       "      <th>topk_jaccard_membership</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balanced_general</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                segment  topk  topk_jaccard_membership\n",
       "0        academic_first   500                      1.0\n",
       "1       small_nurturing   500                      1.0\n",
       "2  progressive_balanced   500                      1.0\n",
       "3      balanced_general   500                      1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated manifest: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/run_manifest_v1.json\n"
     ]
    }
   ],
   "source": [
    "# 02.2 Lexicographic Tie-Break Ranking (Per-Segment Secondary Keys)  \n",
    "\n",
    "# -----------------------------\n",
    "# 1) Define per-segment secondary key policy (v1)\n",
    "# -----------------------------\n",
    "# NOTE: We only reference features that exist in feature_names.\n",
    "# We will fail loud if the config references missing features.\n",
    "SECONDARY_KEY_PREFS = {\n",
    "    \"small_nurturing\": [\"score_size_small\", \"score_attention\"],\n",
    "    \"progressive_balanced\": [\"score_diversity\", \"score_size_small\"],\n",
    "    \"balanced_general\": [],      # neutral: don't inject philosophy bias\n",
    "    \"academic_first\": [],        # keep primary intent dominant and clean\n",
    "}\n",
    "\n",
    "def present_features(candidates):\n",
    "    return [f for f in candidates if f in feat_to_idx]\n",
    "\n",
    "secondary_keys = {seg: present_features(SECONDARY_KEY_PREFS.get(seg, [])) for seg in SEG_KEYS}\n",
    "\n",
    "print(\"Secondary keys by segment (present in matrix):\")\n",
    "display(pd.DataFrame([\n",
    "    {\"segment\": seg, \"secondary_keys\": secondary_keys[seg]} for seg in SEG_KEYS\n",
    "]))\n",
    "\n",
    "# If you want strict mode (recommended for production), enforce that requested keys exist:\n",
    "STRICT = False\n",
    "if STRICT:\n",
    "    for seg, req in SECONDARY_KEY_PREFS.items():\n",
    "        missing = [f for f in req if f not in feat_to_idx]\n",
    "        if missing:\n",
    "            raise KeyError(f\"Segment '{seg}' requested secondary keys not in feature_names: {missing}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Implement lexicographic ranker\n",
    "# -----------------------------\n",
    "stable_id_arr = stable_id_series.astype(str).to_numpy()\n",
    "\n",
    "def lex_rank(scores: np.ndarray,\n",
    "             stable_ids: np.ndarray,\n",
    "             contrib_count: np.ndarray,\n",
    "             secondary_vals: list[np.ndarray] | None = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Sort by:\n",
    "      1) scores DESC\n",
    "      2) each secondary_vals[i] DESC (in order provided)\n",
    "      3) contrib_count DESC\n",
    "      4) stable_id ASC\n",
    "    \"\"\"\n",
    "    keys = [stable_ids]  # last key (primary in lexsort call) is stable_id ASC\n",
    "    keys.append(-contrib_count)  # contrib DESC\n",
    "\n",
    "    # Secondary keys (DESC). Added in reverse because lexsort last key is primary.\n",
    "    if secondary_vals:\n",
    "        for v in reversed(secondary_vals):\n",
    "            keys.append(-v)\n",
    "\n",
    "    # Primary scores DESC (most important)\n",
    "    keys.append(-scores)\n",
    "\n",
    "    return np.lexsort(tuple(keys))\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Apply per segment + verify effects\n",
    "# -----------------------------\n",
    "def overlap_jaccard(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    sa, sb = set(a.tolist()), set(b.tolist())\n",
    "    return len(sa & sb) / len(sa | sb) if (sa | sb) else 1.0\n",
    "\n",
    "def unresolved_ties_count(scores: np.ndarray, order: np.ndarray, topk: int) -> int:\n",
    "    \"\"\"\n",
    "    Counts how many adjacent pairs in Top-K have equal primary score.\n",
    "    (This doesn't mean ordering is undefined; it just quantifies remaining primary-score ties.)\n",
    "    \"\"\"\n",
    "    top = order[:topk]\n",
    "    s = scores[top]\n",
    "    return int((s[1:] == s[:-1]).sum())\n",
    "\n",
    "rows = []\n",
    "overlap_rows = []\n",
    "\n",
    "for seg in SEG_KEYS:\n",
    "    scores = baseline[seg][\"scores\"]\n",
    "    base_order = baseline[seg][\"order\"]\n",
    "\n",
    "    # build secondary value arrays for this segment\n",
    "    sec_feats = secondary_keys.get(seg, [])\n",
    "    sec_vals = [X[:, feat_to_idx[f]].astype(float) for f in sec_feats] if sec_feats else []\n",
    "\n",
    "    order_lex = lex_rank(\n",
    "        scores=scores,\n",
    "        stable_ids=stable_id_arr,\n",
    "        contrib_count=contrib_count,\n",
    "        secondary_vals=sec_vals\n",
    "    )\n",
    "\n",
    "    # store for downstream sections\n",
    "    baseline[seg][\"order_lex_v1\"] = order_lex\n",
    "\n",
    "    # Guardrail: Top-K membership should remain highly similar\n",
    "    j = overlap_jaccard(base_order[:TOPK], order_lex[:TOPK])\n",
    "    overlap_rows.append({\"segment\": seg, \"topk\": TOPK, \"topk_jaccard_membership\": j})\n",
    "\n",
    "    # Quantify \"primary-score ties in Top-K\" (diagnostic)\n",
    "    # This number may stay high; what's improved is deterministic ordering within tie blocks.\n",
    "    base_adj_ties = unresolved_ties_count(scores, base_order, TOPK)\n",
    "    lex_adj_ties = unresolved_ties_count(scores, order_lex, TOPK)\n",
    "\n",
    "    rows.append({\n",
    "        \"segment\": seg,\n",
    "        \"topk\": TOPK,\n",
    "        \"secondary_keys_used\": \",\".join(sec_feats) if sec_feats else \"\",\n",
    "        \"topk_jaccard_membership\": j,\n",
    "        \"adjacent_primary_ties_before\": base_adj_ties,\n",
    "        \"adjacent_primary_ties_after\": lex_adj_ties,\n",
    "        \"note\": \"Primary-score tie counts may remain; ordering within ties is now deterministic via secondary keys + contrib + stable_id.\"\n",
    "    })\n",
    "\n",
    "effect_df = pd.DataFrame(rows)\n",
    "overlap_df2 = pd.DataFrame(overlap_rows)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Save artifacts\n",
    "# -----------------------------\n",
    "effect_out = REPORTS_DIR / \"notebook08_section02_lex_tiebreak_effect.csv\"\n",
    "overlap_out2 = REPORTS_DIR / \"notebook08_section02_topk_overlap_guardrail_v2.csv\"\n",
    "\n",
    "effect_df.to_csv(effect_out, index=False)\n",
    "overlap_df2.to_csv(overlap_out2, index=False)\n",
    "\n",
    "print(\"Saved:\", effect_out)\n",
    "print(\"Saved:\", overlap_out2)\n",
    "\n",
    "print(\"\\nLex tie-break effect summary:\")\n",
    "display(effect_df)\n",
    "\n",
    "print(\"\\nTop-K membership overlap guardrail (Jaccard):\")\n",
    "display(overlap_df2.sort_values(\"topk_jaccard_membership\"))\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Update run manifest\n",
    "# -----------------------------\n",
    "manifest_path = ARTIFACTS_DIR / f\"run_manifest_{SYSTEM_VERSION}.json\"\n",
    "m = load_json(manifest_path)\n",
    "m.setdefault(\"outputs\", {})\n",
    "m[\"outputs\"].update({\n",
    "    \"reports.section02.lex_tiebreak_effect\": str(effect_out),\n",
    "    \"reports.section02.topk_overlap_guardrail_v2\": str(overlap_out2),\n",
    "})\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(m, f, indent=2)\n",
    "\n",
    "print(\"Updated manifest:\", manifest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0441e05-c7a9-4023-a10e-16a8223dce6d",
   "metadata": {},
   "source": [
    "## 02.2 Lexicographic Tie-Break Ranking (Completing the Order)  \n",
    "\n",
    "Section 02.1 showed that adding a tiny numeric bonus alone is not sufficient to\n",
    "resolve large equivalence classes created by discrete feature combinations.\n",
    "\n",
    "This step completes the ranking using a **lexicographic tie-break strategy**:\n",
    "the primary score determines *who belongs*, and additional deterministic keys\n",
    "determine *ordering* within tied groups.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Lexicographic Tie-Breaking Is Required\n",
    "\n",
    "In Section 01 we observed:\n",
    "\n",
    "- Rankings are **stable** under perturbation (low volatility)\n",
    "- But many segments produce **large groups of schools with identical scores**\n",
    "\n",
    "Attempting to “fix” this by modifying the primary score:\n",
    "- risks changing the meaning of the segment\n",
    "- introduces fragile epsilon tuning\n",
    "- makes future calibration harder\n",
    "\n",
    "Lexicographic tie-breaking resolves ties **without altering what the score means**.\n",
    "\n",
    "---\n",
    "\n",
    "## What Changes in This Step (and What Does Not)\n",
    "\n",
    "### What stays the same\n",
    "- Primary segment score definition\n",
    "- Feature weights and intent\n",
    "- Top-K membership (guardrail enforced)\n",
    "\n",
    "### What changes\n",
    "- The system now produces a **total ordering**\n",
    "- Schools with identical scores are ordered deterministically\n",
    "\n",
    "Primary score ties are expected to remain numerically equal;\n",
    "they are no longer left unordered.\n",
    "\n",
    "---\n",
    "\n",
    "## Lexicographic Ranking Policy\n",
    "\n",
    "Schools are ranked using the following ordered keys:\n",
    "\n",
    "1. **Primary segment score** (DESC)  \n",
    "2. **Secondary dense signal** (DESC, segment-specific when appropriate)  \n",
    "3. **Contributing feature count** (DESC)  \n",
    "4. **Stable identifier** (ASC, final deterministic fallback)\n",
    "\n",
    "This guarantees:\n",
    "- determinism\n",
    "- explainability\n",
    "- no silent randomness\n",
    "\n",
    "---\n",
    "\n",
    "## Segment-Specific Secondary Signals\n",
    "\n",
    "Secondary keys are only used when they align with segment intent:\n",
    "\n",
    "- `small_nurturing` → `score_size_small`, `score_attention`\n",
    "- `progressive_balanced` → `score_diversity`, `score_size_small`\n",
    "- `balanced_general` → *(none; neutral ordering)*\n",
    "- `academic_first` → *(none; preserves tier purity)*\n",
    "\n",
    "If a secondary feature is unavailable, it is skipped explicitly\n",
    "(no silent fallback).\n",
    "\n",
    "---\n",
    "\n",
    "## How to Interpret the Diagnostics\n",
    "\n",
    "After this step:\n",
    "\n",
    "- **Primary-score tie counts may remain high**  \n",
    "  This is expected and acceptable.\n",
    "- **Ordering within tie groups is now deterministic**\n",
    "- **Top-K membership remains unchanged** (Jaccard ≈ 1.0)\n",
    "\n",
    "Success is defined as:\n",
    "> *No ambiguity in ordering, not fewer equal score values.*\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Is Launch-Safe\n",
    "\n",
    "- No learning or outcome prediction is introduced\n",
    "- No randomization is used\n",
    "- Rankings are stable across runs and versions\n",
    "- Decisions can be explained in plain language\n",
    "\n",
    "This completes the ranking logic without compromising trust.\n",
    "\n",
    "---\n",
    "\n",
    "> Section 01 identified where the system hesitated.  \n",
    "> Section 02 makes the system decide — explicitly and safely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9528aba7-fac7-4b48-a329-8ee31d3ca261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>topk</th>\n",
       "      <th>n_tie_groups</th>\n",
       "      <th>secondary_keys_used</th>\n",
       "      <th>pct_groups_with_secondary_variance</th>\n",
       "      <th>avg_unique_secondary_per_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first</td>\n",
       "      <td>500</td>\n",
       "      <td>46</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>500</td>\n",
       "      <td>46</td>\n",
       "      <td>score_size_small,score_attention</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>500</td>\n",
       "      <td>44</td>\n",
       "      <td>score_diversity,score_size_small</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balanced_general</td>\n",
       "      <td>500</td>\n",
       "      <td>78</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                segment  topk  n_tie_groups               secondary_keys_used  \\\n",
       "0        academic_first   500            46                                     \n",
       "1       small_nurturing   500            46  score_size_small,score_attention   \n",
       "2  progressive_balanced   500            44  score_diversity,score_size_small   \n",
       "3      balanced_general   500            78                                     \n",
       "\n",
       "   pct_groups_with_secondary_variance  avg_unique_secondary_per_group  \n",
       "0                                 0.0                             NaN  \n",
       "1                                 0.0                             1.0  \n",
       "2                                 0.0                             1.0  \n",
       "3                                 0.0                             NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 02.2b Verify tie resolution power of secondary keys \n",
    "\n",
    "def tie_groups_in_topk(scores: np.ndarray, order: np.ndarray, topk: int):\n",
    "    top = order[:topk]\n",
    "    s = scores[top]\n",
    "    # group by score value\n",
    "    groups = {}\n",
    "    for idx, val in zip(top, s):\n",
    "        groups.setdefault(val, []).append(int(idx))\n",
    "    # keep only tie groups (size>1)\n",
    "    return [g for g in groups.values() if len(g) > 1]\n",
    "\n",
    "def resolution_stats_for_segment(seg: str, topk: int = 500):\n",
    "    scores = baseline[seg][\"scores\"]\n",
    "    order_lex = baseline[seg][\"order_lex_v1\"]\n",
    "    tie_groups = tie_groups_in_topk(scores, order_lex, topk)\n",
    "\n",
    "    sec_feats = secondary_keys.get(seg, [])\n",
    "    if not sec_feats:\n",
    "        return {\n",
    "            \"segment\": seg,\n",
    "            \"topk\": topk,\n",
    "            \"n_tie_groups\": len(tie_groups),\n",
    "            \"secondary_keys_used\": \"\",\n",
    "            \"pct_groups_with_secondary_variance\": 0.0,\n",
    "            \"avg_unique_secondary_per_group\": np.nan,\n",
    "        }\n",
    "\n",
    "    # compute secondary arrays\n",
    "    sec_arrays = [X[:, feat_to_idx[f]].astype(float) for f in sec_feats]\n",
    "\n",
    "    groups_with_variance = 0\n",
    "    unique_counts = []\n",
    "\n",
    "    for g in tie_groups:\n",
    "        # build a tuple per row of (sec1, sec2, ...)\n",
    "        tuples = list(zip(*[arr[g] for arr in sec_arrays]))\n",
    "        u = len(set(tuples))\n",
    "        unique_counts.append(u)\n",
    "        if u > 1:\n",
    "            groups_with_variance += 1\n",
    "\n",
    "    return {\n",
    "        \"segment\": seg,\n",
    "        \"topk\": topk,\n",
    "        \"n_tie_groups\": len(tie_groups),\n",
    "        \"secondary_keys_used\": \",\".join(sec_feats),\n",
    "        \"pct_groups_with_secondary_variance\": (groups_with_variance / len(tie_groups)) if tie_groups else 0.0,\n",
    "        \"avg_unique_secondary_per_group\": float(np.mean(unique_counts)) if unique_counts else np.nan,\n",
    "    }\n",
    "\n",
    "stats = pd.DataFrame([resolution_stats_for_segment(seg, TOPK) for seg in SEG_KEYS])\n",
    "display(stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181d4b6c-a938-4d4e-ae62-24a9c53d5313",
   "metadata": {},
   "source": [
    "### Design Decision: Deterministic Ordering over Artificial Differentiation\n",
    "\n",
    "Empirical analysis in Section 02 confirmed that large score tie groups are caused\n",
    "by genuine feature equivalence rather than instability or noise. Secondary dense\n",
    "signals available in the current feature set do not meaningfully vary within\n",
    "these equivalence classes, and therefore cannot resolve ties semantically.\n",
    "Introducing randomness, excessive weight amplification, or learned ordering\n",
    "would violate determinism and undermine trust. The system therefore adopts a\n",
    "clear and principled stance: **primary scores define membership, lexicographic\n",
    "rules complete the ordering, and a stable identifier provides the final fallback**.\n",
    "This guarantees reproducibility and safety at launch while making the limitation\n",
    "explicit and measurable. Future differentiation will be driven by richer data,\n",
    "not artificial variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920b38c9-bb4f-4696-9991-3c94dd49c902",
   "metadata": {},
   "source": [
    "## 03.0 Statistical Refinement — Learning as Diagnostic, Not Authority \n",
    "\n",
    "Sections 01 and 02 established that the current deterministic scoring system is:\n",
    "\n",
    "- **Stable** (low rank volatility)\n",
    "- **Safe** (deterministic, no randomness)\n",
    "- **Honest** about its limitations (large equivalence classes)\n",
    "\n",
    "The remaining challenge is **information density**:\n",
    "many schools collapse into identical representations because multiple features\n",
    "encode overlapping or redundant signals.\n",
    "\n",
    "This section uses **unsupervised statistical analysis** to answer one question:\n",
    "\n",
    "> *Why does the feature space collapse — and how can it be improved?*\n",
    "\n",
    "Importantly, learning is used here **only as a diagnostic tool**.\n",
    "It does **not** determine rankings, override segments, or introduce prediction.\n",
    "\n",
    "---\n",
    "\n",
    "## Goals of Section 03\n",
    "\n",
    "### Capstone Goals\n",
    "- Demonstrate principled feature analysis\n",
    "- Quantify redundancy and correlation\n",
    "- Use PCA to reason about variance contribution\n",
    "- Show restraint: analysis without authority\n",
    "\n",
    "### Startup Goals\n",
    "- Identify low-value or duplicate features\n",
    "- Reduce unnecessary complexity\n",
    "- Improve computational efficiency\n",
    "- Inform future feature design (what would actually break ties)\n",
    "\n",
    "---\n",
    "\n",
    "## Guardrails (Reaffirmed)\n",
    "\n",
    "- ❌ No supervised learning\n",
    "- ❌ No outcome prediction\n",
    "- ❌ No automatic weight changes\n",
    "- ❌ No ranking overrides\n",
    "\n",
    "All outputs in this section are **advisory only**.\n",
    "\n",
    "---\n",
    "\n",
    "## What This Section Will Produce\n",
    "\n",
    "- Feature correlation matrix\n",
    "- Redundancy warnings (highly correlated features)\n",
    "- Variance contribution analysis (PCA, diagnostic only)\n",
    "- Recommendations for:\n",
    "  - feature removal\n",
    "  - feature consolidation\n",
    "  - future data acquisition\n",
    "\n",
    "These recommendations will be evaluated — not blindly applied — in later steps.\n",
    "\n",
    "---\n",
    "\n",
    "## Roadmap Within Section 03\n",
    "\n",
    "- **03.1** Feature Correlation Analysis  \n",
    "- **03.2** Redundancy Detection & Grouping  \n",
    "- **03.3** PCA / Variance Contribution (Diagnostic)  \n",
    "- **03.4** Actionable Insights (What Actually Adds Signal)\n",
    "\n",
    "---\n",
    "\n",
    "> Determinism defines trust.  \n",
    "> Statistics reveal structure.  \n",
    "> Judgment decides what changes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be24be27-7a06-4a09-b585-911af581199c",
   "metadata": {},
   "source": [
    "## 03.1 Feature Correlation Analysis  \n",
    "\n",
    "This step measures **how much features overlap** with each other.\n",
    "\n",
    "If two features move together almost perfectly, they are effectively encoding\n",
    "the same information. High redundancy reduces information density and contributes\n",
    "to large equivalence classes (ties).\n",
    "\n",
    "Because our feature space includes both:\n",
    "\n",
    "- **binary flags** (0/1)\n",
    "- **dense continuous scores** (0.0–1.0)\n",
    "\n",
    "we compute two correlation views:\n",
    "\n",
    "1) **Pearson correlation** on the full feature matrix (quick global view)  \n",
    "2) **Spearman correlation** as a robustness check (rank-based)\n",
    "\n",
    "Correlation is used strictly as a **diagnostic** tool.\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs / Artifacts\n",
    "\n",
    "- `/reports/notebook08_section03_feature_corr_pearson.csv`\n",
    "- `/reports/notebook08_section03_feature_corr_spearman.csv`\n",
    "- `/reports/notebook08_section03_feature_corr_top_pairs.csv`\n",
    "\n",
    "These are referenced in the run manifest.\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation Guide\n",
    "\n",
    "- |corr| ≥ 0.90 → very likely redundant\n",
    "- |corr| ≥ 0.75 → strong overlap worth reviewing\n",
    "- near 0 → features behave independently\n",
    "\n",
    "We will use these results in 03.2 to propose redundancy groupings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f78dcf2f-74f7-46f8-904f-2e53e5158acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section03_feature_corr_pearson.csv\n",
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section03_feature_corr_spearman.csv\n",
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section03_feature_corr_top_pairs.csv\n",
      "\n",
      "Top correlated feature pairs (|corr|>=0.75):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_a</th>\n",
       "      <th>feature_b</th>\n",
       "      <th>pearson_corr</th>\n",
       "      <th>spearman_corr</th>\n",
       "      <th>pearson_abs</th>\n",
       "      <th>spearman_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [feature_a, feature_b, pearson_corr, spearman_corr, pearson_abs, spearman_abs]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated manifest: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/run_manifest_v1.json\n"
     ]
    }
   ],
   "source": [
    "# 03.1 Feature Correlation Analysis \n",
    "\n",
    "# Build a DataFrame view of X for correlation analysis\n",
    "X_df = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "# Compute correlations\n",
    "corr_pearson = X_df.corr(method=\"pearson\")\n",
    "corr_spearman = X_df.corr(method=\"spearman\")\n",
    "\n",
    "pearson_out = REPORTS_DIR / \"notebook08_section03_feature_corr_pearson.csv\"\n",
    "spearman_out = REPORTS_DIR / \"notebook08_section03_feature_corr_spearman.csv\"\n",
    "\n",
    "corr_pearson.to_csv(pearson_out)\n",
    "corr_spearman.to_csv(spearman_out)\n",
    "\n",
    "print(\"Saved:\", pearson_out)\n",
    "print(\"Saved:\", spearman_out)\n",
    "\n",
    "# -----------------------------\n",
    "# Extract top correlated pairs (excluding diagonal and duplicates)\n",
    "# -----------------------------\n",
    "def top_corr_pairs(corr: pd.DataFrame, k: int = 50, min_abs: float = 0.75) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    cols = corr.columns.tolist()\n",
    "    for i in range(len(cols)):\n",
    "        for j in range(i + 1, len(cols)):\n",
    "            v = float(corr.iloc[i, j])\n",
    "            if abs(v) >= min_abs:\n",
    "                rows.append({\n",
    "                    \"feature_a\": cols[i],\n",
    "                    \"feature_b\": cols[j],\n",
    "                    \"corr\": v,\n",
    "                    \"abs_corr\": abs(v),\n",
    "                })\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        return df\n",
    "    return df.sort_values(\"abs_corr\", ascending=False).head(k)\n",
    "\n",
    "top_pairs_p = top_corr_pairs(corr_pearson, k=100, min_abs=0.75)\n",
    "top_pairs_s = top_corr_pairs(corr_spearman, k=100, min_abs=0.75)\n",
    "\n",
    "# Merge views (same pair may appear in both)\n",
    "if not top_pairs_p.empty or not top_pairs_s.empty:\n",
    "    top_pairs = pd.merge(\n",
    "        top_pairs_p.rename(columns={\"corr\": \"pearson_corr\", \"abs_corr\": \"pearson_abs\"}),\n",
    "        top_pairs_s.rename(columns={\"corr\": \"spearman_corr\", \"abs_corr\": \"spearman_abs\"}),\n",
    "        on=[\"feature_a\", \"feature_b\"],\n",
    "        how=\"outer\"\n",
    "    ).sort_values(\n",
    "        [\"pearson_abs\", \"spearman_abs\"],\n",
    "        ascending=[False, False]\n",
    "    )\n",
    "else:\n",
    "    top_pairs = pd.DataFrame(columns=[\"feature_a\",\"feature_b\",\"pearson_corr\",\"spearman_corr\",\"pearson_abs\",\"spearman_abs\"])\n",
    "\n",
    "pairs_out = REPORTS_DIR / \"notebook08_section03_feature_corr_top_pairs.csv\"\n",
    "top_pairs.to_csv(pairs_out, index=False)\n",
    "print(\"Saved:\", pairs_out)\n",
    "\n",
    "print(\"\\nTop correlated feature pairs (|corr|>=0.75):\")\n",
    "display(top_pairs)\n",
    "\n",
    "# -----------------------------\n",
    "# Update run manifest\n",
    "# -----------------------------\n",
    "manifest_path = ARTIFACTS_DIR / f\"run_manifest_{SYSTEM_VERSION}.json\"\n",
    "m = load_json(manifest_path)\n",
    "m.setdefault(\"outputs\", {})\n",
    "m[\"outputs\"].update({\n",
    "    \"reports.section03.feature_corr_pearson\": str(pearson_out),\n",
    "    \"reports.section03.feature_corr_spearman\": str(spearman_out),\n",
    "    \"reports.section03.feature_corr_top_pairs\": str(pairs_out),\n",
    "})\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(m, f, indent=2)\n",
    "\n",
    "print(\"Updated manifest:\", manifest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956be7e8-0086-476c-8b56-5e1c169a5f84",
   "metadata": {},
   "source": [
    "## 03.3 PCA / Variance Contribution (Diagnostic Only) \n",
    "\n",
    "This step uses **Principal Component Analysis (PCA)** strictly as a **diagnostic tool**\n",
    "to understand how much *independent variation* exists in the current feature space.\n",
    "\n",
    "PCA is **not** used for ranking, weighting, or decision-making.\n",
    "\n",
    "---\n",
    "\n",
    "## Why PCA Here\n",
    "\n",
    "Earlier sections established that:\n",
    "- Pairwise feature correlations are low (03.1)\n",
    "- Yet large equivalence classes still exist (Sections 01–02)\n",
    "\n",
    "PCA helps answer a different question:\n",
    "\n",
    "> *How many effective dimensions of variation does the system actually have?*\n",
    "\n",
    "If most variance is captured by a small number of components, it explains why many\n",
    "schools appear indistinguishable — even without redundant features.\n",
    "\n",
    "---\n",
    "\n",
    "## Guardrails (Reaffirmed)\n",
    "\n",
    "- ❌ PCA components will **not** replace features\n",
    "- ❌ PCA scores will **not** affect ranking\n",
    "- ❌ No automatic weight changes\n",
    "- ❌ No learning authority introduced\n",
    "\n",
    "PCA results are **interpretive only**.\n",
    "\n",
    "---\n",
    "\n",
    "## What This Step Produces\n",
    "\n",
    "- Explained variance by principal component\n",
    "- Cumulative variance curve\n",
    "- Feature loadings per component (interpretation aid)\n",
    "\n",
    "These outputs inform **feature design decisions**, not ranking logic.\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation Guide\n",
    "\n",
    "- If **2–3 components explain most variance** → feature space is low-resolution\n",
    "- If variance is spread thinly → features are weak but independent\n",
    "- Loadings indicate *which features* drive each latent dimension\n",
    "\n",
    "Findings will be summarized in **03.4 Actionable Insights**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9870bf0d-725b-4604-9d82-260b72df02b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section03_pca_variance.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component</th>\n",
       "      <th>explained_variance_ratio</th>\n",
       "      <th>cumulative_variance_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PC1</td>\n",
       "      <td>0.172582</td>\n",
       "      <td>0.172582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PC2</td>\n",
       "      <td>0.127967</td>\n",
       "      <td>0.300549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PC3</td>\n",
       "      <td>0.109647</td>\n",
       "      <td>0.410196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PC4</td>\n",
       "      <td>0.100671</td>\n",
       "      <td>0.510868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PC5</td>\n",
       "      <td>0.100059</td>\n",
       "      <td>0.610926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PC6</td>\n",
       "      <td>0.098788</td>\n",
       "      <td>0.709714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PC7</td>\n",
       "      <td>0.091828</td>\n",
       "      <td>0.801542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PC8</td>\n",
       "      <td>0.089611</td>\n",
       "      <td>0.891153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PC9</td>\n",
       "      <td>0.060845</td>\n",
       "      <td>0.951998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PC10</td>\n",
       "      <td>0.048002</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  component  explained_variance_ratio  cumulative_variance_ratio\n",
       "0       PC1                  0.172582                   0.172582\n",
       "1       PC2                  0.127967                   0.300549\n",
       "2       PC3                  0.109647                   0.410196\n",
       "3       PC4                  0.100671                   0.510868\n",
       "4       PC5                  0.100059                   0.610926\n",
       "5       PC6                  0.098788                   0.709714\n",
       "6       PC7                  0.091828                   0.801542\n",
       "7       PC8                  0.089611                   0.891153\n",
       "8       PC9                  0.060845                   0.951998\n",
       "9      PC10                  0.048002                   1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section03_pca_loadings.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tag_ib</th>\n",
       "      <td>0.024050</td>\n",
       "      <td>0.041573</td>\n",
       "      <td>0.709498</td>\n",
       "      <td>0.011224</td>\n",
       "      <td>0.006020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_cais</th>\n",
       "      <td>0.071755</td>\n",
       "      <td>0.052401</td>\n",
       "      <td>0.423693</td>\n",
       "      <td>0.391362</td>\n",
       "      <td>-0.615088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_ams_montessori</th>\n",
       "      <td>0.025030</td>\n",
       "      <td>0.055320</td>\n",
       "      <td>0.548587</td>\n",
       "      <td>-0.360285</td>\n",
       "      <td>0.482463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_waldorf</th>\n",
       "      <td>0.035014</td>\n",
       "      <td>0.031061</td>\n",
       "      <td>-0.015295</td>\n",
       "      <td>0.600552</td>\n",
       "      <td>0.616272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serves_elementary</th>\n",
       "      <td>-0.148416</td>\n",
       "      <td>0.752782</td>\n",
       "      <td>-0.038046</td>\n",
       "      <td>0.107717</td>\n",
       "      <td>-0.001896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serves_middle</th>\n",
       "      <td>0.250862</td>\n",
       "      <td>0.015413</td>\n",
       "      <td>0.027747</td>\n",
       "      <td>0.498763</td>\n",
       "      <td>0.058934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serves_high</th>\n",
       "      <td>0.467811</td>\n",
       "      <td>-0.504473</td>\n",
       "      <td>0.028195</td>\n",
       "      <td>0.055794</td>\n",
       "      <td>0.012245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_size_small</th>\n",
       "      <td>0.537490</td>\n",
       "      <td>0.210037</td>\n",
       "      <td>-0.101964</td>\n",
       "      <td>-0.131962</td>\n",
       "      <td>0.030121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_attention</th>\n",
       "      <td>0.566198</td>\n",
       "      <td>0.329061</td>\n",
       "      <td>-0.044848</td>\n",
       "      <td>-0.050839</td>\n",
       "      <td>-0.014375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_diversity</th>\n",
       "      <td>0.281315</td>\n",
       "      <td>0.133011</td>\n",
       "      <td>-0.022255</td>\n",
       "      <td>-0.269745</td>\n",
       "      <td>-0.065790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         PC1       PC2       PC3       PC4       PC5\n",
       "tag_ib              0.024050  0.041573  0.709498  0.011224  0.006020\n",
       "tag_cais            0.071755  0.052401  0.423693  0.391362 -0.615088\n",
       "tag_ams_montessori  0.025030  0.055320  0.548587 -0.360285  0.482463\n",
       "tag_waldorf         0.035014  0.031061 -0.015295  0.600552  0.616272\n",
       "serves_elementary  -0.148416  0.752782 -0.038046  0.107717 -0.001896\n",
       "serves_middle       0.250862  0.015413  0.027747  0.498763  0.058934\n",
       "serves_high         0.467811 -0.504473  0.028195  0.055794  0.012245\n",
       "score_size_small    0.537490  0.210037 -0.101964 -0.131962  0.030121\n",
       "score_attention     0.566198  0.329061 -0.044848 -0.050839 -0.014375\n",
       "score_diversity     0.281315  0.133011 -0.022255 -0.269745 -0.065790"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Components needed for 80% variance: 7\n",
      "Components needed for 90% variance: 9\n",
      "Updated manifest: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/run_manifest_v1.json\n"
     ]
    }
   ],
   "source": [
    "# 03.3 PCA / Variance Contribution (Diagnostic Only) \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Prepare data\n",
    "# -----------------------------\n",
    "# Standardize features for PCA (important for mixed scales)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Fit PCA (full)\n",
    "# -----------------------------\n",
    "pca = PCA(random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "explained = pca.explained_variance_ratio_\n",
    "cum_explained = np.cumsum(explained)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Variance summary table\n",
    "# -----------------------------\n",
    "var_df = pd.DataFrame({\n",
    "    \"component\": [f\"PC{i+1}\" for i in range(len(explained))],\n",
    "    \"explained_variance_ratio\": explained,\n",
    "    \"cumulative_variance_ratio\": cum_explained\n",
    "})\n",
    "\n",
    "var_out = REPORTS_DIR / \"notebook08_section03_pca_variance.csv\"\n",
    "var_df.to_csv(var_out, index=False)\n",
    "\n",
    "print(\"Saved:\", var_out)\n",
    "display(var_df.head(10))\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Feature loadings (interpretation aid)\n",
    "# -----------------------------\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    index=feature_names,\n",
    "    columns=[f\"PC{i+1}\" for i in range(len(feature_names))]\n",
    ")\n",
    "\n",
    "loadings_out = REPORTS_DIR / \"notebook08_section03_pca_loadings.csv\"\n",
    "loadings.to_csv(loadings_out)\n",
    "\n",
    "print(\"Saved:\", loadings_out)\n",
    "display(loadings.iloc[:, :5])  # show first 5 PCs for readability\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Quick diagnostics (textual)\n",
    "# -----------------------------\n",
    "k80 = int(np.argmax(cum_explained >= 0.80) + 1)\n",
    "k90 = int(np.argmax(cum_explained >= 0.90) + 1)\n",
    "\n",
    "print(f\"\\nComponents needed for 80% variance: {k80}\")\n",
    "print(f\"Components needed for 90% variance: {k90}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Update run manifest\n",
    "# -----------------------------\n",
    "manifest_path = ARTIFACTS_DIR / f\"run_manifest_{SYSTEM_VERSION}.json\"\n",
    "m = load_json(manifest_path)\n",
    "m.setdefault(\"outputs\", {})\n",
    "m[\"outputs\"].update({\n",
    "    \"reports.section03.pca_variance\": str(var_out),\n",
    "    \"reports.section03.pca_loadings\": str(loadings_out),\n",
    "})\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(m, f, indent=2)\n",
    "\n",
    "print(\"Updated manifest:\", manifest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f66c8fa-ff6b-48a7-b7cd-46e5d2342d7b",
   "metadata": {},
   "source": [
    "## 03.4 Actionable Insights & Recommendations  \n",
    "\n",
    "Sections 03.1–03.3 examined the feature space using correlation analysis and PCA,\n",
    "strictly as diagnostic tools. This section consolidates those findings into\n",
    "**clear, defensible decisions** for both launch and future evolution.\n",
    "\n",
    "---\n",
    "\n",
    "## What We Learned (Evidence-Based)\n",
    "\n",
    "### 1) The feature set is **not redundant**\n",
    "- No feature pairs exhibit high correlation (|corr| ≥ 0.75).\n",
    "- PCA shows variance spread across many components.\n",
    "- There is no “obvious” feature to remove without losing information.\n",
    "\n",
    "**Conclusion:** The system is not bloated or duplicative.\n",
    "\n",
    "---\n",
    "\n",
    "### 2) The feature set is **under-expressive**\n",
    "- 7 components are required to explain 80% of variance.\n",
    "- 9 components are required to explain 90% of variance.\n",
    "- No dominant latent dimensions exist.\n",
    "\n",
    "**Conclusion:** The system has many weak signals, not a few strong ones.\n",
    "\n",
    "This explains:\n",
    "- large equivalence classes (ties)\n",
    "- why secondary features fail to differentiate tied schools\n",
    "- why epsilon bonuses and weight tweaks have limited effect\n",
    "\n",
    "---\n",
    "\n",
    "### 3) PCA confirms restraint was the correct choice\n",
    "- PCA does not reveal compressible structure.\n",
    "- Using PCA outputs for ranking would:\n",
    "  - reduce explainability\n",
    "  - fabricate separation\n",
    "  - violate determinism\n",
    "\n",
    "**Conclusion:** Learning should remain advisory, not authoritative.\n",
    "\n",
    "---\n",
    "\n",
    "## Launch Decisions (What We Will NOT Change)\n",
    "\n",
    "The following choices are **affirmed** for launch:\n",
    "\n",
    "- ✅ Deterministic primary scoring\n",
    "- ✅ Explicit preference segments\n",
    "- ✅ Lexicographic tie-breaking\n",
    "- ✅ Stable ordering over artificial variance\n",
    "- ❌ No supervised learning\n",
    "- ❌ No PCA-based ranking\n",
    "- ❌ No hidden randomness\n",
    "\n",
    "These choices maximize trust, stability, and explainability.\n",
    "\n",
    "---\n",
    "\n",
    "## What Would Actually Break Ties (Future Data, Not Tricks)\n",
    "\n",
    "The analysis shows that **new signal is required**, not re-weighting.\n",
    "High-impact future features would include:\n",
    "\n",
    "### High-Resolution Continuous Signals\n",
    "- commute time / distance to child location\n",
    "- class size distributions (not just “small”)\n",
    "- teacher–student ratios\n",
    "- tuition bands / affordability gradients\n",
    "\n",
    "### Child-Specific Signals\n",
    "- learning style alignment\n",
    "- support needs (gifted, 2e, language)\n",
    "- schedule constraints\n",
    "\n",
    "### Contextual & Constraint Signals\n",
    "- availability / admissions likelihood\n",
    "- transportation access\n",
    "- aftercare coverage\n",
    "\n",
    "These features add **new dimensions**, rather than amplifying old ones.\n",
    "\n",
    "---\n",
    "\n",
    "## Final Takeaway\n",
    "\n",
    "This notebook demonstrates a core principle of trustworthy systems:\n",
    "\n",
    "> *When data cannot justify differentiation, the system should not invent it.*\n",
    "\n",
    "By diagnosing — rather than obscuring — the limits of the current feature space,\n",
    "the system remains honest, stable, and ready for responsible evolution.\n",
    "\n",
    "---\n",
    "\n",
    "## Transition\n",
    "\n",
    "- Sections 01–02 ensured **safety and stability**\n",
    "- Section 03 explained **why ties exist**\n",
    "- The system is now **launch-ready**\n",
    "- Future improvement depends on **better data, not more math**\n",
    "\n",
    "> Determinism builds trust.  \n",
    "> Diagnostics reveal limits.  \n",
    "> New data creates resolution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75a5c27-2058-4013-8587-798ace2a8b25",
   "metadata": {},
   "source": [
    "## 04. Segment Blending — Continuous Personalization Without ML  \n",
    "\n",
    "Up to this point, the system has operated on **discrete preference segments**.\n",
    "Each segment represents a clear, interpretable worldview (e.g. academic-first,\n",
    "small-nurturing).\n",
    "\n",
    "Segment Blending introduces **continuous personalization** by allowing users\n",
    "to smoothly interpolate between two segments — without introducing learning,\n",
    "prediction, or instability.\n",
    "\n",
    "This enables:\n",
    "- slider-based UX controls\n",
    "- nuanced preferences (“mostly academic, but still nurturing”)\n",
    "- infinite personas from a small, trusted base\n",
    "\n",
    "---\n",
    "\n",
    "## Core Idea\n",
    "\n",
    "Each segment is represented by a **weight vector** in feature space.\n",
    "\n",
    "We define a blended vector as:\n",
    "\n",
    "\\[\n",
    "\\vec{W}_{blend} = \\alpha \\cdot \\vec{W}_{A} + (1 - \\alpha) \\cdot \\vec{W}_{B}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\(\\alpha \\in [0, 1]\\)\n",
    "- \\(\\alpha = 1.0\\) → pure Segment A\n",
    "- \\(\\alpha = 0.0\\) → pure Segment B\n",
    "\n",
    "No learning is involved.\n",
    "This is linear algebra over already-validated intent vectors.\n",
    "\n",
    "---\n",
    "\n",
    "## Guardrails\n",
    "\n",
    "- ❌ No modification to individual segment definitions\n",
    "- ❌ No learned blending weights\n",
    "- ❌ No override of tier or eligibility logic\n",
    "- ✅ Deterministic\n",
    "- ✅ Explainable\n",
    "- ✅ Stable under perturbation\n",
    "\n",
    "Blending operates strictly at the **vector level**, not the rule level.\n",
    "\n",
    "---\n",
    "\n",
    "## What This Section Produces\n",
    "\n",
    "- A reusable `blend_segments()` function\n",
    "- Blended weight vectors\n",
    "- Ranked school lists for blended personas\n",
    "- Diagnostics showing how Top-K changes as α varies\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Is Safe for Launch\n",
    "\n",
    "- The endpoints (α = 0 or 1) are already validated segments\n",
    "- Intermediate states are convex combinations (no surprises)\n",
    "- Ordering remains deterministic\n",
    "- Rankings evolve smoothly as preferences change\n",
    "\n",
    "This is **personalization without prediction**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5889b5d-4ccd-49bb-a9ab-e530baedef24",
   "metadata": {},
   "source": [
    "### 04.1 Implementing Segment Blending\n",
    "\n",
    "This step implements the core blending operation.\n",
    "\n",
    "Each preference segment is represented by a validated weight vector.\n",
    "Blending is performed by a simple convex combination of two such vectors,\n",
    "controlled by a single parameter \\(\\alpha\\).\n",
    "\n",
    "No learning, tuning, or normalization is introduced here.\n",
    "The blended vector remains fully deterministic and interpretable.\n",
    "\n",
    "This function is designed to be reusable by:\n",
    "- UI sliders\n",
    "- API endpoints\n",
    "- precomputed blended personas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "24884809-fbbc-4031-8bdb-9762333c9301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04.1 Segment Blending — Implementation\n",
    "\n",
    "def blend_segments(seg_a: str, seg_b: str, alpha: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Blend two segment weight vectors linearly.\n",
    "\n",
    "    alpha = 1.0 → seg_a\n",
    "    alpha = 0.0 → seg_b\n",
    "    \"\"\"\n",
    "    assert 0.0 <= alpha <= 1.0, \"alpha must be in [0,1]\"\n",
    "\n",
    "    w_a = baseline[seg_a][\"w\"]\n",
    "    w_b = baseline[seg_b][\"w\"]\n",
    "\n",
    "    return alpha * w_a + (1.0 - alpha) * w_b\n",
    "\n",
    "\n",
    "def score_and_rank_blend(seg_a: str, seg_b: str, alpha: float):\n",
    "    \"\"\"\n",
    "    Score and rank schools using a blended segment vector.\n",
    "    Uses lexicographic tie-breaking from Section 02.\n",
    "    \"\"\"\n",
    "    w_blend = blend_segments(seg_a, seg_b, alpha)\n",
    "    scores = score_schools(X, w_blend)\n",
    "\n",
    "    order = lex_rank(\n",
    "        scores=scores,\n",
    "        stable_ids=stable_id_arr,\n",
    "        contrib_count=contrib_count,\n",
    "        secondary_vals=[]  # keep neutral for blended views\n",
    "    )\n",
    "\n",
    "    return scores, order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3002fd6-b403-40da-b2f3-111219810795",
   "metadata": {},
   "source": [
    "### 04.2 Validating Smooth Ranking Transitions\n",
    "\n",
    "Blending must behave *smoothly* to be safe for user-facing controls.\n",
    "\n",
    "This step verifies that small changes in \\(\\alpha\\):\n",
    "- do not cause abrupt rank reshuffling\n",
    "- preserve Top-K membership continuity\n",
    "- maintain deterministic behavior\n",
    "\n",
    "We measure **Top-K Jaccard overlap** between adjacent \\(\\alpha\\) values.\n",
    "High overlap confirms that blending produces intuitive, stable transitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "532c36f2-3032-43f1-a7b2-8f5d1b043a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>topk_jaccard_vs_prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.162791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.960784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.960784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.960784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha  topk_jaccard_vs_prev\n",
       "0     0.0              1.000000\n",
       "1     0.1              0.851852\n",
       "2     0.2              0.063830\n",
       "3     0.3              0.162791\n",
       "4     0.4              0.851852\n",
       "5     0.5              1.000000\n",
       "6     0.6              0.960784\n",
       "7     0.7              0.960784\n",
       "8     0.8              1.000000\n",
       "9     0.9              0.960784\n",
       "10    1.0              0.923077"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 04.2 Blending Diagnostics — Top-K Drift\n",
    "\n",
    "SEG_A = \"academic_first\"\n",
    "SEG_B = \"small_nurturing\"\n",
    "TOPK = 50\n",
    "\n",
    "alphas = np.linspace(0.0, 1.0, 11)\n",
    "\n",
    "rows = []\n",
    "prev_topk = None\n",
    "\n",
    "for a in alphas:\n",
    "    scores, order = score_and_rank_blend(SEG_A, SEG_B, a)\n",
    "    topk = order[:TOPK]\n",
    "\n",
    "    if prev_topk is None:\n",
    "        jaccard = 1.0\n",
    "    else:\n",
    "        jaccard = len(set(topk) & set(prev_topk)) / len(set(topk) | set(prev_topk))\n",
    "\n",
    "    rows.append({\n",
    "        \"alpha\": round(a, 2),\n",
    "        \"topk_jaccard_vs_prev\": jaccard\n",
    "    })\n",
    "\n",
    "    prev_topk = topk\n",
    "\n",
    "blend_stability_df = pd.DataFrame(rows)\n",
    "display(blend_stability_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6069061-ac5c-4781-8401-9e4783fa6b19",
   "metadata": {},
   "source": [
    "### 04.3 Previewing a Blended Persona\n",
    "\n",
    "This optional step provides a concrete preview of blended results.\n",
    "\n",
    "It demonstrates:\n",
    "- how blended rankings look in practice\n",
    "- that blended scores are reasonable interpolations\n",
    "- that the system can generate new personas without redefining segments\n",
    "\n",
    "This preview is intended for:\n",
    "- sanity checking\n",
    "- demos\n",
    "- stakeholder communication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5833efe9-c3fc-4612-bdda-f40e8162517c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>row_index</th>\n",
       "      <th>_row_id_tmp</th>\n",
       "      <th>blended_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112054</th>\n",
       "      <td>PRI_A0770343</td>\n",
       "      <td>112054</td>\n",
       "      <td>112054</td>\n",
       "      <td>9.358156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112238</th>\n",
       "      <td>PRI_A0900353</td>\n",
       "      <td>112238</td>\n",
       "      <td>112238</td>\n",
       "      <td>9.335372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123458</th>\n",
       "      <td>PRI_BB180318</td>\n",
       "      <td>123458</td>\n",
       "      <td>123458</td>\n",
       "      <td>9.315184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119885</th>\n",
       "      <td>PRI_A9101385</td>\n",
       "      <td>119885</td>\n",
       "      <td>119885</td>\n",
       "      <td>6.642018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118078</th>\n",
       "      <td>PRI_A2100388</td>\n",
       "      <td>118078</td>\n",
       "      <td>118078</td>\n",
       "      <td>6.637326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102831</th>\n",
       "      <td>PRI_00078361</td>\n",
       "      <td>102831</td>\n",
       "      <td>102831</td>\n",
       "      <td>6.632470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102896</th>\n",
       "      <td>PRI_00081873</td>\n",
       "      <td>102896</td>\n",
       "      <td>102896</td>\n",
       "      <td>6.627290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114438</th>\n",
       "      <td>PRI_A1500546</td>\n",
       "      <td>114438</td>\n",
       "      <td>114438</td>\n",
       "      <td>6.593049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113512</th>\n",
       "      <td>PRI_A1300480</td>\n",
       "      <td>113512</td>\n",
       "      <td>113512</td>\n",
       "      <td>6.566732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121650</th>\n",
       "      <td>PRI_A9700620</td>\n",
       "      <td>121650</td>\n",
       "      <td>121650</td>\n",
       "      <td>6.555062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           school_id  row_index  _row_id_tmp  blended_score\n",
       "112054  PRI_A0770343     112054       112054       9.358156\n",
       "112238  PRI_A0900353     112238       112238       9.335372\n",
       "123458  PRI_BB180318     123458       123458       9.315184\n",
       "119885  PRI_A9101385     119885       119885       6.642018\n",
       "118078  PRI_A2100388     118078       118078       6.637326\n",
       "102831  PRI_00078361     102831       102831       6.632470\n",
       "102896  PRI_00081873     102896       102896       6.627290\n",
       "114438  PRI_A1500546     114438       114438       6.593049\n",
       "113512  PRI_A1300480     113512       113512       6.566732\n",
       "121650  PRI_A9700620     121650       121650       6.555062"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 04.3 Preview blended Top-10\n",
    "\n",
    "alpha_demo = 0.6\n",
    "scores, order = score_and_rank_blend(\"academic_first\", \"small_nurturing\", alpha_demo)\n",
    "\n",
    "preview = index_df.iloc[order[:10]].copy()\n",
    "preview[\"blended_score\"] = scores[order[:10]]\n",
    "\n",
    "display(preview)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7dcbf0-380d-415e-ac7e-529f58b7bf79",
   "metadata": {},
   "source": [
    "### Design Decision: Snap-to-Safe Segment Blending \n",
    "\n",
    "Empirical testing in Section 04.2 shows that while blended scores evolve\n",
    "continuously, **rank order does not always change smoothly** as the blending\n",
    "parameter \\(\\alpha\\) varies. In particular, small changes in \\(\\alpha\\) can\n",
    "cross feature-dominance boundaries, causing large Top-K reshuffles.\n",
    "\n",
    "This behavior is not a bug or instability — it is an inherent property of\n",
    "linear scoring systems applied to clustered data.\n",
    "\n",
    "To ensure a **trustworthy and intuitive user experience**, the launch design\n",
    "adopts a **snap-to-safe blending strategy**:\n",
    "\n",
    "- Blending is exposed using a small set of **pre-validated blend points**\n",
    "  (e.g. \\(\\alpha \\in \\{0.0, 0.25, 0.5, 0.75, 1.0\\}\\))\n",
    "- Each blend point is deterministic, testable, and explainable\n",
    "- Users never land in unstable transition zones\n",
    "- Rankings remain stable and predictable across interactions\n",
    "\n",
    "This preserves the expressive power of segment blending while avoiding\n",
    "unexpected rank jumps.\n",
    "\n",
    "Future versions may introduce smoother UI controls (e.g. hysteresis or\n",
    "debounced updates), but **v1 prioritizes clarity and trust over continuous motion**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b786a-edbf-4b6f-8c66-ec50a037fc03",
   "metadata": {},
   "source": [
    "## 05. Evaluation & Safety Regression \n",
    "This section ensures that all refinements introduced in Sections 02–04\n",
    "(tie-breaking and segment blending) preserve **core safety guarantees**.\n",
    "\n",
    "The goal is not to optimize rankings, but to **prove that nothing unsafe or\n",
    "unintended has been introduced**.\n",
    "\n",
    "All checks in this section are **hard guardrails**.\n",
    "Any failure blocks progression to production artifact generation.\n",
    "\n",
    "---\n",
    "\n",
    "## Safety Principles Enforced\n",
    "\n",
    "1. **Tier dominance is preserved**\n",
    "   - High-signal tier tags (e.g., IB, CAIS) must not be diluted below acceptable floors.\n",
    "2. **Eligibility constraints are respected**\n",
    "   - Grade-span mismatches are not introduced by blending.\n",
    "3. **Top-K membership stability**\n",
    "   - Blended views must not introduce unexpected schools outside the expected envelope.\n",
    "4. **Explainability consistency**\n",
    "   - Blended scores must remain interpretable as linear combinations of known segments.\n",
    "\n",
    "---\n",
    "\n",
    "## What This Section Produces\n",
    "\n",
    "- Tier-floor regression checks (pass/fail)\n",
    "- Grade-span regression checks\n",
    "- Top-K overlap safety metrics\n",
    "- A consolidated safety report\n",
    "\n",
    "If all checks pass, the system is considered **launch-safe**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e984971-fdae-4580-b299-6ef6757f42d3",
   "metadata": {},
   "source": [
    "### 05.1 Tier Dominance Regression (Safety Check)  ✅ [Launch-critical]\n",
    "\n",
    "This check ensures that **segment blending does not violate tier intent**.\n",
    "\n",
    "Each endpoint segment encodes an explicit worldview (e.g. academic-first,\n",
    "small-nurturing). Blending must *interpolate* between these worldviews —\n",
    "not introduce or suppress tier signals unexpectedly.\n",
    "\n",
    "---\n",
    "\n",
    "#### What This Check Verifies\n",
    "\n",
    "For each blended segment pair and each blend point \\(\\alpha\\):\n",
    "\n",
    "- Tier presence at **α = 0.0** matches the **Segment B baseline**\n",
    "- Tier presence at **α = 1.0** matches the **Segment A baseline**\n",
    "- Intermediate values change smoothly between endpoints\n",
    "- No tier appears in blended results if absent in **both** endpoints\n",
    "- No tier disappears if present in **both** endpoints\n",
    "\n",
    "This protects against accidental dilution or amplification of high-signal tiers\n",
    "(e.g. IB, CAIS).\n",
    "\n",
    "---\n",
    "\n",
    "#### How to Interpret the Output\n",
    "\n",
    "- Zero tier rate at an endpoint is **not an error** if the baseline segment\n",
    "  does not emphasize that tier.\n",
    "- Unexpected non-zero rates or endpoint mismatches indicate a regression\n",
    "  and must be investigated before launch.\n",
    "\n",
    "This check enforces **relative consistency**, not absolute quotas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d3459-9b94-46f5-abad-c7bd334f91e7",
   "metadata": {},
   "source": [
    "### Clarification: Interpreting α Endpoints in Blending \n",
    "\n",
    "In this notebook, blending is defined as:\n",
    "\n",
    "\\[\n",
    "\\vec{W}_{blend} = \\alpha \\vec{W}_{A} + (1-\\alpha)\\vec{W}_{B}\n",
    "\\]\n",
    "\n",
    "Therefore:\n",
    "\n",
    "- **α = 0.00** corresponds to **pure Segment B**\n",
    "- **α = 1.00** corresponds to **pure Segment A**\n",
    "\n",
    "So in a blend labeled `academic_first ↔ small_nurturing`:\n",
    "- α = 0.00 should match **small_nurturing** tier rates\n",
    "- α = 1.00 should match **academic_first** tier rates\n",
    "\n",
    "Intermediate α values are expected to interpolate smoothly between these endpoints.\n",
    "This prevents misinterpreting “tier rate = 0.0” at α = 0.0 as a regression when it\n",
    "is simply the Segment B baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a12b4e89-c213-4b8c-8cbe-42bad38d010a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint tier baselines (Top-K):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blend</th>\n",
       "      <th>endpoint_segment</th>\n",
       "      <th>alpha</th>\n",
       "      <th>tier</th>\n",
       "      <th>topk_rate</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>0.0</td>\n",
       "      <td>has_ams_montessori</td>\n",
       "      <td>0.010</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>0.0</td>\n",
       "      <td>has_cais</td>\n",
       "      <td>0.000</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>0.0</td>\n",
       "      <td>has_ib</td>\n",
       "      <td>0.002</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>0.0</td>\n",
       "      <td>has_waldorf</td>\n",
       "      <td>0.030</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>academic_first</td>\n",
       "      <td>1.0</td>\n",
       "      <td>has_ams_montessori</td>\n",
       "      <td>0.002</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>academic_first</td>\n",
       "      <td>1.0</td>\n",
       "      <td>has_cais</td>\n",
       "      <td>0.146</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>academic_first</td>\n",
       "      <td>1.0</td>\n",
       "      <td>has_ib</td>\n",
       "      <td>0.066</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>academic_first</td>\n",
       "      <td>1.0</td>\n",
       "      <td>has_waldorf</td>\n",
       "      <td>0.000</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>has_ams_montessori</td>\n",
       "      <td>0.002</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>has_cais</td>\n",
       "      <td>0.000</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>has_ib</td>\n",
       "      <td>0.000</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>has_waldorf</td>\n",
       "      <td>0.000</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>academic_first</td>\n",
       "      <td>1.0</td>\n",
       "      <td>has_ams_montessori</td>\n",
       "      <td>0.002</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>academic_first</td>\n",
       "      <td>1.0</td>\n",
       "      <td>has_cais</td>\n",
       "      <td>0.146</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>academic_first</td>\n",
       "      <td>1.0</td>\n",
       "      <td>has_ib</td>\n",
       "      <td>0.066</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>academic_first</td>\n",
       "      <td>1.0</td>\n",
       "      <td>has_waldorf</td>\n",
       "      <td>0.000</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    blend      endpoint_segment  alpha  \\\n",
       "10  academic_first ↔ progressive_balanced  progressive_balanced    0.0   \n",
       "9   academic_first ↔ progressive_balanced  progressive_balanced    0.0   \n",
       "8   academic_first ↔ progressive_balanced  progressive_balanced    0.0   \n",
       "11  academic_first ↔ progressive_balanced  progressive_balanced    0.0   \n",
       "14  academic_first ↔ progressive_balanced        academic_first    1.0   \n",
       "13  academic_first ↔ progressive_balanced        academic_first    1.0   \n",
       "12  academic_first ↔ progressive_balanced        academic_first    1.0   \n",
       "15  academic_first ↔ progressive_balanced        academic_first    1.0   \n",
       "2        academic_first ↔ small_nurturing       small_nurturing    0.0   \n",
       "1        academic_first ↔ small_nurturing       small_nurturing    0.0   \n",
       "0        academic_first ↔ small_nurturing       small_nurturing    0.0   \n",
       "3        academic_first ↔ small_nurturing       small_nurturing    0.0   \n",
       "6        academic_first ↔ small_nurturing        academic_first    1.0   \n",
       "5        academic_first ↔ small_nurturing        academic_first    1.0   \n",
       "4        academic_first ↔ small_nurturing        academic_first    1.0   \n",
       "7        academic_first ↔ small_nurturing        academic_first    1.0   \n",
       "\n",
       "                  tier  topk_rate               kind  \n",
       "10  has_ams_montessori      0.010  endpoint_baseline  \n",
       "9             has_cais      0.000  endpoint_baseline  \n",
       "8               has_ib      0.002  endpoint_baseline  \n",
       "11         has_waldorf      0.030  endpoint_baseline  \n",
       "14  has_ams_montessori      0.002  endpoint_baseline  \n",
       "13            has_cais      0.146  endpoint_baseline  \n",
       "12              has_ib      0.066  endpoint_baseline  \n",
       "15         has_waldorf      0.000  endpoint_baseline  \n",
       "2   has_ams_montessori      0.002  endpoint_baseline  \n",
       "1             has_cais      0.000  endpoint_baseline  \n",
       "0               has_ib      0.000  endpoint_baseline  \n",
       "3          has_waldorf      0.000  endpoint_baseline  \n",
       "6   has_ams_montessori      0.002  endpoint_baseline  \n",
       "5             has_cais      0.146  endpoint_baseline  \n",
       "4               has_ib      0.066  endpoint_baseline  \n",
       "7          has_waldorf      0.000  endpoint_baseline  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section05_tier_regression.csv\n",
      "\n",
      "Tier regression preview (blend rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blend</th>\n",
       "      <th>alpha</th>\n",
       "      <th>tier</th>\n",
       "      <th>topk_rate</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.00</td>\n",
       "      <td>has_ams_montessori</td>\n",
       "      <td>0.010</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.00</td>\n",
       "      <td>has_cais</td>\n",
       "      <td>0.000</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.00</td>\n",
       "      <td>has_ib</td>\n",
       "      <td>0.002</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.00</td>\n",
       "      <td>has_waldorf</td>\n",
       "      <td>0.030</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.25</td>\n",
       "      <td>has_ams_montessori</td>\n",
       "      <td>0.010</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.25</td>\n",
       "      <td>has_cais</td>\n",
       "      <td>0.146</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.25</td>\n",
       "      <td>has_ib</td>\n",
       "      <td>0.066</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.25</td>\n",
       "      <td>has_waldorf</td>\n",
       "      <td>0.030</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.50</td>\n",
       "      <td>has_ams_montessori</td>\n",
       "      <td>0.008</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.50</td>\n",
       "      <td>has_cais</td>\n",
       "      <td>0.146</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.50</td>\n",
       "      <td>has_ib</td>\n",
       "      <td>0.066</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.50</td>\n",
       "      <td>has_waldorf</td>\n",
       "      <td>0.030</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.75</td>\n",
       "      <td>has_ams_montessori</td>\n",
       "      <td>0.004</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.75</td>\n",
       "      <td>has_cais</td>\n",
       "      <td>0.146</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.75</td>\n",
       "      <td>has_ib</td>\n",
       "      <td>0.066</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.75</td>\n",
       "      <td>has_waldorf</td>\n",
       "      <td>0.030</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>1.00</td>\n",
       "      <td>has_ams_montessori</td>\n",
       "      <td>0.002</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>1.00</td>\n",
       "      <td>has_cais</td>\n",
       "      <td>0.146</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>1.00</td>\n",
       "      <td>has_ib</td>\n",
       "      <td>0.066</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>1.00</td>\n",
       "      <td>has_waldorf</td>\n",
       "      <td>0.000</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    blend  alpha                tier  \\\n",
       "22  academic_first ↔ progressive_balanced   0.00  has_ams_montessori   \n",
       "21  academic_first ↔ progressive_balanced   0.00            has_cais   \n",
       "20  academic_first ↔ progressive_balanced   0.00              has_ib   \n",
       "23  academic_first ↔ progressive_balanced   0.00         has_waldorf   \n",
       "26  academic_first ↔ progressive_balanced   0.25  has_ams_montessori   \n",
       "25  academic_first ↔ progressive_balanced   0.25            has_cais   \n",
       "24  academic_first ↔ progressive_balanced   0.25              has_ib   \n",
       "27  academic_first ↔ progressive_balanced   0.25         has_waldorf   \n",
       "30  academic_first ↔ progressive_balanced   0.50  has_ams_montessori   \n",
       "29  academic_first ↔ progressive_balanced   0.50            has_cais   \n",
       "28  academic_first ↔ progressive_balanced   0.50              has_ib   \n",
       "31  academic_first ↔ progressive_balanced   0.50         has_waldorf   \n",
       "34  academic_first ↔ progressive_balanced   0.75  has_ams_montessori   \n",
       "33  academic_first ↔ progressive_balanced   0.75            has_cais   \n",
       "32  academic_first ↔ progressive_balanced   0.75              has_ib   \n",
       "35  academic_first ↔ progressive_balanced   0.75         has_waldorf   \n",
       "38  academic_first ↔ progressive_balanced   1.00  has_ams_montessori   \n",
       "37  academic_first ↔ progressive_balanced   1.00            has_cais   \n",
       "36  academic_first ↔ progressive_balanced   1.00              has_ib   \n",
       "39  academic_first ↔ progressive_balanced   1.00         has_waldorf   \n",
       "\n",
       "    topk_rate   kind  \n",
       "22      0.010  blend  \n",
       "21      0.000  blend  \n",
       "20      0.002  blend  \n",
       "23      0.030  blend  \n",
       "26      0.010  blend  \n",
       "25      0.146  blend  \n",
       "24      0.066  blend  \n",
       "27      0.030  blend  \n",
       "30      0.008  blend  \n",
       "29      0.146  blend  \n",
       "28      0.066  blend  \n",
       "31      0.030  blend  \n",
       "34      0.004  blend  \n",
       "33      0.146  blend  \n",
       "32      0.066  blend  \n",
       "35      0.030  blend  \n",
       "38      0.002  blend  \n",
       "37      0.146  blend  \n",
       "36      0.066  blend  \n",
       "39      0.000  blend  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blend</th>\n",
       "      <th>alpha</th>\n",
       "      <th>max_abs_diff</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   blend  alpha  max_abs_diff status\n",
       "0       academic_first ↔ small_nurturing    0.0           0.0   PASS\n",
       "1       academic_first ↔ small_nurturing    1.0           0.0   PASS\n",
       "2  academic_first ↔ progressive_balanced    0.0           0.0   PASS\n",
       "3  academic_first ↔ progressive_balanced    1.0           0.0   PASS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section05_tier_endpoint_check.csv\n",
      "Updated manifest: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/run_manifest_v1.json\n"
     ]
    }
   ],
   "source": [
    "# 05.1 Tier Dominance Regression (Complete + Endpoint Baselines) \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "TOPK = 500\n",
    "BLEND_POINTS = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "TIER_COLS = [\"has_ib\", \"has_cais\", \"has_ams_montessori\", \"has_waldorf\"]\n",
    "\n",
    "BLENDS = [\n",
    "    (\"academic_first\", \"small_nurturing\"),\n",
    "    (\"academic_first\", \"progressive_balanced\"),\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Compute endpoint baselines for each blend\n",
    "# -----------------------------\n",
    "endpoint_rows = []\n",
    "for seg_a, seg_b in BLENDS:\n",
    "    for seg, alpha_label in [(seg_b, 0.0), (seg_a, 1.0)]:  # IMPORTANT: α=0 -> seg_b, α=1 -> seg_a\n",
    "        top_idx = baseline[seg][\"order\"][:TOPK]\n",
    "        df = schools_master_df.iloc[top_idx]\n",
    "        for tier in TIER_COLS:\n",
    "            endpoint_rows.append({\n",
    "                \"blend\": f\"{seg_a} ↔ {seg_b}\",\n",
    "                \"endpoint_segment\": seg,\n",
    "                \"alpha\": alpha_label,\n",
    "                \"tier\": tier,\n",
    "                \"topk_rate\": float(df[tier].mean()),\n",
    "                \"kind\": \"endpoint_baseline\"\n",
    "            })\n",
    "\n",
    "endpoint_df = pd.DataFrame(endpoint_rows)\n",
    "\n",
    "print(\"Endpoint tier baselines (Top-K):\")\n",
    "display(endpoint_df.sort_values([\"blend\", \"alpha\", \"tier\"]))\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Evaluate tier rates across blend points\n",
    "# -----------------------------\n",
    "rows = []\n",
    "for seg_a, seg_b in BLENDS:\n",
    "    for a in BLEND_POINTS:\n",
    "        scores, order = score_and_rank_blend(seg_a, seg_b, a)  # α=0 -> seg_b, α=1 -> seg_a\n",
    "        topk_idx = order[:TOPK]\n",
    "        topk_df = schools_master_df.iloc[topk_idx]\n",
    "\n",
    "        for tier in TIER_COLS:\n",
    "            rows.append({\n",
    "                \"blend\": f\"{seg_a} ↔ {seg_b}\",\n",
    "                \"alpha\": float(a),\n",
    "                \"tier\": tier,\n",
    "                \"topk_rate\": float(topk_df[tier].mean()),\n",
    "                \"kind\": \"blend\"\n",
    "            })\n",
    "\n",
    "tier_reg_df = pd.DataFrame(rows)\n",
    "\n",
    "# Combine for a single report table\n",
    "tier_reg_all = pd.concat([endpoint_df, tier_reg_df], ignore_index=True)\n",
    "\n",
    "tier_out = REPORTS_DIR / \"notebook08_section05_tier_regression.csv\"\n",
    "tier_reg_all.to_csv(tier_out, index=False)\n",
    "\n",
    "print(\"Saved:\", tier_out)\n",
    "\n",
    "print(\"\\nTier regression preview (blend rows):\")\n",
    "display(\n",
    "    tier_reg_df.sort_values([\"blend\", \"alpha\", \"tier\"]).head(20)\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Simple guardrail checks (relative, not absolute floors)\n",
    "# -----------------------------\n",
    "# Guardrail A: Endpoint rows should match baseline exactly (by definition)\n",
    "# This checks that our α interpretation and endpoints are correct.\n",
    "def endpoint_match_ok(df_all: pd.DataFrame) -> pd.DataFrame:\n",
    "    checks = []\n",
    "    for blend in df_all[\"blend\"].unique():\n",
    "        sub = df_all[df_all[\"blend\"] == blend]\n",
    "        for alpha in [0.0, 1.0]:\n",
    "            end_base = sub[(sub[\"kind\"] == \"endpoint_baseline\") & (sub[\"alpha\"] == alpha)].set_index(\"tier\")[\"topk_rate\"]\n",
    "            end_blend = sub[(sub[\"kind\"] == \"blend\") & (sub[\"alpha\"] == alpha)].set_index(\"tier\")[\"topk_rate\"]\n",
    "            diff = (end_blend - end_base).abs()\n",
    "            checks.append({\n",
    "                \"blend\": blend,\n",
    "                \"alpha\": alpha,\n",
    "                \"max_abs_diff\": float(diff.max()) if len(diff) else np.nan,\n",
    "                \"status\": \"PASS\" if (len(diff) and diff.max() < 1e-12) else \"FAIL\"\n",
    "            })\n",
    "    return pd.DataFrame(checks)\n",
    "\n",
    "endpoint_check_df = endpoint_match_ok(tier_reg_all)\n",
    "display(endpoint_check_df)\n",
    "\n",
    "endpoint_check_out = REPORTS_DIR / \"notebook08_section05_tier_endpoint_check.csv\"\n",
    "endpoint_check_df.to_csv(endpoint_check_out, index=False)\n",
    "print(\"Saved:\", endpoint_check_out)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Update run manifest\n",
    "# -----------------------------\n",
    "manifest_path = ARTIFACTS_DIR / f\"run_manifest_{SYSTEM_VERSION}.json\"\n",
    "m = load_json(manifest_path)\n",
    "m.setdefault(\"outputs\", {})\n",
    "m[\"outputs\"].update({\n",
    "    \"reports.section05.tier_regression\": str(tier_out),\n",
    "    \"reports.section05.tier_endpoint_check\": str(endpoint_check_out),\n",
    "})\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(m, f, indent=2)\n",
    "\n",
    "print(\"Updated manifest:\", manifest_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0384b3f9-ad4c-4488-a5bf-f0bebbd48001",
   "metadata": {},
   "source": [
    "### 05.2 Grade-Span Regression (Eligibility Safety Check) \n",
    "\n",
    "This check ensures that blending and tie-breaking do **not** introduce schools\n",
    "that violate basic **eligibility expectations** around grade span.\n",
    "\n",
    "Because our current v2 feature space only contains grade-span flags\n",
    "(`serves_elementary`, `serves_middle`, `serves_high`) rather than explicit\n",
    "requested grades, we enforce a conservative safety rule:\n",
    "\n",
    "- A grade-span signal should **not appear** in blended Top-K results\n",
    "  if it is absent in **both** endpoint segments.\n",
    "\n",
    "This protects against “hallucinated” eligibility introduced by blending artifacts\n",
    "and serves as a prerequisite for future stricter enforcement (e.g., matching a\n",
    "child’s target grades).\n",
    "\n",
    "---\n",
    "\n",
    "#### What This Check Verifies\n",
    "\n",
    "For each blend pair and blend point \\(\\alpha\\):\n",
    "\n",
    "- Top-K grade-span rates at **α = 0.0** match the Segment B baseline\n",
    "- Top-K grade-span rates at **α = 1.0** match the Segment A baseline\n",
    "- For intermediate α:\n",
    "  - Grade-span rates should remain within the endpoint envelope\n",
    "  - No grade flag appears if absent at both endpoints\n",
    "\n",
    "---\n",
    "\n",
    "#### Outputs\n",
    "\n",
    "- `/reports/notebook08_section05_grade_regression.csv`\n",
    "- `/reports/notebook08_section05_grade_endpoint_check.csv`\n",
    "- `/reports/notebook08_section05_grade_envelope_violations.csv` (only if violations exist)\n",
    "\n",
    "If violations occur, Section 06 is blocked until addressed.\n",
    "\n",
    "**Note on “large_drift_review” flags:**  \n",
    "These are not launch blockers. They indicate that intermediate blend points can\n",
    "shift the Top-K grade-span composition substantially when the two endpoint\n",
    "segments are very different (e.g., elementary-heavy vs secondary-heavy). This is\n",
    "expected under Top-K truncation and overlapping grade flags, but is surfaced as\n",
    "a product/UX note: blend pairs with large drift should be exposed using\n",
    "snap-to-safe blend points and clear user-facing explanations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "05e3821d-493b-4215-8d3a-5fcb43c1aafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint grade-span baselines (Top-K):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blend</th>\n",
       "      <th>endpoint_segment</th>\n",
       "      <th>alpha</th>\n",
       "      <th>grade_flag</th>\n",
       "      <th>topk_rate</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>0.0</td>\n",
       "      <td>serves_elementary</td>\n",
       "      <td>0.840</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>0.0</td>\n",
       "      <td>serves_high</td>\n",
       "      <td>0.138</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>0.0</td>\n",
       "      <td>serves_middle</td>\n",
       "      <td>0.134</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>academic_first</td>\n",
       "      <td>1.0</td>\n",
       "      <td>serves_elementary</td>\n",
       "      <td>0.694</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>academic_first</td>\n",
       "      <td>1.0</td>\n",
       "      <td>serves_high</td>\n",
       "      <td>0.952</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>academic_first</td>\n",
       "      <td>1.0</td>\n",
       "      <td>serves_middle</td>\n",
       "      <td>0.954</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>serves_elementary</td>\n",
       "      <td>1.000</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>serves_high</td>\n",
       "      <td>0.040</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>serves_middle</td>\n",
       "      <td>0.098</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>academic_first</td>\n",
       "      <td>1.0</td>\n",
       "      <td>serves_elementary</td>\n",
       "      <td>0.694</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>academic_first</td>\n",
       "      <td>1.0</td>\n",
       "      <td>serves_high</td>\n",
       "      <td>0.952</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>academic_first</td>\n",
       "      <td>1.0</td>\n",
       "      <td>serves_middle</td>\n",
       "      <td>0.954</td>\n",
       "      <td>endpoint_baseline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    blend      endpoint_segment  alpha  \\\n",
       "6   academic_first ↔ progressive_balanced  progressive_balanced    0.0   \n",
       "8   academic_first ↔ progressive_balanced  progressive_balanced    0.0   \n",
       "7   academic_first ↔ progressive_balanced  progressive_balanced    0.0   \n",
       "9   academic_first ↔ progressive_balanced        academic_first    1.0   \n",
       "11  academic_first ↔ progressive_balanced        academic_first    1.0   \n",
       "10  academic_first ↔ progressive_balanced        academic_first    1.0   \n",
       "0        academic_first ↔ small_nurturing       small_nurturing    0.0   \n",
       "2        academic_first ↔ small_nurturing       small_nurturing    0.0   \n",
       "1        academic_first ↔ small_nurturing       small_nurturing    0.0   \n",
       "3        academic_first ↔ small_nurturing        academic_first    1.0   \n",
       "5        academic_first ↔ small_nurturing        academic_first    1.0   \n",
       "4        academic_first ↔ small_nurturing        academic_first    1.0   \n",
       "\n",
       "           grade_flag  topk_rate               kind  \n",
       "6   serves_elementary      0.840  endpoint_baseline  \n",
       "8         serves_high      0.138  endpoint_baseline  \n",
       "7       serves_middle      0.134  endpoint_baseline  \n",
       "9   serves_elementary      0.694  endpoint_baseline  \n",
       "11        serves_high      0.952  endpoint_baseline  \n",
       "10      serves_middle      0.954  endpoint_baseline  \n",
       "0   serves_elementary      1.000  endpoint_baseline  \n",
       "2         serves_high      0.040  endpoint_baseline  \n",
       "1       serves_middle      0.098  endpoint_baseline  \n",
       "3   serves_elementary      0.694  endpoint_baseline  \n",
       "5         serves_high      0.952  endpoint_baseline  \n",
       "4       serves_middle      0.954  endpoint_baseline  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section05_grade_regression.csv\n",
      "\n",
      "Grade regression preview (blend rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blend</th>\n",
       "      <th>alpha</th>\n",
       "      <th>grade_flag</th>\n",
       "      <th>topk_rate</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.00</td>\n",
       "      <td>serves_elementary</td>\n",
       "      <td>0.840</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.00</td>\n",
       "      <td>serves_high</td>\n",
       "      <td>0.138</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.00</td>\n",
       "      <td>serves_middle</td>\n",
       "      <td>0.134</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.25</td>\n",
       "      <td>serves_elementary</td>\n",
       "      <td>0.658</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.25</td>\n",
       "      <td>serves_high</td>\n",
       "      <td>0.946</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.25</td>\n",
       "      <td>serves_middle</td>\n",
       "      <td>0.948</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.50</td>\n",
       "      <td>serves_elementary</td>\n",
       "      <td>0.662</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.50</td>\n",
       "      <td>serves_high</td>\n",
       "      <td>0.948</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.50</td>\n",
       "      <td>serves_middle</td>\n",
       "      <td>0.950</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.75</td>\n",
       "      <td>serves_elementary</td>\n",
       "      <td>0.666</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.75</td>\n",
       "      <td>serves_high</td>\n",
       "      <td>0.952</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.75</td>\n",
       "      <td>serves_middle</td>\n",
       "      <td>0.954</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>1.00</td>\n",
       "      <td>serves_elementary</td>\n",
       "      <td>0.694</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>1.00</td>\n",
       "      <td>serves_high</td>\n",
       "      <td>0.952</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>1.00</td>\n",
       "      <td>serves_middle</td>\n",
       "      <td>0.954</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.00</td>\n",
       "      <td>serves_elementary</td>\n",
       "      <td>1.000</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.00</td>\n",
       "      <td>serves_high</td>\n",
       "      <td>0.040</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.00</td>\n",
       "      <td>serves_middle</td>\n",
       "      <td>0.098</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.25</td>\n",
       "      <td>serves_elementary</td>\n",
       "      <td>1.000</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.25</td>\n",
       "      <td>serves_high</td>\n",
       "      <td>0.506</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.25</td>\n",
       "      <td>serves_middle</td>\n",
       "      <td>0.578</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.50</td>\n",
       "      <td>serves_elementary</td>\n",
       "      <td>0.950</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.50</td>\n",
       "      <td>serves_high</td>\n",
       "      <td>0.952</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.50</td>\n",
       "      <td>serves_middle</td>\n",
       "      <td>0.958</td>\n",
       "      <td>blend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    blend  alpha         grade_flag  \\\n",
       "15  academic_first ↔ progressive_balanced   0.00  serves_elementary   \n",
       "17  academic_first ↔ progressive_balanced   0.00        serves_high   \n",
       "16  academic_first ↔ progressive_balanced   0.00      serves_middle   \n",
       "18  academic_first ↔ progressive_balanced   0.25  serves_elementary   \n",
       "20  academic_first ↔ progressive_balanced   0.25        serves_high   \n",
       "19  academic_first ↔ progressive_balanced   0.25      serves_middle   \n",
       "21  academic_first ↔ progressive_balanced   0.50  serves_elementary   \n",
       "23  academic_first ↔ progressive_balanced   0.50        serves_high   \n",
       "22  academic_first ↔ progressive_balanced   0.50      serves_middle   \n",
       "24  academic_first ↔ progressive_balanced   0.75  serves_elementary   \n",
       "26  academic_first ↔ progressive_balanced   0.75        serves_high   \n",
       "25  academic_first ↔ progressive_balanced   0.75      serves_middle   \n",
       "27  academic_first ↔ progressive_balanced   1.00  serves_elementary   \n",
       "29  academic_first ↔ progressive_balanced   1.00        serves_high   \n",
       "28  academic_first ↔ progressive_balanced   1.00      serves_middle   \n",
       "0        academic_first ↔ small_nurturing   0.00  serves_elementary   \n",
       "2        academic_first ↔ small_nurturing   0.00        serves_high   \n",
       "1        academic_first ↔ small_nurturing   0.00      serves_middle   \n",
       "3        academic_first ↔ small_nurturing   0.25  serves_elementary   \n",
       "5        academic_first ↔ small_nurturing   0.25        serves_high   \n",
       "4        academic_first ↔ small_nurturing   0.25      serves_middle   \n",
       "6        academic_first ↔ small_nurturing   0.50  serves_elementary   \n",
       "8        academic_first ↔ small_nurturing   0.50        serves_high   \n",
       "7        academic_first ↔ small_nurturing   0.50      serves_middle   \n",
       "\n",
       "    topk_rate   kind  \n",
       "15      0.840  blend  \n",
       "17      0.138  blend  \n",
       "16      0.134  blend  \n",
       "18      0.658  blend  \n",
       "20      0.946  blend  \n",
       "19      0.948  blend  \n",
       "21      0.662  blend  \n",
       "23      0.948  blend  \n",
       "22      0.950  blend  \n",
       "24      0.666  blend  \n",
       "26      0.952  blend  \n",
       "25      0.954  blend  \n",
       "27      0.694  blend  \n",
       "29      0.952  blend  \n",
       "28      0.954  blend  \n",
       "0       1.000  blend  \n",
       "2       0.040  blend  \n",
       "1       0.098  blend  \n",
       "3       1.000  blend  \n",
       "5       0.506  blend  \n",
       "4       0.578  blend  \n",
       "6       0.950  blend  \n",
       "8       0.952  blend  \n",
       "7       0.958  blend  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blend</th>\n",
       "      <th>alpha</th>\n",
       "      <th>max_abs_diff</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   blend  alpha  max_abs_diff status\n",
       "0       academic_first ↔ small_nurturing    0.0           0.0   PASS\n",
       "1       academic_first ↔ small_nurturing    1.0           0.0   PASS\n",
       "2  academic_first ↔ progressive_balanced    0.0           0.0   PASS\n",
       "3  academic_first ↔ progressive_balanced    1.0           0.0   PASS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section05_grade_endpoint_check.csv\n",
      "Envelope violations detected. Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section05_grade_envelope_violations.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blend</th>\n",
       "      <th>alpha</th>\n",
       "      <th>grade_flag</th>\n",
       "      <th>topk_rate</th>\n",
       "      <th>endpoint_lo</th>\n",
       "      <th>endpoint_hi</th>\n",
       "      <th>violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.50</td>\n",
       "      <td>serves_middle</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.954</td>\n",
       "      <td>outside_endpoint_envelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.25</td>\n",
       "      <td>serves_elementary</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.840</td>\n",
       "      <td>outside_endpoint_envelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.50</td>\n",
       "      <td>serves_elementary</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.840</td>\n",
       "      <td>outside_endpoint_envelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.75</td>\n",
       "      <td>serves_elementary</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.840</td>\n",
       "      <td>outside_endpoint_envelope</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   blend  alpha         grade_flag  topk_rate  \\\n",
       "0       academic_first ↔ small_nurturing   0.50      serves_middle      0.958   \n",
       "1  academic_first ↔ progressive_balanced   0.25  serves_elementary      0.658   \n",
       "2  academic_first ↔ progressive_balanced   0.50  serves_elementary      0.662   \n",
       "3  academic_first ↔ progressive_balanced   0.75  serves_elementary      0.666   \n",
       "\n",
       "   endpoint_lo  endpoint_hi                  violation  \n",
       "0        0.098        0.954  outside_endpoint_envelope  \n",
       "1        0.694        0.840  outside_endpoint_envelope  \n",
       "2        0.694        0.840  outside_endpoint_envelope  \n",
       "3        0.694        0.840  outside_endpoint_envelope  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated manifest: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/run_manifest_v1.json\n"
     ]
    }
   ],
   "source": [
    "# 05.2 Grade-Span Regression (Eligibility Safety Check)  \n",
    "\n",
    "TOPK = 500\n",
    "BLEND_POINTS = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "GRADE_COLS = [\"serves_elementary\", \"serves_middle\", \"serves_high\"]\n",
    "\n",
    "BLENDS = [\n",
    "    (\"academic_first\", \"small_nurturing\"),\n",
    "    (\"academic_first\", \"progressive_balanced\"),\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Endpoint baselines (α=0 -> seg_b, α=1 -> seg_a)\n",
    "# -----------------------------\n",
    "endpoint_rows = []\n",
    "for seg_a, seg_b in BLENDS:\n",
    "    for seg, alpha_label in [(seg_b, 0.0), (seg_a, 1.0)]:\n",
    "        top_idx = baseline[seg][\"order\"][:TOPK]\n",
    "        df = schools_master_df.iloc[top_idx]\n",
    "        for g in GRADE_COLS:\n",
    "            endpoint_rows.append({\n",
    "                \"blend\": f\"{seg_a} ↔ {seg_b}\",\n",
    "                \"endpoint_segment\": seg,\n",
    "                \"alpha\": alpha_label,\n",
    "                \"grade_flag\": g,\n",
    "                \"topk_rate\": float(df[g].mean()),\n",
    "                \"kind\": \"endpoint_baseline\"\n",
    "            })\n",
    "\n",
    "endpoint_df = pd.DataFrame(endpoint_rows)\n",
    "\n",
    "print(\"Endpoint grade-span baselines (Top-K):\")\n",
    "display(endpoint_df.sort_values([\"blend\", \"alpha\", \"grade_flag\"]))\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Grade-span rates across blend points\n",
    "# -----------------------------\n",
    "rows = []\n",
    "for seg_a, seg_b in BLENDS:\n",
    "    for a in BLEND_POINTS:\n",
    "        scores, order = score_and_rank_blend(seg_a, seg_b, a)\n",
    "        top_idx = order[:TOPK]\n",
    "        df = schools_master_df.iloc[top_idx]\n",
    "\n",
    "        for g in GRADE_COLS:\n",
    "            rows.append({\n",
    "                \"blend\": f\"{seg_a} ↔ {seg_b}\",\n",
    "                \"alpha\": float(a),\n",
    "                \"grade_flag\": g,\n",
    "                \"topk_rate\": float(df[g].mean()),\n",
    "                \"kind\": \"blend\"\n",
    "            })\n",
    "\n",
    "grade_reg_df = pd.DataFrame(rows)\n",
    "grade_reg_all = pd.concat([endpoint_df, grade_reg_df], ignore_index=True)\n",
    "\n",
    "grade_out = REPORTS_DIR / \"notebook08_section05_grade_regression.csv\"\n",
    "grade_reg_all.to_csv(grade_out, index=False)\n",
    "print(\"Saved:\", grade_out)\n",
    "\n",
    "print(\"\\nGrade regression preview (blend rows):\")\n",
    "display(grade_reg_df.sort_values([\"blend\", \"alpha\", \"grade_flag\"]).head(24))\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Endpoint match check (sanity)\n",
    "# -----------------------------\n",
    "def endpoint_match_ok(df_all: pd.DataFrame) -> pd.DataFrame:\n",
    "    checks = []\n",
    "    for blend in df_all[\"blend\"].unique():\n",
    "        sub = df_all[df_all[\"blend\"] == blend]\n",
    "        for alpha in [0.0, 1.0]:\n",
    "            end_base = sub[(sub[\"kind\"] == \"endpoint_baseline\") & (sub[\"alpha\"] == alpha)].set_index(\"grade_flag\")[\"topk_rate\"]\n",
    "            end_blend = sub[(sub[\"kind\"] == \"blend\") & (sub[\"alpha\"] == alpha)].set_index(\"grade_flag\")[\"topk_rate\"]\n",
    "            diff = (end_blend - end_base).abs()\n",
    "            checks.append({\n",
    "                \"blend\": blend,\n",
    "                \"alpha\": alpha,\n",
    "                \"max_abs_diff\": float(diff.max()) if len(diff) else np.nan,\n",
    "                \"status\": \"PASS\" if (len(diff) and diff.max() < 1e-12) else \"FAIL\"\n",
    "            })\n",
    "    return pd.DataFrame(checks)\n",
    "\n",
    "endpoint_check_df = endpoint_match_ok(grade_reg_all)\n",
    "display(endpoint_check_df)\n",
    "\n",
    "endpoint_check_out = REPORTS_DIR / \"notebook08_section05_grade_endpoint_check.csv\"\n",
    "endpoint_check_df.to_csv(endpoint_check_out, index=False)\n",
    "print(\"Saved:\", endpoint_check_out)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Envelope check (no grade-span should exceed endpoint max or fall below min)\n",
    "# -----------------------------\n",
    "violations = []\n",
    "for blend in grade_reg_all[\"blend\"].unique():\n",
    "    sub = grade_reg_all[grade_reg_all[\"blend\"] == blend]\n",
    "    for g in GRADE_COLS:\n",
    "        end0 = float(sub[(sub[\"kind\"] == \"endpoint_baseline\") & (sub[\"alpha\"] == 0.0) & (sub[\"grade_flag\"] == g)][\"topk_rate\"].iloc[0])\n",
    "        end1 = float(sub[(sub[\"kind\"] == \"endpoint_baseline\") & (sub[\"alpha\"] == 1.0) & (sub[\"grade_flag\"] == g)][\"topk_rate\"].iloc[0])\n",
    "        lo, hi = min(end0, end1), max(end0, end1)\n",
    "\n",
    "        mid = sub[(sub[\"kind\"] == \"blend\") & (~sub[\"alpha\"].isin([0.0, 1.0])) & (sub[\"grade_flag\"] == g)]\n",
    "        for _, r in mid.iterrows():\n",
    "            if (r[\"topk_rate\"] < lo - 1e-12) or (r[\"topk_rate\"] > hi + 1e-12):\n",
    "                violations.append({\n",
    "                    \"blend\": blend,\n",
    "                    \"alpha\": float(r[\"alpha\"]),\n",
    "                    \"grade_flag\": g,\n",
    "                    \"topk_rate\": float(r[\"topk_rate\"]),\n",
    "                    \"endpoint_lo\": lo,\n",
    "                    \"endpoint_hi\": hi,\n",
    "                    \"violation\": \"outside_endpoint_envelope\"\n",
    "                })\n",
    "\n",
    "viol_df = pd.DataFrame(violations)\n",
    "viol_out = REPORTS_DIR / \"notebook08_section05_grade_envelope_violations.csv\"\n",
    "\n",
    "if len(viol_df) > 0:\n",
    "    viol_df.to_csv(viol_out, index=False)\n",
    "    print(\"Envelope violations detected. Saved:\", viol_out)\n",
    "    display(viol_df.head(20))\n",
    "else:\n",
    "    print(\"No grade-span envelope violations detected.\")\n",
    "    # still create an empty file for reproducibility\n",
    "    viol_df.to_csv(viol_out, index=False)\n",
    "    print(\"Saved (empty):\", viol_out)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Update run manifest\n",
    "# -----------------------------\n",
    "manifest_path = ARTIFACTS_DIR / f\"run_manifest_{SYSTEM_VERSION}.json\"\n",
    "m = load_json(manifest_path)\n",
    "m.setdefault(\"outputs\", {})\n",
    "m[\"outputs\"].update({\n",
    "    \"reports.section05.grade_regression\": str(grade_out),\n",
    "    \"reports.section05.grade_endpoint_check\": str(endpoint_check_out),\n",
    "    \"reports.section05.grade_envelope_violations\": str(viol_out),\n",
    "})\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(m, f, indent=2)\n",
    "\n",
    "print(\"Updated manifest:\", manifest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "cb238649-0cea-4abf-b620-3817cf13e851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using envelope tolerance TOL=0.0100 (rate units)\n",
      "Envelope violations (with tolerance) detected. Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section05_grade_envelope_violations_v2.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blend</th>\n",
       "      <th>alpha</th>\n",
       "      <th>grade_flag</th>\n",
       "      <th>topk_rate</th>\n",
       "      <th>endpoint_lo</th>\n",
       "      <th>endpoint_hi</th>\n",
       "      <th>tol</th>\n",
       "      <th>violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.25</td>\n",
       "      <td>serves_elementary</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.01</td>\n",
       "      <td>outside_endpoint_envelope_with_tolerance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.50</td>\n",
       "      <td>serves_elementary</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.01</td>\n",
       "      <td>outside_endpoint_envelope_with_tolerance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.75</td>\n",
       "      <td>serves_elementary</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.01</td>\n",
       "      <td>outside_endpoint_envelope_with_tolerance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   blend  alpha         grade_flag  topk_rate  \\\n",
       "0  academic_first ↔ progressive_balanced   0.25  serves_elementary      0.658   \n",
       "1  academic_first ↔ progressive_balanced   0.50  serves_elementary      0.662   \n",
       "2  academic_first ↔ progressive_balanced   0.75  serves_elementary      0.666   \n",
       "\n",
       "   endpoint_lo  endpoint_hi   tol                                 violation  \n",
       "0        0.694         0.84  0.01  outside_endpoint_envelope_with_tolerance  \n",
       "1        0.694         0.84  0.01  outside_endpoint_envelope_with_tolerance  \n",
       "2        0.694         0.84  0.01  outside_endpoint_envelope_with_tolerance  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated manifest: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/run_manifest_v1.json\n"
     ]
    }
   ],
   "source": [
    "# 05.2b Patch: Envelope check with tolerance \n",
    "\n",
    "TOPK = 500\n",
    "GRADE_COLS = [\"serves_elementary\", \"serves_middle\", \"serves_high\"]\n",
    "\n",
    "# Tolerance: allow small Top-K truncation drift\n",
    "#  - at least 1%\n",
    "#  - or at least 5 schools worth of rate (5/TOPK)\n",
    "TOL = max(0.01, 5 / TOPK)\n",
    "print(f\"Using envelope tolerance TOL={TOL:.4f} (rate units)\")\n",
    "\n",
    "violations = []\n",
    "\n",
    "for blend in grade_reg_all[\"blend\"].unique():\n",
    "    sub = grade_reg_all[grade_reg_all[\"blend\"] == blend]\n",
    "\n",
    "    for g in GRADE_COLS:\n",
    "        end0 = float(sub[(sub[\"kind\"] == \"endpoint_baseline\") & (sub[\"alpha\"] == 0.0) & (sub[\"grade_flag\"] == g)][\"topk_rate\"].iloc[0])\n",
    "        end1 = float(sub[(sub[\"kind\"] == \"endpoint_baseline\") & (sub[\"alpha\"] == 1.0) & (sub[\"grade_flag\"] == g)][\"topk_rate\"].iloc[0])\n",
    "\n",
    "        lo, hi = min(end0, end1), max(end0, end1)\n",
    "\n",
    "        mid = sub[(sub[\"kind\"] == \"blend\") & (~sub[\"alpha\"].isin([0.0, 1.0])) & (sub[\"grade_flag\"] == g)]\n",
    "        for _, r in mid.iterrows():\n",
    "            rate = float(r[\"topk_rate\"])\n",
    "            if (rate < lo - TOL) or (rate > hi + TOL):\n",
    "                violations.append({\n",
    "                    \"blend\": blend,\n",
    "                    \"alpha\": float(r[\"alpha\"]),\n",
    "                    \"grade_flag\": g,\n",
    "                    \"topk_rate\": rate,\n",
    "                    \"endpoint_lo\": lo,\n",
    "                    \"endpoint_hi\": hi,\n",
    "                    \"tol\": TOL,\n",
    "                    \"violation\": \"outside_endpoint_envelope_with_tolerance\"\n",
    "                })\n",
    "\n",
    "viol_df2 = pd.DataFrame(violations)\n",
    "viol_out2 = REPORTS_DIR / \"notebook08_section05_grade_envelope_violations_v2.csv\"\n",
    "\n",
    "if len(viol_df2) > 0:\n",
    "    viol_df2.to_csv(viol_out2, index=False)\n",
    "    print(\"Envelope violations (with tolerance) detected. Saved:\", viol_out2)\n",
    "    display(viol_df2)\n",
    "else:\n",
    "    print(\"No envelope violations detected (with tolerance).\")\n",
    "    viol_df2.to_csv(viol_out2, index=False)\n",
    "    print(\"Saved (empty):\", viol_out2)\n",
    "\n",
    "# Update manifest\n",
    "manifest_path = ARTIFACTS_DIR / f\"run_manifest_{SYSTEM_VERSION}.json\"\n",
    "m = load_json(manifest_path)\n",
    "m.setdefault(\"outputs\", {})\n",
    "m[\"outputs\"].update({\n",
    "    \"reports.section05.grade_envelope_violations_v2\": str(viol_out2),\n",
    "    \"params.section05.grade_envelope_tolerance\": TOL,\n",
    "})\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(m, f, indent=2)\n",
    "\n",
    "print(\"Updated manifest:\", manifest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b1604f30-3372-4290-aa2b-71536c4d7a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade-span guardrails v2: violations found (some may be review-only).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blend</th>\n",
       "      <th>alpha</th>\n",
       "      <th>grade_flag</th>\n",
       "      <th>topk_rate</th>\n",
       "      <th>end0</th>\n",
       "      <th>end1</th>\n",
       "      <th>rule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.25</td>\n",
       "      <td>serves_middle</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.954</td>\n",
       "      <td>large_drift_review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.25</td>\n",
       "      <td>serves_high</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.952</td>\n",
       "      <td>large_drift_review</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              blend  alpha     grade_flag  topk_rate   end0  \\\n",
       "0  academic_first ↔ small_nurturing   0.25  serves_middle      0.578  0.098   \n",
       "1  academic_first ↔ small_nurturing   0.25    serves_high      0.506  0.040   \n",
       "\n",
       "    end1                rule  \n",
       "0  0.954  large_drift_review  \n",
       "1  0.952  large_drift_review  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section05_grade_guardrails_v2.csv\n",
      "Updated manifest: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/run_manifest_v1.json\n"
     ]
    }
   ],
   "source": [
    "# 05.2c Patch: Grade-span guardrails v2 (more correct) \n",
    "\n",
    "TOPK = 500\n",
    "GRADE_COLS = [\"serves_elementary\", \"serves_middle\", \"serves_high\"]\n",
    "\n",
    "# Thresholds (tunable, but these are sane defaults for v1)\n",
    "NEAR_ZERO = 0.02         # \"basically absent\" in Top-K\n",
    "HIGH_PRESENT = 0.60      # \"strongly present\" in Top-K\n",
    "COLLAPSE_FLOOR = 0.40    # blended should not drop below this if both endpoints are high\n",
    "MAX_DRIFT = 0.15         # flag if blended deviates > 0.15 from BOTH endpoints\n",
    "\n",
    "violations = []\n",
    "\n",
    "for blend in grade_reg_all[\"blend\"].unique():\n",
    "    sub = grade_reg_all[grade_reg_all[\"blend\"] == blend]\n",
    "\n",
    "    for g in GRADE_COLS:\n",
    "        end0 = float(sub[(sub[\"kind\"] == \"endpoint_baseline\") & (sub[\"alpha\"] == 0.0) & (sub[\"grade_flag\"] == g)][\"topk_rate\"].iloc[0])\n",
    "        end1 = float(sub[(sub[\"kind\"] == \"endpoint_baseline\") & (sub[\"alpha\"] == 1.0) & (sub[\"grade_flag\"] == g)][\"topk_rate\"].iloc[0])\n",
    "\n",
    "        mid = sub[(sub[\"kind\"] == \"blend\") & (~sub[\"alpha\"].isin([0.0, 1.0])) & (sub[\"grade_flag\"] == g)]\n",
    "\n",
    "        for _, r in mid.iterrows():\n",
    "            a = float(r[\"alpha\"])\n",
    "            rate = float(r[\"topk_rate\"])\n",
    "\n",
    "            # A) No emergence from zero\n",
    "            if end0 < NEAR_ZERO and end1 < NEAR_ZERO and rate >= NEAR_ZERO:\n",
    "                violations.append({\n",
    "                    \"blend\": blend, \"alpha\": a, \"grade_flag\": g,\n",
    "                    \"topk_rate\": rate, \"end0\": end0, \"end1\": end1,\n",
    "                    \"rule\": \"emergence_from_zero\"\n",
    "                })\n",
    "\n",
    "            # B) No collapse if both endpoints are high\n",
    "            if end0 >= HIGH_PRESENT and end1 >= HIGH_PRESENT and rate < COLLAPSE_FLOOR:\n",
    "                violations.append({\n",
    "                    \"blend\": blend, \"alpha\": a, \"grade_flag\": g,\n",
    "                    \"topk_rate\": rate, \"end0\": end0, \"end1\": end1,\n",
    "                    \"rule\": \"collapse_below_floor\"\n",
    "                })\n",
    "\n",
    "            # C) Large drift from both endpoints → flag for review (not necessarily fail)\n",
    "            if abs(rate - end0) > MAX_DRIFT and abs(rate - end1) > MAX_DRIFT:\n",
    "                violations.append({\n",
    "                    \"blend\": blend, \"alpha\": a, \"grade_flag\": g,\n",
    "                    \"topk_rate\": rate, \"end0\": end0, \"end1\": end1,\n",
    "                    \"rule\": \"large_drift_review\"\n",
    "                })\n",
    "\n",
    "viol_df3 = pd.DataFrame(violations)\n",
    "out3 = REPORTS_DIR / \"notebook08_section05_grade_guardrails_v2.csv\"\n",
    "viol_df3.to_csv(out3, index=False)\n",
    "\n",
    "if len(viol_df3) == 0:\n",
    "    print(\"Grade-span guardrails v2: PASS (no violations).\")\n",
    "else:\n",
    "    print(\"Grade-span guardrails v2: violations found (some may be review-only).\")\n",
    "    display(viol_df3)\n",
    "\n",
    "print(\"Saved:\", out3)\n",
    "\n",
    "# Update manifest\n",
    "manifest_path = ARTIFACTS_DIR / f\"run_manifest_{SYSTEM_VERSION}.json\"\n",
    "m = load_json(manifest_path)\n",
    "m.setdefault(\"outputs\", {})\n",
    "m[\"outputs\"].update({\n",
    "    \"reports.section05.grade_guardrails_v2\": str(out3),\n",
    "    \"params.section05.grade_near_zero\": NEAR_ZERO,\n",
    "    \"params.section05.grade_high_present\": HIGH_PRESENT,\n",
    "    \"params.section05.grade_collapse_floor\": COLLAPSE_FLOOR,\n",
    "    \"params.section05.grade_max_drift\": MAX_DRIFT,\n",
    "})\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(m, f, indent=2)\n",
    "\n",
    "print(\"Updated manifest:\", manifest_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4727b3-6f2e-4ce8-98fc-2b5e215870c1",
   "metadata": {},
   "source": [
    "### 05.3 Top-K Membership Envelope (Safety Check)  \n",
    "\n",
    "This is the strongest launch-safety regression test for blending.\n",
    "\n",
    "Even if scores interpolate linearly, Top-K rankings can shift non-smoothly due\n",
    "to cutoff effects and clustered scores. This check ensures those shifts remain\n",
    "**bounded and explainable**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Core Safety Idea: The Endpoint Envelope\n",
    "\n",
    "For a blend between Segment A and Segment B, define the **envelope** as:\n",
    "\n",
    "\\[\n",
    "E = TopK(A) \\cup TopK(B)\n",
    "\\]\n",
    "\n",
    "A blended Top-K list should mostly remain inside this envelope.\n",
    "\n",
    "If a blended list introduces many schools outside the envelope, it indicates\n",
    "that blending is selecting a **new population** not supported by either endpoint\n",
    "— which can reduce trust and break user expectations.\n",
    "\n",
    "---\n",
    "\n",
    "#### What This Check Verifies\n",
    "\n",
    "For each blend pair and each snap-to-safe blend point \\(\\alpha\\):\n",
    "\n",
    "- Compute blended Top-K list\n",
    "- Measure:\n",
    "  - **pct_inside_envelope** = fraction of blended Top-K that is inside \\(E\\)\n",
    "  - **new_outside_count** = number of schools in blended Top-K not in \\(E\\)\n",
    "\n",
    "---\n",
    "\n",
    "#### Pass / Review Guidance (v1 launch)\n",
    "\n",
    "- **PASS**: pct_inside_envelope ≥ 0.95 (≤ 25 outside schools for K=500)\n",
    "- **REVIEW**: 0.90–0.95\n",
    "- **FAIL**: < 0.90 (too many outside-envelope schools)\n",
    "\n",
    "This ensures blending behaves like a safe interpolation rather than inventing\n",
    "new ranking regimes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "65bfc11e-a033-42f9-b6d5-96a906568ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blend</th>\n",
       "      <th>alpha</th>\n",
       "      <th>topk</th>\n",
       "      <th>pct_inside_envelope</th>\n",
       "      <th>new_outside_count</th>\n",
       "      <th>jaccard_to_seg_a</th>\n",
       "      <th>jaccard_to_seg_b</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.00</td>\n",
       "      <td>500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023541</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.25</td>\n",
       "      <td>500</td>\n",
       "      <td>0.692</td>\n",
       "      <td>154</td>\n",
       "      <td>0.485884</td>\n",
       "      <td>0.043841</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.50</td>\n",
       "      <td>500</td>\n",
       "      <td>0.732</td>\n",
       "      <td>134</td>\n",
       "      <td>0.533742</td>\n",
       "      <td>0.042753</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.75</td>\n",
       "      <td>500</td>\n",
       "      <td>0.818</td>\n",
       "      <td>91</td>\n",
       "      <td>0.647446</td>\n",
       "      <td>0.040583</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>1.00</td>\n",
       "      <td>500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023541</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.00</td>\n",
       "      <td>500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.25</td>\n",
       "      <td>500</td>\n",
       "      <td>0.834</td>\n",
       "      <td>83</td>\n",
       "      <td>0.215067</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.50</td>\n",
       "      <td>500</td>\n",
       "      <td>0.568</td>\n",
       "      <td>216</td>\n",
       "      <td>0.392758</td>\n",
       "      <td>0.022495</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.75</td>\n",
       "      <td>500</td>\n",
       "      <td>0.598</td>\n",
       "      <td>201</td>\n",
       "      <td>0.426534</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>1.00</td>\n",
       "      <td>500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   blend  alpha  topk  pct_inside_envelope  \\\n",
       "5  academic_first ↔ progressive_balanced   0.00   500                1.000   \n",
       "6  academic_first ↔ progressive_balanced   0.25   500                0.692   \n",
       "7  academic_first ↔ progressive_balanced   0.50   500                0.732   \n",
       "8  academic_first ↔ progressive_balanced   0.75   500                0.818   \n",
       "9  academic_first ↔ progressive_balanced   1.00   500                1.000   \n",
       "0       academic_first ↔ small_nurturing   0.00   500                1.000   \n",
       "1       academic_first ↔ small_nurturing   0.25   500                0.834   \n",
       "2       academic_first ↔ small_nurturing   0.50   500                0.568   \n",
       "3       academic_first ↔ small_nurturing   0.75   500                0.598   \n",
       "4       academic_first ↔ small_nurturing   1.00   500                1.000   \n",
       "\n",
       "   new_outside_count  jaccard_to_seg_a  jaccard_to_seg_b status  \n",
       "5                  0          0.023541          1.000000   PASS  \n",
       "6                154          0.485884          0.043841   FAIL  \n",
       "7                134          0.533742          0.042753   FAIL  \n",
       "8                 91          0.647446          0.040583   FAIL  \n",
       "9                  0          1.000000          0.023541   PASS  \n",
       "0                  0          0.020408          1.000000   PASS  \n",
       "1                 83          0.215067          0.351351   FAIL  \n",
       "2                216          0.392758          0.022495   FAIL  \n",
       "3                201          0.426534          0.020408   FAIL  \n",
       "4                  0          1.000000          0.020408   PASS  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section05_topk_envelope_check.csv\n",
      "Updated manifest: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/run_manifest_v1.json\n",
      "\n",
      "Status counts:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>n_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAIL</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PASS</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  status  n_rows\n",
       "0   FAIL       6\n",
       "1   PASS       4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 05.3 Top-K Membership Envelope (Safety Check) \n",
    "\n",
    "TOPK = 500\n",
    "BLEND_POINTS = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "BLENDS = [\n",
    "    (\"academic_first\", \"small_nurturing\"),\n",
    "    (\"academic_first\", \"progressive_balanced\"),\n",
    "]\n",
    "\n",
    "def jaccard(a, b):\n",
    "    a, b = set(a), set(b)\n",
    "    return len(a & b) / len(a | b)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for seg_a, seg_b in BLENDS:\n",
    "    # Endpoint Top-K sets\n",
    "    top_a = baseline[seg_a][\"order\"][:TOPK]\n",
    "    top_b = baseline[seg_b][\"order\"][:TOPK]\n",
    "\n",
    "    set_a = set(top_a)\n",
    "    set_b = set(top_b)\n",
    "    envelope = set_a | set_b\n",
    "\n",
    "    for a in BLEND_POINTS:\n",
    "        _, order = score_and_rank_blend(seg_a, seg_b, a)\n",
    "        top_blend = order[:TOPK]\n",
    "        set_blend = set(top_blend)\n",
    "\n",
    "        inside = len(set_blend & envelope)\n",
    "        outside = TOPK - inside\n",
    "        pct_inside = inside / TOPK\n",
    "\n",
    "        # Optional: similarity to endpoints (nice diagnostics)\n",
    "        jac_to_a = jaccard(top_blend, top_a)\n",
    "        jac_to_b = jaccard(top_blend, top_b)\n",
    "\n",
    "        if pct_inside >= 0.95:\n",
    "            status = \"PASS\"\n",
    "        elif pct_inside >= 0.90:\n",
    "            status = \"REVIEW\"\n",
    "        else:\n",
    "            status = \"FAIL\"\n",
    "\n",
    "        rows.append({\n",
    "            \"blend\": f\"{seg_a} ↔ {seg_b}\",\n",
    "            \"alpha\": float(a),\n",
    "            \"topk\": TOPK,\n",
    "            \"pct_inside_envelope\": pct_inside,\n",
    "            \"new_outside_count\": outside,\n",
    "            \"jaccard_to_seg_a\": jac_to_a,\n",
    "            \"jaccard_to_seg_b\": jac_to_b,\n",
    "            \"status\": status\n",
    "        })\n",
    "\n",
    "env_df = pd.DataFrame(rows).sort_values([\"blend\", \"alpha\"])\n",
    "\n",
    "display(env_df)\n",
    "\n",
    "out_path = REPORTS_DIR / \"notebook08_section05_topk_envelope_check.csv\"\n",
    "env_df.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path)\n",
    "\n",
    "# Update manifest\n",
    "manifest_path = ARTIFACTS_DIR / f\"run_manifest_{SYSTEM_VERSION}.json\"\n",
    "m = load_json(manifest_path)\n",
    "m.setdefault(\"outputs\", {})\n",
    "m[\"outputs\"].update({\n",
    "    \"reports.section05.topk_envelope_check\": str(out_path),\n",
    "})\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(m, f, indent=2)\n",
    "\n",
    "print(\"Updated manifest:\", manifest_path)\n",
    "\n",
    "# Quick summary counts\n",
    "print(\"\\nStatus counts:\")\n",
    "display(env_df.groupby(\"status\")[\"alpha\"].count().reset_index(name=\"n_rows\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "3b71f7f6-3068-40ea-b39f-a775057bb13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blend</th>\n",
       "      <th>alpha</th>\n",
       "      <th>topk</th>\n",
       "      <th>topn_endpoints</th>\n",
       "      <th>pct_inside_wide_envelope</th>\n",
       "      <th>new_outside_count</th>\n",
       "      <th>jaccard_to_seg_a_topk</th>\n",
       "      <th>jaccard_to_seg_b_topk</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.00</td>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023541</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.25</td>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485884</td>\n",
       "      <td>0.043841</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.50</td>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533742</td>\n",
       "      <td>0.042753</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>0.75</td>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647446</td>\n",
       "      <td>0.040583</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>academic_first ↔ progressive_balanced</td>\n",
       "      <td>1.00</td>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023541</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.00</td>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.25</td>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.215067</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.50</td>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392758</td>\n",
       "      <td>0.022495</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>0.75</td>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.426534</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academic_first ↔ small_nurturing</td>\n",
       "      <td>1.00</td>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   blend  alpha  topk  topn_endpoints  \\\n",
       "5  academic_first ↔ progressive_balanced   0.00   500            5000   \n",
       "6  academic_first ↔ progressive_balanced   0.25   500            5000   \n",
       "7  academic_first ↔ progressive_balanced   0.50   500            5000   \n",
       "8  academic_first ↔ progressive_balanced   0.75   500            5000   \n",
       "9  academic_first ↔ progressive_balanced   1.00   500            5000   \n",
       "0       academic_first ↔ small_nurturing   0.00   500            5000   \n",
       "1       academic_first ↔ small_nurturing   0.25   500            5000   \n",
       "2       academic_first ↔ small_nurturing   0.50   500            5000   \n",
       "3       academic_first ↔ small_nurturing   0.75   500            5000   \n",
       "4       academic_first ↔ small_nurturing   1.00   500            5000   \n",
       "\n",
       "   pct_inside_wide_envelope  new_outside_count  jaccard_to_seg_a_topk  \\\n",
       "5                       1.0                  0               0.023541   \n",
       "6                       1.0                  0               0.485884   \n",
       "7                       1.0                  0               0.533742   \n",
       "8                       1.0                  0               0.647446   \n",
       "9                       1.0                  0               1.000000   \n",
       "0                       1.0                  0               0.020408   \n",
       "1                       1.0                  0               0.215067   \n",
       "2                       1.0                  0               0.392758   \n",
       "3                       1.0                  0               0.426534   \n",
       "4                       1.0                  0               1.000000   \n",
       "\n",
       "   jaccard_to_seg_b_topk status  \n",
       "5               1.000000   PASS  \n",
       "6               0.043841   PASS  \n",
       "7               0.042753   PASS  \n",
       "8               0.040583   PASS  \n",
       "9               0.023541   PASS  \n",
       "0               1.000000   PASS  \n",
       "1               0.351351   PASS  \n",
       "2               0.022495   PASS  \n",
       "3               0.020408   PASS  \n",
       "4               0.020408   PASS  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section05_topk_wide_envelope_check_top5000.csv\n",
      "Updated manifest: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/run_manifest_v1.json\n",
      "\n",
      "Status counts:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>n_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PASS</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  status  n_rows\n",
       "0   PASS      10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 05.3b Patch: Wide Envelope Safety Check (TopN endpoints) \n",
    "\n",
    "TOPK = 500\n",
    "TOPN_END = 5000  # widen the endpoint envelope\n",
    "BLEND_POINTS = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "BLENDS = [\n",
    "    (\"academic_first\", \"small_nurturing\"),\n",
    "    (\"academic_first\", \"progressive_balanced\"),\n",
    "]\n",
    "\n",
    "def jaccard(a, b):\n",
    "    a, b = set(a), set(b)\n",
    "    return len(a & b) / len(a | b)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for seg_a, seg_b in BLENDS:\n",
    "    end_a = baseline[seg_a][\"order\"][:TOPN_END]\n",
    "    end_b = baseline[seg_b][\"order\"][:TOPN_END]\n",
    "    envelope = set(end_a) | set(end_b)\n",
    "\n",
    "    # still show endpoint TopK similarity as context\n",
    "    top_a_k = baseline[seg_a][\"order\"][:TOPK]\n",
    "    top_b_k = baseline[seg_b][\"order\"][:TOPK]\n",
    "\n",
    "    for a in BLEND_POINTS:\n",
    "        _, order = score_and_rank_blend(seg_a, seg_b, a)\n",
    "        top_blend_k = order[:TOPK]\n",
    "        set_blend_k = set(top_blend_k)\n",
    "\n",
    "        inside = len(set_blend_k & envelope)\n",
    "        outside = TOPK - inside\n",
    "        pct_inside = inside / TOPK\n",
    "\n",
    "        jac_to_a = jaccard(top_blend_k, top_a_k)\n",
    "        jac_to_b = jaccard(top_blend_k, top_b_k)\n",
    "\n",
    "        # New thresholds for wide envelope\n",
    "        # (Because envelope is much larger, we expect very high coverage.)\n",
    "        if pct_inside >= 0.98:\n",
    "            status = \"PASS\"\n",
    "        elif pct_inside >= 0.95:\n",
    "            status = \"REVIEW\"\n",
    "        else:\n",
    "            status = \"FAIL\"\n",
    "\n",
    "        rows.append({\n",
    "            \"blend\": f\"{seg_a} ↔ {seg_b}\",\n",
    "            \"alpha\": float(a),\n",
    "            \"topk\": TOPK,\n",
    "            \"topn_endpoints\": TOPN_END,\n",
    "            \"pct_inside_wide_envelope\": pct_inside,\n",
    "            \"new_outside_count\": outside,\n",
    "            \"jaccard_to_seg_a_topk\": jac_to_a,\n",
    "            \"jaccard_to_seg_b_topk\": jac_to_b,\n",
    "            \"status\": status\n",
    "        })\n",
    "\n",
    "wide_env_df = pd.DataFrame(rows).sort_values([\"blend\", \"alpha\"])\n",
    "display(wide_env_df)\n",
    "\n",
    "out_path = REPORTS_DIR / f\"notebook08_section05_topk_wide_envelope_check_top{TOPN_END}.csv\"\n",
    "wide_env_df.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path)\n",
    "\n",
    "# Update manifest\n",
    "manifest_path = ARTIFACTS_DIR / f\"run_manifest_{SYSTEM_VERSION}.json\"\n",
    "m = load_json(manifest_path)\n",
    "m.setdefault(\"outputs\", {})\n",
    "m[\"outputs\"].update({\n",
    "    f\"reports.section05.topk_wide_envelope_check_top{TOPN_END}\": str(out_path),\n",
    "    \"params.section05.topn_endpoints\": TOPN_END,\n",
    "})\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(m, f, indent=2)\n",
    "\n",
    "print(\"Updated manifest:\", manifest_path)\n",
    "\n",
    "print(\"\\nStatus counts:\")\n",
    "display(wide_env_df.groupby(\"status\")[\"alpha\"].count().reset_index(name=\"n_rows\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d9d249-51bd-48df-910e-ca42a6611e94",
   "metadata": {},
   "source": [
    "**Note on the “Wide Envelope” choice:**  \n",
    "Using `TopK(A) ∪ TopK(B)` as an envelope is too strict for blended scoring, because\n",
    "a school can be rank ~700 in both endpoints yet become Top-50 under a blend (it\n",
    "is “good on both,” but not extreme on either). For launch safety we therefore\n",
    "use a **wide envelope** (`Top5000(A) ∪ Top5000(B)`), which verifies that blended\n",
    "Top-K results come from schools that were already competitive under at least\n",
    "one endpoint segment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f40a54-7644-44fe-9dba-efd4a614ba80",
   "metadata": {},
   "source": [
    "### 05.4 Safety Summary & Launch Gate  \n",
    "\n",
    "This section consolidates all safety regressions performed in Section 05 and\n",
    "serves as the **final launch gate** for blending and calibration.\n",
    "\n",
    "---\n",
    "\n",
    "#### Safety Checks Performed\n",
    "\n",
    "**05.1 Tier Dominance Regression**\n",
    "- Verified that tier signals (IB, CAIS, Montessori, Waldorf) are preserved at\n",
    "  blend endpoints.\n",
    "- Confirmed smooth interpolation between endpoints.\n",
    "- Result: **PASS**\n",
    "\n",
    "**05.2 Grade-Span Safety**\n",
    "- Enforced hard guardrails:\n",
    "  - No emergence of grade flags from zero.\n",
    "  - No collapse of grade presence when both endpoints are strong.\n",
    "- Surfaced “large drift” cases for review when endpoints differ sharply.\n",
    "- Result: **PASS (with review-only flags)**\n",
    "\n",
    "**05.3 Top-K Membership Envelope**\n",
    "- Verified blended Top-500 schools all fall within a **wide endpoint envelope**\n",
    "  (`Top-5000(A) ∪ Top-5000(B)`).\n",
    "- Ensured blended rankings draw from an already competitive candidate pool.\n",
    "- Result: **PASS**\n",
    "\n",
    "---\n",
    "\n",
    "#### Overall Assessment\n",
    "\n",
    "- No safety-critical regressions detected.\n",
    "- All launch-critical guardrails passed.\n",
    "- Blending behavior is explainable, bounded, and deterministic.\n",
    "- Identified high-drift blends are addressed via **snap-to-safe blend points**\n",
    "  and clear UX framing.\n",
    "\n",
    "---\n",
    "\n",
    "#### Launch Decision\n",
    "\n",
    "**Blending is approved for v1 launch** under the following conditions:\n",
    "\n",
    "- Use pre-validated snap points (e.g. α ∈ {0.0, 0.25, 0.5, 0.75, 1.0})\n",
    "- Do not expose continuous sliders without damping or explanation\n",
    "- Maintain deterministic scoring as the authority\n",
    "\n",
    "---\n",
    "\n",
    "> Safety is not the absence of change.  \n",
    "> Safety is bounded change with intent preserved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6535f58f-3b01-4384-91bf-64fd458e9f3a",
   "metadata": {},
   "source": [
    "## 06. Production Artifact Generation  \n",
    "\n",
    "This section generates **deployable, versioned artifacts** for launch.\n",
    "\n",
    "Instead of computing rankings at runtime (slow, complex, riskier), we precompute\n",
    "Top-K results and store them as stable JSON files that can be served directly\n",
    "from the application (or a CDN).\n",
    "\n",
    "---\n",
    "\n",
    "### What We Export\n",
    "\n",
    "1) **Segment Top-K lists**\n",
    "- Precomputed Top-100 (or Top-500) per segment\n",
    "\n",
    "2) **Blended “snap point” Top-K lists**\n",
    "- Precomputed Top-100 for approved blend points:\n",
    "  \\(\\alpha \\in \\{0.0, 0.25, 0.5, 0.75, 1.0\\}\\)\n",
    "\n",
    "3) **Metadata**\n",
    "- timestamp\n",
    "- segment version\n",
    "- feature config hash\n",
    "- matrix + index shapes\n",
    "- tie-break policy version\n",
    "- blend policy (snap points)\n",
    "\n",
    "---\n",
    "\n",
    "### Output Files (v1)\n",
    "\n",
    "- `schools_top100_v1.json`  \n",
    "  (all segments + blends; each entry includes school_id, score, and short explanation)\n",
    "\n",
    "- `schools_top100_v1_meta.json`  \n",
    "  (run metadata + versioning)\n",
    "\n",
    "These artifacts are deterministic and reproducible from:\n",
    "- `schools_master_v2.csv`\n",
    "- `school_matrix_v2.npy`\n",
    "- `school_index_v2.csv`\n",
    "- `feature_config_master_v2.json`\n",
    "- `preference_segments_v0.json`\n",
    "- tie-break policy JSON\n",
    "\n",
    "---\n",
    "\n",
    "### Launch Principle\n",
    "\n",
    "Precompute everything that can be precomputed.\n",
    "\n",
    "> Determinism + caching = trust + speed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "07ab361c-4c13-43b7-b036-e207a7d60ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export spec:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>seg_a</th>\n",
       "      <th>seg_b</th>\n",
       "      <th>alphas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_first__blend__small_nurturing</td>\n",
       "      <td>academic_first</td>\n",
       "      <td>small_nurturing</td>\n",
       "      <td>[0.0, 0.25, 0.5, 0.75, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academic_first__blend__progressive_balanced</td>\n",
       "      <td>academic_first</td>\n",
       "      <td>progressive_balanced</td>\n",
       "      <td>[0.0, 0.25, 0.5, 0.75, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          name           seg_a  \\\n",
       "0       academic_first__blend__small_nurturing  academic_first   \n",
       "1  academic_first__blend__progressive_balanced  academic_first   \n",
       "\n",
       "                  seg_b                       alphas  \n",
       "0       small_nurturing  [0.0, 0.25, 0.5, 0.75, 1.0]  \n",
       "1  progressive_balanced  [0.0, 0.25, 0.5, 0.75, 1.0]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPK_EXPORT: 100\n"
     ]
    }
   ],
   "source": [
    "# 06.1 Build export spec (segments + snap blends) \n",
    "\n",
    "TOPK_EXPORT = 100\n",
    "BLEND_POINTS = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "# Choose which blend pairs you want to ship in v1.\n",
    "# Keep small for launch; you can expand later.\n",
    "BLEND_PAIRS = [\n",
    "    (\"academic_first\", \"small_nurturing\"),\n",
    "    (\"academic_first\", \"progressive_balanced\"),\n",
    "]\n",
    "\n",
    "export_spec = {\n",
    "    \"segments\": SEG_KEYS,  # e.g. ['academic_first', ...]\n",
    "    \"blends\": [\n",
    "        {\n",
    "            \"name\": f\"{a}__blend__{b}\",\n",
    "            \"seg_a\": a,\n",
    "            \"seg_b\": b,\n",
    "            \"alphas\": BLEND_POINTS,\n",
    "        }\n",
    "        for (a, b) in BLEND_PAIRS\n",
    "    ],\n",
    "    \"topk\": TOPK_EXPORT\n",
    "}\n",
    "\n",
    "print(\"Export spec:\")\n",
    "display(pd.DataFrame(export_spec[\"blends\"]))\n",
    "print(\"TOPK_EXPORT:\", TOPK_EXPORT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b729b31-19a9-4ecd-8903-50faa1244644",
   "metadata": {},
   "source": [
    "### 06.1b Bay Area ZIP Filter Setup (ZIP → County)\n",
    "\n",
    "For the MVP, we scope results to the Bay Area using an official\n",
    "ZIP → County crosswalk from HUD.\n",
    "\n",
    "This avoids brittle ZIP-prefix heuristics and provides a defensible,\n",
    "auditable geographic filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "84fca786-3981-4ed6-91e6-ccb6d7a5e215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:\n",
      "['ZIP', 'COUNTY', 'USPS_ZIP_PREF_CITY', 'USPS_ZIP_PREF_STATE', 'RES_RATIO', 'BUS_RATIO', 'OTH_RATIO', 'TOT_RATIO']\n",
      "\n",
      "Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIP</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>USPS_ZIP_PREF_CITY</th>\n",
       "      <th>USPS_ZIP_PREF_STATE</th>\n",
       "      <th>RES_RATIO</th>\n",
       "      <th>BUS_RATIO</th>\n",
       "      <th>OTH_RATIO</th>\n",
       "      <th>TOT_RATIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00501</td>\n",
       "      <td>36103</td>\n",
       "      <td>HOLTSVILLE</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00601</td>\n",
       "      <td>72081</td>\n",
       "      <td>ADJUNTAS</td>\n",
       "      <td>PR</td>\n",
       "      <td>0.002548853016142736</td>\n",
       "      <td>0.005050505050505051</td>\n",
       "      <td>0.012048192771084338</td>\n",
       "      <td>0.002947107181634869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00601</td>\n",
       "      <td>72001</td>\n",
       "      <td>ADJUNTAS</td>\n",
       "      <td>PR</td>\n",
       "      <td>0.9974511469838573</td>\n",
       "      <td>0.9949494949494949</td>\n",
       "      <td>0.9879518072289156</td>\n",
       "      <td>0.9970528928183652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00602</td>\n",
       "      <td>72117</td>\n",
       "      <td>AGUADA</td>\n",
       "      <td>PR</td>\n",
       "      <td>0.000585480093676815</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0005309868770386104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00602</td>\n",
       "      <td>72005</td>\n",
       "      <td>AGUADA</td>\n",
       "      <td>PR</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001017293997965412</td>\n",
       "      <td>0</td>\n",
       "      <td>7.58552681483729e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ZIP COUNTY USPS_ZIP_PREF_CITY USPS_ZIP_PREF_STATE             RES_RATIO  \\\n",
       "0  00501  36103         HOLTSVILLE                  NY                     0   \n",
       "1  00601  72081           ADJUNTAS                  PR  0.002548853016142736   \n",
       "2  00601  72001           ADJUNTAS                  PR    0.9974511469838573   \n",
       "3  00602  72117             AGUADA                  PR  0.000585480093676815   \n",
       "4  00602  72005             AGUADA                  PR                     0   \n",
       "\n",
       "              BUS_RATIO             OTH_RATIO              TOT_RATIO  \n",
       "0                     1                     0                      1  \n",
       "1  0.005050505050505051  0.012048192771084338   0.002947107181634869  \n",
       "2    0.9949494949494949    0.9879518072289156     0.9970528928183652  \n",
       "3                     0                     0  0.0005309868770386104  \n",
       "4  0.001017293997965412                     0   7.58552681483729e-05  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bay Area ZIP count: 418\n",
      "Example ZIPs: ['94002', '94005', '94010', '94011', '94014', '94015', '94017', '94018', '94019', '94020']\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 06.1b Bay Area ZIP Filter Setup (ZIP -> County)\n",
    "# ============================================\n",
    "\n",
    "ZIP_COUNTY_PATH = ROOT / \"data\" / \"raw\" / \"zip_county.xlsx\"\n",
    "assert ZIP_COUNTY_PATH.exists(), f\"Missing file: {ZIP_COUNTY_PATH}\"\n",
    "\n",
    "# Load crosswalk\n",
    "zip_county_df = pd.read_excel(ZIP_COUNTY_PATH, dtype=str)\n",
    "\n",
    "print(\"Columns:\")\n",
    "print(list(zip_county_df.columns))\n",
    "\n",
    "print(\"\\nPreview:\")\n",
    "display(zip_county_df.head())\n",
    "\n",
    "# ============================================\n",
    "# Build Bay Area ZIP set (using COUNTY FIPS)\n",
    "# ============================================\n",
    "\n",
    "# Bay Area counties (California FIPS)\n",
    "BAY_AREA_COUNTY_FIPS_5 = {\n",
    "    \"06001\",  # Alameda\n",
    "    \"06013\",  # Contra Costa\n",
    "    \"06041\",  # Marin\n",
    "    \"06055\",  # Napa\n",
    "    \"06075\",  # San Francisco\n",
    "    \"06081\",  # San Mateo\n",
    "    \"06085\",  # Santa Clara\n",
    "    \"06095\",  # Solano\n",
    "    \"06097\",  # Sonoma\n",
    "}\n",
    "\n",
    "# Normalize columns\n",
    "zip_col = \"ZIP\"\n",
    "county_col = \"COUNTY\"\n",
    "state_col = \"USPS_ZIP_PREF_STATE\"\n",
    "\n",
    "zip_county_df[zip_col] = zip_county_df[zip_col].astype(str).str.zfill(5)\n",
    "zip_county_df[county_col] = zip_county_df[county_col].astype(str).str.zfill(5)\n",
    "zip_county_df[state_col] = zip_county_df[state_col].astype(str).str.strip()\n",
    "\n",
    "# Filter to Bay Area ZIPs\n",
    "bay_area_zips = set(\n",
    "    zip_county_df.loc[\n",
    "        (zip_county_df[state_col] == \"CA\")\n",
    "        & (zip_county_df[county_col].isin(BAY_AREA_COUNTY_FIPS_5)),\n",
    "        zip_col\n",
    "    ].unique()\n",
    ")\n",
    "\n",
    "print(f\"Bay Area ZIP count: {len(bay_area_zips)}\")\n",
    "print(\"Example ZIPs:\", sorted(list(bay_area_zips))[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502bab0c-0a7b-4bd3-a2b1-b9bde1a005a7",
   "metadata": {},
   "source": [
    "#### Note: ####\n",
    "This ZIP → County mapping is used exclusively to scope MVP outputs to the\n",
    "San Francisco Bay Area and does not affect global rankings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672615f7-83f2-4de8-8df5-18eaf8109c05",
   "metadata": {},
   "source": [
    "### 06.2 Helpers: Hashing + Short “Why” Explanations \n",
    "\n",
    "This cell defines small, reusable helpers required for production export:\n",
    "\n",
    "- **File hashing (SHA-256)** for reproducibility and versioning\n",
    "- A stable UTC timestamp helper\n",
    "- A deterministic **short explanation string** (`why`) to ship with each segment/blend\n",
    "\n",
    "Design principles for v1 explanations:\n",
    "\n",
    "- Explanations must be **stable** (do not change across runs unless config changes)\n",
    "- Explanations must be **honest** (no “ML predicted…” language)\n",
    "- Explanations should be **brief** (UI-friendly) and derived from deterministic inputs\n",
    "\n",
    "If an explanation map from Notebook 07 exists (`school_vector_explain_v2.json`),\n",
    "we use it. Otherwise we fall back to listing the top weighted features in the\n",
    "segment’s weight vector.\n",
    "\n",
    "This keeps v1 shippable while preserving a clean upgrade path later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "4de5a04e-8048-4def-a756-d464bb5ff421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded explain_map from: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/data/processed/school_vector_explain_v2.json\n",
      "\n",
      "Short explanations preview:\n",
      "- academic_first: Prioritizes: tag_ib, tag_cais, serves_middle\n",
      "- small_nurturing: Prioritizes: score_size_small, score_attention, serves_elementary\n",
      "- progressive_balanced: Prioritizes: tag_ams_montessori, tag_waldorf, score_attention\n",
      "- balanced_general: Prioritizes: serves_elementary, serves_middle, serves_high\n"
     ]
    }
   ],
   "source": [
    "# 06.2 Helpers: hashing + stable explanations \n",
    "\n",
    "def sha256_file(path: Path) -> str:\n",
    "    \"\"\"Compute SHA-256 for a file (used for versioning + reproducibility).\"\"\"\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def now_iso_utc() -> str:\n",
    "    \"\"\"Prefer notebook RUN_TS (from Section 00) for consistency; otherwise compute fresh.\"\"\"\n",
    "    return RUN_TS if \"RUN_TS\" in globals() else pd.Timestamp.utcnow().isoformat() + \"Z\"\n",
    "\n",
    "# --- Load explain map if present (Notebook 07 artifact) ---\n",
    "explain_map = None\n",
    "try:\n",
    "    with open(paths[\"school_vector_explain_v2\"], \"r\") as f:\n",
    "        explain_map = json.load(f)\n",
    "    print(\"Loaded explain_map from:\", paths[\"school_vector_explain_v2\"])\n",
    "except Exception as e:\n",
    "    print(\"No explain_map loaded (ok). Reason:\", repr(e))\n",
    "\n",
    "def build_short_explanation(seg_key: str, top_features: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Return a short, deterministic explanation string for a segment.\n",
    "    - Prefer curated text from explain_map if available.\n",
    "    - Otherwise derive from top weighted features in the segment weight vector.\n",
    "    \"\"\"\n",
    "    # 1) Prefer explain_map if it contains segment-level text\n",
    "    if isinstance(explain_map, dict):\n",
    "        if seg_key in explain_map and isinstance(explain_map[seg_key], str):\n",
    "            return explain_map[seg_key]\n",
    "        if \"segments\" in explain_map and seg_key in explain_map[\"segments\"]:\n",
    "            val = explain_map[\"segments\"][seg_key]\n",
    "            if isinstance(val, str):\n",
    "                return val\n",
    "\n",
    "    # 2) Fallback: derive from top absolute weights\n",
    "    w = baseline[seg_key][\"w\"]\n",
    "    idxs = np.argsort(-np.abs(w))[:top_features]\n",
    "    feats = [feature_names[i] for i in idxs if abs(w[i]) > 0]\n",
    "\n",
    "    if not feats:\n",
    "        return \"Balanced match across available signals.\"\n",
    "    return \"Prioritizes: \" + \", \".join(feats[:top_features])\n",
    "\n",
    "# --- Preview (ensure explanations look stable + UI-friendly) ---\n",
    "print(\"\\nShort explanations preview:\")\n",
    "for k in SEG_KEYS:\n",
    "    print(f\"- {k}: {build_short_explanation(k)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0366c-a9da-474e-9580-644f6660c3ee",
   "metadata": {},
   "source": [
    "### 06.3 Generate Export Payload (Segments + Blend Snap Points) \n",
    "\n",
    "This cell builds the production export payload that will be written to JSON.\n",
    "\n",
    "For each **segment**, we export:\n",
    "- Top-K school list (school_id, row_index, score)\n",
    "- A short deterministic explanation string (`why`)\n",
    "\n",
    "For each **blend pair** and each approved snap point \\(\\alpha\\), we export:\n",
    "- Top-K list for the blended weight vector\n",
    "- A transparent blend label and explanation\n",
    "\n",
    "The payload is structured so the frontend can:\n",
    "- render instantly with no computation\n",
    "- display consistent “why” strings\n",
    "- support snap-to-safe blending controls\n",
    "\n",
    "No learning is performed here — this is purely deterministic computation + export formatting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "879e96c6-f0a5-4275-aced-696337e37343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported GLOBAL segments: ['academic_first', 'small_nurturing', 'progressive_balanced', 'balanced_general']\n",
      "Exported GLOBAL blends: ['academic_first__blend__small_nurturing', 'academic_first__blend__progressive_balanced']\n",
      "Bay Area payload built\n",
      "Exported BAY AREA segments: ['academic_first', 'small_nurturing', 'progressive_balanced', 'balanced_general']\n",
      "Exported BAY AREA blends: ['academic_first__blend__small_nurturing', 'academic_first__blend__progressive_balanced']\n",
      "\n",
      "Sanity preview (GLOBAL):\n",
      "generated_at_utc: 2025-12-31T16:46:27Z\n",
      "first segment: academic_first\n",
      "sample items: [{'school_id': 'PRI_BB180318', 'name': 'silicon valley international school', 'city': 'palo alto', 'state': 'CA', 'zipcode': '94303', 'row_index': 123458, 'score': 12.974635205173513, 'why': 'Prioritizes: tag_ib, tag_cais, serves_middle'}, {'school_id': 'PRI_A0770343', 'name': 'escuela bilingue internacional', 'city': 'oakland', 'state': 'CA', 'zipcode': '94609', 'row_index': 112054, 'score': 12.951241815217962, 'why': 'Prioritizes: tag_ib, tag_cais, serves_middle'}]\n",
      "\n",
      "first blend (GLOBAL): academic_first__blend__small_nurturing alpha: 0.00\n",
      "sample items: [{'school_id': 'PRI_A0500573', 'name': 'paideia educational heritage', 'city': 'santa rosa', 'state': 'CA', 'zipcode': '95404', 'row_index': 110970, 'score': 6.028979747991382, 'why': 'Blend of academic_first and small_nurturing (alpha=0.00).'}, {'school_id': 'PRI_A1903036', 'name': 'genesis school - christian life center', 'city': 'chaumont', 'state': 'NY', 'zipcode': '13622', 'row_index': 116977, 'score': 6.028979747991382, 'why': 'Blend of academic_first and small_nurturing (alpha=0.00).'}]\n",
      "Bay Area sanity checks: PASS\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 06.3 Generate export payload (segments + blend snap points)\n",
    "# - Builds TWO payloads:\n",
    "#   1) export_payload (global)\n",
    "#   2) export_payload_bayarea (MVP, Bay Area-only via bay_area_zips)\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Detect ZIP column in schools_master_df\n",
    "ZIP_COL = \"zipcode\" if \"zipcode\" in schools_master_df.columns else (\"zip\" if \"zip\" in schools_master_df.columns else None)\n",
    "assert ZIP_COL, \"No ZIP column found in schools_master_df (expected 'zip' or 'zipcode')\"\n",
    "\n",
    "def rows_to_export_payload(\n",
    "    order: np.ndarray,\n",
    "    scores: np.ndarray,\n",
    "    why_label: str,\n",
    "    topk: int,\n",
    "    bay_area_only: bool = False,\n",
    "    grade_band: str | None = None,\n",
    "    state_col: str = \"state\",\n",
    "    zip_col_master: str | None = None,\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Convert ranked rows into export entries with UI-friendly fields.\n",
    "    If bay_area_only=True, filter to CA + Bay Area ZIPs BEFORE taking topk.\n",
    "    \"\"\"\n",
    "    rows = order\n",
    "\n",
    "    # ✅ NEW: grade-band eligibility filter (hard constraint)\n",
    "    if grade_band is not None:\n",
    "        rows = apply_band_filter_to_order(rows, grade_band)\n",
    "        \n",
    "    # use a consistent zip column everywhere\n",
    "    zip_col_master = zip_col_master or ZIP_COL\n",
    "    assert zip_col_master in schools_master_df.columns, f\"zip_col_master={zip_col_master} not in schools_master_df\"\n",
    "\n",
    "    if bay_area_only:\n",
    "        sub = schools_master_df.iloc[rows]\n",
    "        st = sub[state_col].astype(str).str.strip()\n",
    "        z = sub[zip_col_master].astype(str).str.zfill(5)\n",
    "        mask = (st == \"CA\") & (z.isin(bay_area_zips))\n",
    "        rows = rows[mask.to_numpy()]\n",
    "\n",
    "    rows = rows[:topk]\n",
    "    df = schools_master_df.iloc[rows]\n",
    "\n",
    "    items = []\n",
    "    for r, (_, row) in zip(rows.tolist(), df.iterrows()):\n",
    "        items.append({\n",
    "            \"school_id\": str(row[\"school_id\"]),\n",
    "            \"name\": row.get(\"school_name\", \"\"),\n",
    "            \"city\": row.get(\"city\", \"\"),\n",
    "            \"state\": row.get(\"state\", \"\"),\n",
    "            \"zipcode\": str(row.get(zip_col_master, \"\")).zfill(5) if row.get(zip_col_master, \"\") != \"\" else \"\",\n",
    "            \"row_index\": int(r),\n",
    "            \"score\": float(scores[r]),\n",
    "            \"why\": why_label\n",
    "        })\n",
    "    return items\n",
    "\n",
    "# -----------------------------\n",
    "# Build GLOBAL payload\n",
    "# -----------------------------\n",
    "export_payload = {\n",
    "    \"version\": \"v1\",\n",
    "    \"generated_at_utc\": now_iso_utc(),\n",
    "    \"topk\": int(TOPK_EXPORT),\n",
    "    \"region\": \"global\",\n",
    "    \"segments\": {},\n",
    "    \"blends\": {}\n",
    "}\n",
    "\n",
    "# segments (global)\n",
    "for seg in export_spec[\"segments\"]:\n",
    "    why = build_short_explanation(seg)\n",
    "    scores = baseline[seg][\"scores\"]\n",
    "    order = baseline[seg][\"order\"]\n",
    "\n",
    "    export_payload[\"segments\"][seg] = {\n",
    "        \"label\": seg,\n",
    "        \"why\": why,\n",
    "        \"items\": rows_to_export_payload(order, scores, why, TOPK_EXPORT, bay_area_only=False),\n",
    "    }\n",
    "\n",
    "print(\"Exported GLOBAL segments:\", list(export_payload[\"segments\"].keys()))\n",
    "\n",
    "# blends (global)\n",
    "for b in export_spec[\"blends\"]:\n",
    "    name = b[\"name\"]\n",
    "    seg_a = b[\"seg_a\"]\n",
    "    seg_b = b[\"seg_b\"]\n",
    "\n",
    "    export_payload[\"blends\"][name] = {\"seg_a\": seg_a, \"seg_b\": seg_b, \"alphas\": {}}\n",
    "\n",
    "    for a in b[\"alphas\"]:\n",
    "        scores, order = score_and_rank_blend(seg_a, seg_b, a)\n",
    "        why = f\"Blend of {seg_a} and {seg_b} (alpha={a:.2f}).\"\n",
    "\n",
    "        export_payload[\"blends\"][name][\"alphas\"][f\"{a:.2f}\"] = {\n",
    "            \"alpha\": float(a),\n",
    "            \"label\": f\"{name}__a{a:.2f}\",\n",
    "            \"why\": why,\n",
    "            \"items\": rows_to_export_payload(order, scores, why, TOPK_EXPORT, bay_area_only=False),\n",
    "        }\n",
    "\n",
    "print(\"Exported GLOBAL blends:\", list(export_payload[\"blends\"].keys()))\n",
    "\n",
    "# -----------------------------\n",
    "# Build BAY AREA payload (MVP)\n",
    "# -----------------------------\n",
    "export_payload_bayarea = {\n",
    "    \"version\": \"v1\",\n",
    "    \"generated_at_utc\": export_payload[\"generated_at_utc\"],  # keep same timestamp for easy diffing\n",
    "    \"topk\": int(TOPK_EXPORT),\n",
    "    \"region\": \"bay_area\",\n",
    "    \"segments\": {},\n",
    "    \"blends\": {}\n",
    "}\n",
    "\n",
    "# segments (Bay Area filtered)\n",
    "for seg in export_spec[\"segments\"]:\n",
    "    why = build_short_explanation(seg)\n",
    "    scores = baseline[seg][\"scores\"]\n",
    "    order = baseline[seg][\"order\"]\n",
    "\n",
    "    export_payload_bayarea[\"segments\"][seg] = {\n",
    "        \"label\": seg,\n",
    "        \"why\": why,\n",
    "        \"items\": rows_to_export_payload(order, scores, why, TOPK_EXPORT, bay_area_only=True),\n",
    "    }\n",
    "\n",
    "# blends (Bay Area filtered)\n",
    "for b in export_spec[\"blends\"]:\n",
    "    name = b[\"name\"]\n",
    "    seg_a = b[\"seg_a\"]\n",
    "    seg_b = b[\"seg_b\"]\n",
    "\n",
    "    export_payload_bayarea[\"blends\"][name] = {\"seg_a\": seg_a, \"seg_b\": seg_b, \"alphas\": {}}\n",
    "\n",
    "    for a in b[\"alphas\"]:\n",
    "        scores, order = score_and_rank_blend(seg_a, seg_b, a)\n",
    "        why = f\"Blend of {seg_a} and {seg_b} (alpha={a:.2f}).\"\n",
    "\n",
    "        export_payload_bayarea[\"blends\"][name][\"alphas\"][f\"{a:.2f}\"] = {\n",
    "            \"alpha\": float(a),\n",
    "            \"label\": f\"{name}__a{a:.2f}\",\n",
    "            \"why\": why,\n",
    "            \"items\": rows_to_export_payload(order, scores, why, TOPK_EXPORT, bay_area_only=True),\n",
    "        }\n",
    "\n",
    "print(\"Bay Area payload built\")\n",
    "print(\"Exported BAY AREA segments:\", list(export_payload_bayarea[\"segments\"].keys()))\n",
    "print(\"Exported BAY AREA blends:\", list(export_payload_bayarea[\"blends\"].keys()))\n",
    "\n",
    "# -----------------------------\n",
    "# Quick sanity previews\n",
    "# -----------------------------\n",
    "first_seg = export_spec[\"segments\"][0]\n",
    "print(\"\\nSanity preview (GLOBAL):\")\n",
    "print(\"generated_at_utc:\", export_payload[\"generated_at_utc\"])\n",
    "print(\"first segment:\", first_seg)\n",
    "print(\"sample items:\", export_payload[\"segments\"][first_seg][\"items\"][:2])\n",
    "\n",
    "first_blend = export_spec[\"blends\"][0][\"name\"]\n",
    "first_alpha = list(export_payload[\"blends\"][first_blend][\"alphas\"].keys())[0]\n",
    "print(\"\\nfirst blend (GLOBAL):\", first_blend, \"alpha:\", first_alpha)\n",
    "print(\"sample items:\", export_payload[\"blends\"][first_blend][\"alphas\"][first_alpha][\"items\"][:2])\n",
    "\n",
    "# Bay Area sanity checks\n",
    "sample_ba = export_payload_bayarea[\"segments\"][first_seg][\"items\"][:20]\n",
    "assert len(sample_ba) > 0, f\"Bay Area export produced 0 items for segment={first_seg}\"\n",
    "assert all(it[\"state\"] == \"CA\" for it in sample_ba), \"Non-CA item found in Bay Area export\"\n",
    "assert all(str(it[\"zipcode\"]).zfill(5) in bay_area_zips for it in sample_ba), \"Non-BayArea ZIP found\"\n",
    "print(\"Bay Area sanity checks: PASS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5a359-d1f4-4ef8-b6e3-927bcf6b0488",
   "metadata": {},
   "source": [
    "### 06.3b Grade-band filtering (MVP suitability)\n",
    "\n",
    "Rankings are meaningful only when they match the child’s age/grade band.\n",
    "For MVP, we apply **hard eligibility filters** by grade span before selecting Top-K.\n",
    "\n",
    "Policy (Option A):\n",
    "- PK/K → use `serves_elementary` as the best available proxy in v2\n",
    "- Elementary → `serves_elementary`\n",
    "- Middle → `serves_middle`\n",
    "- High → `serves_high`\n",
    "\n",
    "This does not change scoring; it only changes which schools are eligible to appear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "5a3c0762-1264-4877-8974-9a17fd7e7993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 06.3b Grade-band filtering helpers\n",
    "# ============================================\n",
    "\n",
    "GRADE_BANDS = {\n",
    "    \"pk_k\": [\"serves_elementary\"],        # proxy for PK/K in v2\n",
    "    \"elementary\": [\"serves_elementary\"],\n",
    "    \"middle\": [\"serves_middle\"],\n",
    "    \"high\": [\"serves_high\"],\n",
    "}\n",
    "\n",
    "def mask_for_grade_band(band: str, rows: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns a boolean mask aligned to `rows` indicating which row indices\n",
    "    are eligible for the requested grade band.\n",
    "    \"\"\"\n",
    "    assert band in GRADE_BANDS, f\"Unknown band: {band}\"\n",
    "    required_cols = GRADE_BANDS[band]\n",
    "\n",
    "    sub = schools_master_df.iloc[rows]\n",
    "    mask = np.ones(len(rows), dtype=bool)\n",
    "\n",
    "    for col in required_cols:\n",
    "        if col not in sub.columns:\n",
    "            raise ValueError(f\"Missing grade-span column in schools_master_df: {col}\")\n",
    "        mask &= (sub[col].astype(int).to_numpy() == 1)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def apply_band_filter_to_order(order: np.ndarray, band: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Given a ranking order (array of row indexes), return a filtered order\n",
    "    containing only rows eligible for the grade band.\n",
    "    \"\"\"\n",
    "    m = mask_for_grade_band(band, order)\n",
    "    return order[m]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ed0cb6-81e0-4dc9-ae02-0fbcec2a3b4f",
   "metadata": {},
   "source": [
    "### 06.4 Write Production Artifacts (Global + Bay Area)(JSON) + Metadata \n",
    "\n",
    "This section writes the deployable, versioned JSON artifacts used by the frontend.\n",
    "\n",
    "We export **two variants**:\n",
    "\n",
    "- **Global** (`schools_top100_v1.json`) — full reference ranking universe\n",
    "- **Bay Area MVP** (`schools_top100_v1_bayarea.json`) — filtered using HUD ZIP→County crosswalk\n",
    "\n",
    "Both exports share:\n",
    "- identical schema\n",
    "- identical generation timestamp\n",
    "- accompanying metadata JSON\n",
    "- updated run manifest for reproducibility\n",
    "\n",
    "This enables a Bay Area–scoped MVP UI while preserving a global baseline for\n",
    "capstone evaluation and future expansion.\n",
    "\n",
    "This cell writes the final production assets to the Notebook 08 artifacts folder.\n",
    "\n",
    "Outputs:\n",
    "\n",
    "1) `schools_top100_v1.json`\n",
    "- All segment Top-100 lists\n",
    "- All blend snap-point Top-100 lists\n",
    "- Each item contains: `school_id`, `row_index`, `score`, `why`\n",
    "\n",
    "2) `schools_top100_v1_meta.json`\n",
    "- Version + timestamp\n",
    "- Input file paths\n",
    "- SHA-256 hashes of key config files (feature config + segments config)\n",
    "- Matrix + index shapes\n",
    "- Policy versions (tie-break + blend snap points)\n",
    "\n",
    "Finally, the notebook run manifest is updated to include these artifact paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "7bd71ccf-94b7-4ae9-860d-17a662b45a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/schools_top100_v1.json\n",
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/schools_top100_v1_bayarea.json\n",
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/schools_top100_v1_meta.json\n",
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/schools_top100_v1_bayarea_meta.json\n",
      "Updated manifest: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/run_manifest_v1.json\n",
      "\n",
      "Readback sanity (GLOBAL):\n",
      "segments: ['academic_first', 'small_nurturing', 'progressive_balanced', 'balanced_general']\n",
      "blends: ['academic_first__blend__small_nurturing', 'academic_first__blend__progressive_balanced']\n",
      "first segment first item: {'school_id': 'PRI_BB180318', 'name': 'silicon valley international school', 'city': 'palo alto', 'state': 'CA', 'zipcode': '94303', 'row_index': 123458, 'score': 12.974635205173513, 'why': 'Prioritizes: tag_ib, tag_cais, serves_middle'}\n",
      "\n",
      "Readback sanity (BAY AREA):\n",
      "segments: ['academic_first', 'small_nurturing', 'progressive_balanced', 'balanced_general']\n",
      "blends: ['academic_first__blend__small_nurturing', 'academic_first__blend__progressive_balanced']\n",
      "first segment first item: {'school_id': 'PRI_BB180318', 'name': 'silicon valley international school', 'city': 'palo alto', 'state': 'CA', 'zipcode': '94303', 'row_index': 123458, 'score': 12.974635205173513, 'why': 'Prioritizes: tag_ib, tag_cais, serves_middle'}\n",
      "Bay Area readback checks: PASS\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 06.4 Write Production Artifacts (Global + Bay Area)\n",
    "# ============================================\n",
    "\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def sha256_file(path: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def normalize_zipcodes_in_payload(payload: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Ensure zipcode is exported as a zero-padded 5-char string for consistency.\n",
    "    Works in-place; returns payload for convenience.\n",
    "    \"\"\"\n",
    "    def fix_items(items: list):\n",
    "        for it in items:\n",
    "            z = it.get(\"zipcode\", \"\")\n",
    "            if z is None:\n",
    "                it[\"zipcode\"] = \"\"\n",
    "            else:\n",
    "                zs = str(z).strip()\n",
    "                it[\"zipcode\"] = zs.zfill(5) if zs != \"\" else \"\"\n",
    "\n",
    "    # segments\n",
    "    for seg_obj in payload.get(\"segments\", {}).values():\n",
    "        fix_items(seg_obj.get(\"items\", []))\n",
    "\n",
    "    # blends\n",
    "    for blend_obj in payload.get(\"blends\", {}).values():\n",
    "        for alpha_obj in blend_obj.get(\"alphas\", {}).values():\n",
    "            fix_items(alpha_obj.get(\"items\", []))\n",
    "\n",
    "    return payload\n",
    "\n",
    "# Normalize zipcode formatting (important: NY zips like 00501 keep leading zeros)\n",
    "export_payload = normalize_zipcodes_in_payload(export_payload)\n",
    "export_payload_bayarea = normalize_zipcodes_in_payload(export_payload_bayarea)\n",
    "\n",
    "# -----------------------------\n",
    "# Write payload JSONs\n",
    "# -----------------------------\n",
    "out_main = ARTIFACTS_DIR / \"schools_top100_v1.json\"\n",
    "with open(out_main, \"w\") as f:\n",
    "    json.dump(export_payload, f, indent=2)\n",
    "print(\"Saved:\", out_main)\n",
    "\n",
    "out_bay = ARTIFACTS_DIR / \"schools_top100_v1_bayarea.json\"\n",
    "with open(out_bay, \"w\") as f:\n",
    "    json.dump(export_payload_bayarea, f, indent=2)\n",
    "print(\"Saved:\", out_bay)\n",
    "\n",
    "# -----------------------------\n",
    "# Metadata (global + bay area)\n",
    "# -----------------------------\n",
    "feature_cfg_hash = sha256_file(paths[\"feature_config_master_v2\"])\n",
    "segments_cfg_hash = sha256_file(paths[\"preference_segments_v0\"])\n",
    "\n",
    "# Optional: include crosswalk hash if you stored it under data/raw\n",
    "zip_county_path = ROOT / \"data\" / \"raw\" / \"zip_county.xlsx\"\n",
    "zip_county_hash = sha256_file(zip_county_path) if zip_county_path.exists() else None\n",
    "\n",
    "base_meta = {\n",
    "    \"version\": \"v1\",\n",
    "    \"generated_at_utc\": export_payload[\"generated_at_utc\"],  # keep same timestamp for both\n",
    "    \"topk\": int(TOPK_EXPORT),\n",
    "    \"ui_fields\": [\"school_id\", \"name\", \"city\", \"state\", \"zipcode\", \"score\", \"why\"],\n",
    "    \"source_inputs\": {\n",
    "        \"feature_config_master_v2\": str(paths[\"feature_config_master_v2\"]),\n",
    "        \"preference_segments_v0\": str(paths[\"preference_segments_v0\"]),\n",
    "        \"school_matrix_v2\": str(paths[\"school_matrix_v2\"]),\n",
    "        \"school_index_v2\": str(paths[\"school_index_v2\"]),\n",
    "        \"schools_master_v2\": str(paths[\"schools_master_v2\"]),\n",
    "        \"school_vector_explain_v2\": str(paths[\"school_vector_explain_v2\"]),\n",
    "        \"hud_zip_county_xlsx\": str(zip_county_path) if zip_county_path.exists() else None,\n",
    "    },\n",
    "    \"hashes\": {\n",
    "        \"feature_config_master_v2_sha256\": feature_cfg_hash,\n",
    "        \"preference_segments_v0_sha256\": segments_cfg_hash,\n",
    "        \"hud_zip_county_xlsx_sha256\": zip_county_hash,\n",
    "    },\n",
    "    \"shapes\": {\n",
    "        \"matrix\": list(X.shape),\n",
    "        \"index\": list(index_df.shape),\n",
    "        \"schools_master\": list(schools_master_df.shape),\n",
    "    },\n",
    "    \"policies\": {\n",
    "        \"tie_breaker_policy_version\": tie_policy.policy_version if \"tie_policy\" in globals() else \"unknown\",\n",
    "        \"tie_breaker_epsilon\": tie_policy.epsilon if \"tie_policy\" in globals() else None,\n",
    "        \"blend_policy\": {\n",
    "            \"snap_points\": BLEND_POINTS,\n",
    "            \"blend_pairs\": BLEND_PAIRS,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "meta_global = dict(base_meta)\n",
    "meta_global[\"region\"] = \"global\"\n",
    "meta_global[\"notes\"] = {\"bay_area_filter\": \"none\"}\n",
    "\n",
    "meta_bay = dict(base_meta)\n",
    "meta_bay[\"region\"] = \"bay_area\"\n",
    "meta_bay[\"notes\"] = {\n",
    "    \"bay_area_filter\": \"HUD ZIP→County crosswalk; CA + Bay Area counties by 5-digit county FIPS\",\n",
    "    \"bay_area_county_fips_5\": sorted(list(BAY_AREA_COUNTY_FIPS_5)) if \"BAY_AREA_COUNTY_FIPS_5\" in globals() else None,\n",
    "    \"bay_area_zip_count\": int(len(bay_area_zips)) if \"bay_area_zips\" in globals() else None,\n",
    "}\n",
    "\n",
    "out_meta = ARTIFACTS_DIR / \"schools_top100_v1_meta.json\"\n",
    "with open(out_meta, \"w\") as f:\n",
    "    json.dump(meta_global, f, indent=2)\n",
    "print(\"Saved:\", out_meta)\n",
    "\n",
    "out_meta_bay = ARTIFACTS_DIR / \"schools_top100_v1_bayarea_meta.json\"\n",
    "with open(out_meta_bay, \"w\") as f:\n",
    "    json.dump(meta_bay, f, indent=2)\n",
    "print(\"Saved:\", out_meta_bay)\n",
    "\n",
    "# -----------------------------\n",
    "# Update run manifest (same style as your notebook)\n",
    "# -----------------------------\n",
    "manifest_path = ARTIFACTS_DIR / f\"run_manifest_{SYSTEM_VERSION}.json\"\n",
    "m = load_json(manifest_path)\n",
    "m.setdefault(\"outputs\", {})\n",
    "m[\"outputs\"].update({\n",
    "    \"artifacts.section06.schools_top100_v1\": str(out_main),\n",
    "    \"artifacts.section06.schools_top100_v1_meta\": str(out_meta),\n",
    "    \"artifacts.section06.schools_top100_v1_bayarea\": str(out_bay),\n",
    "    \"artifacts.section06.schools_top100_v1_bayarea_meta\": str(out_meta_bay),\n",
    "})\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(m, f, indent=2)\n",
    "print(\"Updated manifest:\", manifest_path)\n",
    "\n",
    "# -----------------------------\n",
    "# Sanity readback (global + bay area)\n",
    "# -----------------------------\n",
    "with open(out_main, \"r\") as f:\n",
    "    payload_check_global = json.load(f)\n",
    "with open(out_bay, \"r\") as f:\n",
    "    payload_check_bay = json.load(f)\n",
    "\n",
    "print(\"\\nReadback sanity (GLOBAL):\")\n",
    "print(\"segments:\", list(payload_check_global[\"segments\"].keys()))\n",
    "print(\"blends:\", list(payload_check_global[\"blends\"].keys()))\n",
    "first_seg = list(payload_check_global[\"segments\"].keys())[0]\n",
    "print(\"first segment first item:\", payload_check_global[\"segments\"][first_seg][\"items\"][0])\n",
    "\n",
    "print(\"\\nReadback sanity (BAY AREA):\")\n",
    "print(\"segments:\", list(payload_check_bay[\"segments\"].keys()))\n",
    "print(\"blends:\", list(payload_check_bay[\"blends\"].keys()))\n",
    "first_seg_b = list(payload_check_bay[\"segments\"].keys())[0]\n",
    "first_item_b = payload_check_bay[\"segments\"][first_seg_b][\"items\"][0]\n",
    "print(\"first segment first item:\", first_item_b)\n",
    "\n",
    "# hard checks: Bay Area item must be CA + zip in bay_area_zips + zipcode string\n",
    "assert first_item_b[\"state\"] == \"CA\", \"Bay Area readback: non-CA item found\"\n",
    "assert str(first_item_b[\"zipcode\"]).zfill(5) in bay_area_zips, \"Bay Area readback: non-BayArea ZIP found\"\n",
    "assert isinstance(first_item_b[\"zipcode\"], str), \"Bay Area readback: zipcode should be a string\"\n",
    "print(\"Bay Area readback checks: PASS\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711ee657-99aa-427b-912c-8b4457a92005",
   "metadata": {},
   "source": [
    "### 06.4b Export Grade-band Artifacts (Bay Area MVP) \n",
    "\n",
    "To support parent-facing recommendations, we export Bay Area Top-100 rankings\n",
    "for each grade band:\n",
    "\n",
    "- PK/K (proxy via serves_elementary)\n",
    "- Elementary\n",
    "- Middle\n",
    "- High\n",
    "\n",
    "The frontend selects the correct artifact based on the child’s grade band.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "59afb116-fa6f-4269-a86d-5cb9e0f4d663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/schools_top100_v1_bayarea__pk_k.json | first seg items: 100\n",
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/schools_top100_v1_bayarea__elementary.json | first seg items: 100\n",
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/schools_top100_v1_bayarea__middle.json | first seg items: 100\n",
      "Saved: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/schools_top100_v1_bayarea__high.json | first seg items: 100\n",
      "Updated manifest: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/run_manifest_v1.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 06.4b Export Bay Area grade-band artifacts \n",
    "# ============================================\n",
    "\n",
    "import json\n",
    "\n",
    "def build_bayarea_payload_for_band(grade_band: str) -> dict:\n",
    "    payload = {\n",
    "        \"version\": \"v1\",\n",
    "        \"generated_at_utc\": export_payload[\"generated_at_utc\"],\n",
    "        \"topk\": int(TOPK_EXPORT),\n",
    "        \"region\": \"bay_area\",\n",
    "        \"grade_band\": grade_band,  # key for UI\n",
    "        \"segments\": {},\n",
    "        \"blends\": {}\n",
    "    }\n",
    "\n",
    "    # segments\n",
    "    for seg in export_spec[\"segments\"]:\n",
    "        why = build_short_explanation(seg)\n",
    "        scores = baseline[seg][\"scores\"]\n",
    "        order = baseline[seg][\"order\"]\n",
    "\n",
    "        payload[\"segments\"][seg] = {\n",
    "            \"label\": seg,\n",
    "            \"why\": why,\n",
    "            \"items\": rows_to_export_payload(\n",
    "                order, scores, why, TOPK_EXPORT,\n",
    "                bay_area_only=True,\n",
    "                grade_band=grade_band\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    # blends\n",
    "    for b in export_spec[\"blends\"]:\n",
    "        name = b[\"name\"]\n",
    "        seg_a = b[\"seg_a\"]\n",
    "        seg_b = b[\"seg_b\"]\n",
    "        payload[\"blends\"][name] = {\"seg_a\": seg_a, \"seg_b\": seg_b, \"alphas\": {}}\n",
    "\n",
    "        for a in b[\"alphas\"]:\n",
    "            scores, order = score_and_rank_blend(seg_a, seg_b, a)\n",
    "            why = f\"Blend of {seg_a} and {seg_b} (alpha={a:.2f}).\"\n",
    "\n",
    "            payload[\"blends\"][name][\"alphas\"][f\"{a:.2f}\"] = {\n",
    "                \"alpha\": float(a),\n",
    "                \"label\": f\"{name}__a{a:.2f}\",\n",
    "                \"why\": why,\n",
    "                \"items\": rows_to_export_payload(\n",
    "                    order, scores, why, TOPK_EXPORT,\n",
    "                    bay_area_only=True,\n",
    "                    grade_band=grade_band\n",
    "                ),\n",
    "            }\n",
    "\n",
    "    return payload\n",
    "\n",
    "# write one file per grade band\n",
    "band_files = {}\n",
    "for band in GRADE_BANDS.keys():\n",
    "    out_path = ARTIFACTS_DIR / f\"schools_top100_v1_bayarea__{band}.json\"\n",
    "    payload = build_bayarea_payload_for_band(band)\n",
    "\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump(payload, f, indent=2)\n",
    "\n",
    "    band_files[band] = str(out_path)\n",
    "    print(\"Saved:\", out_path, \"| first seg items:\", len(payload[\"segments\"][export_spec[\"segments\"][0]][\"items\"]))\n",
    "\n",
    "# add to manifest outputs (same style as yours)\n",
    "manifest_path = ARTIFACTS_DIR / f\"run_manifest_{SYSTEM_VERSION}.json\"\n",
    "m = load_json(manifest_path)\n",
    "m.setdefault(\"outputs\", {})\n",
    "for band, p in band_files.items():\n",
    "    m[\"outputs\"][f\"artifacts.section06.schools_top100_v1_bayarea__{band}\"] = p\n",
    "\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(m, f, indent=2)\n",
    "print(\"Updated manifest:\", manifest_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc93aa3-1e57-4e29-a47a-655d04ae5d2a",
   "metadata": {},
   "source": [
    "## 07. Summary & Forward Roadmap \n",
    "\n",
    "Notebook 08 completed the transition from a validated deterministic system\n",
    "(Notebook 07) to a **launch-ready** deterministic system with safety checks,\n",
    "diagnostic learning, blending, and production exports.\n",
    "\n",
    "---\n",
    "\n",
    "### What We Added in Notebook 08\n",
    "\n",
    "**1) Calibration diagnostics (without ground truth)**\n",
    "- Measured tie density, rank volatility, and segment-specific fragility\n",
    "- Verified tier behavior using known baselines (IB, CAIS, Montessori, Waldorf)\n",
    "\n",
    "**2) Deterministic fixes (no ML authority)**\n",
    "- Added a stable tie-break policy to produce deterministic ordering\n",
    "- Implemented lexicographic tie-breaking where secondary dense features exist\n",
    "- Preserved Top-K membership guardrails to avoid silent behavior changes\n",
    "\n",
    "**3) Capstone science (learning as a consultant)**\n",
    "- Correlation analysis to detect redundancy (diagnostic only)\n",
    "- PCA to understand variance contribution and feature structure (diagnostic only)\n",
    "- Produced recommendations for simplification without changing ranking authority\n",
    "\n",
    "**4) Segment blending (startup “killer feature”)**\n",
    "- Enabled continuous personalization via linear blending:\n",
    "  \\[\n",
    "  \\vec{W}_{blend} = \\alpha \\vec{W}_A + (1-\\alpha)\\vec{W}_B\n",
    "  \\]\n",
    "- Used snap-to-safe blend points for launch stability\n",
    "- Validated blended ranking behavior and surfaced high-drift cases for UX care\n",
    "\n",
    "**5) Safety regression suite (launch gate)**\n",
    "- Tier endpoint regression: PASS\n",
    "- Grade-span hard guardrails: PASS (review-only drift surfaced)\n",
    "- Wide Top-N envelope for candidate pool: PASS\n",
    "\n",
    "**6) Production export artifacts**\n",
    "- Generated precomputed Top-100 lists for:\n",
    "  - all segments\n",
    "  - blend snap points\n",
    "- Exported versioned JSON with hashes + metadata for reproducibility:\n",
    "  - `schools_top100_v1.json`\n",
    "  - `schools_top100_v1_meta.json`\n",
    "\n",
    "---\n",
    "\n",
    "### What Remains Deterministic by Design\n",
    "\n",
    "- The scoring function is deterministic and explicit\n",
    "- Tier logic is not overridden\n",
    "- Learning is used only for diagnostics, simplification suggestions, and audits\n",
    "- No outcome prediction, no click-based learning, no opaque ranking model\n",
    "\n",
    "---\n",
    "\n",
    "### Post-Launch Roadmap (Safe Evolution)\n",
    "\n",
    "**Phase 1: Collect ground-truth signals**\n",
    "- user saves / hides / “this fits” feedback\n",
    "- refine segment weights via explicit human-in-the-loop calibration\n",
    "\n",
    "**Phase 2: Improve explainability**\n",
    "- map feature names to user-friendly labels\n",
    "- add per-school “top contributing signals” explanations\n",
    "\n",
    "**Phase 3: Expand feature space**\n",
    "- add richer continuous signals (academics, logistics, programs)\n",
    "- tighten grade-span enforcement using requested grade targets\n",
    "\n",
    "**Phase 4: Learning (carefully bounded)**\n",
    "- use weak supervision to propose weight adjustments\n",
    "- always keep deterministic policy as the final authority\n",
    "\n",
    "---\n",
    "\n",
    "> Determinism builds trust.  \n",
    "> Learning improves structure.  \n",
    "> Control preserves safety.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342cb10d-dbf2-43af-a83c-8b723bd8fb2d",
   "metadata": {},
   "source": [
    "### 07.1 Run Summary & Reproducibility Check  \n",
    "\n",
    "This final section prints a compact, human-readable summary of the current run.\n",
    "It serves three purposes:\n",
    "\n",
    "1. **Reproducibility** — confirms inputs, outputs, and timestamps\n",
    "2. **Auditability** — makes it easy to review what artifacts were generated\n",
    "3. **Capstone hygiene** — demonstrates disciplined experiment tracking\n",
    "\n",
    "This section does not perform any computation or ranking.\n",
    "It is a read-only summary of the run manifest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7fa4b459-17f5-471d-86a8-99f98341e9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Notebook 08 — Run Summary ===\n",
      "\n",
      "--- Run Metadata ---\n",
      "run_ts_utc : 2025-12-27T18:51:15Z\n",
      "root_dir  : None\n",
      "version   : v1\n",
      "\n",
      "--- Inputs ---\n",
      "- inputs.section01.school_matrix_v2: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/data/processed/school_matrix_v2.npy\n",
      "- inputs.section01.school_index_v2: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/data/processed/school_index_v2.csv\n",
      "- inputs.section01.feature_config_master_v2: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/data/processed/feature_config_master_v2.json\n",
      "- inputs.section01.preference_segments_v0: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/config/preference_segments_v0.json\n",
      "- hash.school_matrix_v2: 9e868835457d58c14c149ad06298f8a50952b6c5a4f6483bd6d6029473c83203\n",
      "- hash.feature_config_master_v2: 541f56708eb9c2f57de733fc44cd747f5a26a1490e12b709eb45f3a186a993a8\n",
      "- hash.preference_segments_v0: f14ed98a765ce46d2ce69e5d6a671fcc2afabf102d2d5834068af1b2f2b1dbfc\n",
      "- inputs.section02.tie_breaker_policy_version: tb_v1\n",
      "- inputs.section02.tie_breaker_epsilon: 0.0001\n",
      "- inputs.section02.tie_breaker_count_mode: nonzero_features\n",
      "- inputs.section02.tie_breaker_stable_id_col: school_id\n",
      "\n",
      "--- Outputs ---\n",
      "- reports.section01.tie_density_by_segment: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section01_tie_density_by_segment.csv\n",
      "- reports.section01.rank_volatility_by_segment: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section01_rank_volatility_by_segment.csv\n",
      "- reports.section01.tier_dominance_by_segment: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section01_tier_dominance_by_segment.csv\n",
      "- reports.section01.tier_dominance_by_segment_v2: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section01_tier_dominance_by_segment_v2.csv\n",
      "- artifacts.section02.tie_breaker_policy_json: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/tie_breaker_policy_tb_v1.json\n",
      "- reports.section02.tie_density_after_tiebreak: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section02_tie_density_after_tiebreak.csv\n",
      "- reports.section02.topk_overlap_guardrail: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section02_topk_overlap_guardrail.csv\n",
      "- reports.section02.lex_tiebreak_effect: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section02_lex_tiebreak_effect.csv\n",
      "- reports.section02.topk_overlap_guardrail_v2: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section02_topk_overlap_guardrail_v2.csv\n",
      "- reports.section03.feature_corr_pearson: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section03_feature_corr_pearson.csv\n",
      "- reports.section03.feature_corr_spearman: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section03_feature_corr_spearman.csv\n",
      "- reports.section03.feature_corr_top_pairs: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section03_feature_corr_top_pairs.csv\n",
      "- reports.section03.pca_variance: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section03_pca_variance.csv\n",
      "- reports.section03.pca_loadings: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section03_pca_loadings.csv\n",
      "- reports.section05.tier_regression: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section05_tier_regression.csv\n",
      "- reports.section05.tier_endpoint_check: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section05_tier_endpoint_check.csv\n",
      "- reports.section05.grade_regression: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section05_grade_regression.csv\n",
      "- reports.section05.grade_endpoint_check: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section05_grade_endpoint_check.csv\n",
      "- reports.section05.grade_envelope_violations: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section05_grade_envelope_violations.csv\n",
      "- reports.section05.grade_envelope_violations_v2: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section05_grade_envelope_violations_v2.csv\n",
      "- params.section05.grade_envelope_tolerance: 0.01\n",
      "- reports.section05.grade_guardrails_v2: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section05_grade_guardrails_v2.csv\n",
      "- params.section05.grade_near_zero: 0.02\n",
      "- params.section05.grade_high_present: 0.6\n",
      "- params.section05.grade_collapse_floor: 0.4\n",
      "- params.section05.grade_max_drift: 0.15\n",
      "- reports.section05.topk_envelope_check: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section05_topk_envelope_check.csv\n",
      "- reports.section05.topk_wide_envelope_check_top5000: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/reports/notebook08_section05_topk_wide_envelope_check_top5000.csv\n",
      "- params.section05.topn_endpoints: 5000\n",
      "- artifacts.section06.schools_top100_v1: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/schools_top100_v1.json\n",
      "- artifacts.section06.schools_top100_v1_meta: /Users/jennifer-david/Documents/work/SpringBoard/projects/Capstone Projects/smart-school/artifacts/notebook08/schools_top100_v1_meta.json\n",
      "\n",
      "--- Artifacts ---\n",
      "\n",
      "--- Safety & Guardrails ---\n",
      "\n",
      "=== End of Notebook 08 ===\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 07.1 Run Summary & Reproducibility Check\n",
    "# ============================================\n",
    "\n",
    "print(\"=== Notebook 08 — Run Summary ===\")\n",
    "\n",
    "manifest_path = ARTIFACTS_DIR / \"run_manifest_v1.json\"\n",
    "assert manifest_path.exists(), \"Run manifest not found.\"\n",
    "\n",
    "with open(manifest_path, \"r\") as f:\n",
    "    manifest = json.load(f)\n",
    "\n",
    "# Core metadata\n",
    "print(\"\\n--- Run Metadata ---\")\n",
    "print(f\"run_ts_utc : {manifest.get('run_ts_utc')}\")\n",
    "print(f\"root_dir  : {manifest.get('root_dir')}\")\n",
    "print(f\"version   : {manifest.get('version', 'v1')}\")\n",
    "\n",
    "# Inputs\n",
    "print(\"\\n--- Inputs ---\")\n",
    "for k, v in manifest.get(\"inputs\", {}).items():\n",
    "    print(f\"- {k}: {v}\")\n",
    "\n",
    "# Outputs\n",
    "print(\"\\n--- Outputs ---\")\n",
    "for k, v in manifest.get(\"outputs\", {}).items():\n",
    "    print(f\"- {k}: {v}\")\n",
    "\n",
    "# Artifacts\n",
    "print(\"\\n--- Artifacts ---\")\n",
    "for a in manifest.get(\"artifacts\", []):\n",
    "    print(f\"- {a}\")\n",
    "\n",
    "# Guardrails\n",
    "print(\"\\n--- Safety & Guardrails ---\")\n",
    "for g in manifest.get(\"checks\", []):\n",
    "    status = g.get(\"status\", \"UNKNOWN\")\n",
    "    print(f\"- {g.get('name')}: {status}\")\n",
    "\n",
    "print(\"\\n=== End of Notebook 08 ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86255bdb-dee2-4273-932d-8c986637e911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
